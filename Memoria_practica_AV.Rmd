---
title: "Mundial de natación de Kazán 2015"
author: "Inés Molinero, Javier Villanueva, Salma Ghailan, Alonso González"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    toc: yes
    toc_float:
      collapsed: true
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Cargamos las librerias que vamos necesitando a lo largo del codigo

library(rpart)
library(rpart.plot)
library(caret)
library(pastecs)
library(factoextra)
library(dplyr)
library(MASS)
library(rstatix)
library(ggplot2)
library(tidyr)
library(ggimage)
library(countrycode)
library(ggExtra)
library(cluster)
library(purrr)
library(dendextend)
library(RColorBrewer)
library(knitr)
library(FSA)
library(tidyverse)
library(viridis) # Para una paleta amigable para daltónicos
```

# Introducción.

En este proyecto, se analizarán los resultados del **mundial de natación de 2015** con el objetivo de identificar patrones en el desempeño de los nadadores por país y eventos.
Se realizará un análisis exploratorio de datos y se utilizarán técnicas de reducción de dimensionalidad, aprendizaje no supervisado, aprendizaje supervisado, medidas de rendimiento, comparación de modelos y técnicas de Aprendizaje Máquina Explicable.

En primer lugar, veamos con qué datos vamos a tratar.
El conjunto de datos consiste en los resultados del Campeonato Mundial de Natación Kazán del año 2015, con los correspondientes datos de cada nadador y prueba.
Los datos han sido extraídos de [Omega](http://www.omegatiming.com/File/Download?id=00010F0200FFFFFFFFFFFFFFFFFFFF08), la plataforma oficial de tiempos de la World Aquatics.
El conjunto de datos contiene información sobre los nadadores (fecha de nacimiento, país, id), y sobre la prueba nadada (tiempo de reacción, parciales, tiempo total, estilo, serie).

Las variables o atributos que conforman el conjunto de datos son:

-   athleteid: id del nadador
-   lastname: Apellidos del nadador
-   firstname: El nombre del nadador
-   birthdate: Fecha de nacimiento del nadador
-   gender: Género del nadador/a
-   name: Nombre del país
-   code: abreviatura del país.
-   eventid: id de la prueba nadada (único)
-   heat: Serie en la que nadaron
-   lane: Calle en la que nadaron (0 a 9)
-   points: puntos FINA que realizaron. (es una "estimación" entre el mejor tiempo o récord del mundo, y el tiempo realizado. )
-   reactiontime: Tiempo de reacción en la salida.
-   swimtime: tiempo tardado
-   split: Parcial
-   cumswimtime: Tiempo acumulado en el parcial
-   splitdistance: Distancia del parcial
-   daytime: hora a la que se nadó
-   round: ronda (preliminar, semifinal, final)
-   distance: distancia de la prueba
-   relaycount: Número de relevista.
-   stroke: Estilo de nado en el que se realizó la prueba.
-   splitswimtime: Tiempo del parcial (50m)

# Entender los datos.

Primeramente, vamos a leer los datos:

```{r}
datos2015<-read.csv("datos/2015_FINA.csv", header=TRUE, sep = ',')
```

Una vez nuestro programa los ha leído, vamos a averiguar el tamaño de los datos con los que vamos a tratar:

```{r}
dim(datos2015)
```

Las dimensiones del dataframe son 11423 filas y 22 variables o columnas.

Veamos la primera ocurrencia:

```{r}
head(datos2015,1)
```

Observamos Noel Borshi, nadadora albanesa nacida un 13 de febrero de 1996, que tiene como id el número (100784).
Noel Borshi nadó la prueba 1 en la serie 1 y carril 4.
Nadó el 100m Mariposa en la ronda preliminar con un tiempo final de 63.65 segundos y pasó por el primer parcial (50m) en 29.63 segundos.

# Análisis exploratorio de datos.

## Resumen de los datos.

A continuación, vamos a ver un resumen de los datos:

```{r}
summary(datos2015)
```

De aquí, podemos observar que tenemos algunos valores nulos (NA's), durante toda la competición, que como máximo hubo 12 series y como mínimo 1 y que la piscina disponía de 10 carriles numerados del 0 al 9.
También observamos que se nadaron pruebas de 50 y hasta 1500 metros.

Tenemos variables categóricas las cuales se han tratado como continuas de partida.
Por lo cual, usando la librería "dyplr", vamos a convertirlas a variables categóricas en R para tener una mejor visualización de ellas.

```{r}
datos2015<- datos2015 %>% convert_as_factor(gender,name,code,round,heat,lane,stroke, relaycount)

```

Visualicemos ahora de nuevo el resumen:

```{r}
summary(datos2015)
```

Viendo este resumen de los datos podemos comenzar a entender algunas de las variables.

Observamos que las variables name y code toman absolutamente los mismos valores.
Se trata del país de procedencia de cada nadador.

Vemos que hay 5 ***tipos de nado***: braza, mariposa, crol, espalda y estilos individual.

No hemos guardado la distancia como una variable categórica, pero más adelante veremos que hay 6 distancias (50, 100, 200, 400, 800, 1500).
Hay 5 tipos de ronda distintos.

El menor tiempo de reacción fue de 0.42 y el mayor de 0.97.

Viendo los datos, observamos que cada nadador tiene en una prueba concreta, tantas filas como parciales tenía en esa prueba, luego es obvio que para conocer mejor algunas variables, vamos a necesitar limpiar los datos para que los elementos repetidos no causen interferencia en nuestros datos.

A continuación, vamos a ir realizando estudios para tratar de comprender más a fondo algunas variables.

## Variable Relaycount.

Si observamos el resumen de la variable relaycount:

```{r}
summary(datos2015$relaycount)
```

Observamos que sólo toma un único valor, 1.
Esto se debe principalmente a que nuestro conjunto de datos consta de las pruebas individuales del mundial de Kazán 2015, luego como no hay relevos, todos los nadadores son el primer "relevista" en su prueba.

Luego, la eliminamos:

```{r}
datos2015$relaycount <- NULL
```

Luego ahora, tenemos 21 variables en vez de 22.

## Valores NA. Datos faltantes.

Si volvemos a mirar nuestro resumen, observamos que hay valores faltantes.
Vamos a tratar de identificarlos, intentar entender el por qué de esos datos faltantes, y razonar cuándo será conveniente eliminarlos o no de nuestro estudio.

Para ello, vamos a obtener primeramente un resumen de cuántos datos faltantes hay:

```{r}
print(sum(is.na(datos2015)))
```

Observamos que hay 309 valores faltantes.

Vamos a crear una dataframe donde se nos muestren dónde se encuentran los valores faltantes:

```{r}
datosNA <- datos2015[rowSums(is.na(datos2015)) > 0, ]
dim(datosNA)

```

Observamos que, de 11429 observaciones de mi dataframe original, en 73 de ellas, existe algún valor nulo.
Es decir, un 0.63 % por ciento.
Lo cual es un valor muy bajo.

En principio y sin estudiar nada más, podríamos considerar eliminar las filas que contengan datos faltantes ya que toman un valor muy pequeño con respecto al total.
Aún así, vamos a ver dónde se suelen tomar más valores nulos e intentar explicar el por qué.
Hacemos una dataframe adicional con los valores nulos de cada variable en porcentaje:

```{r}
percent_na <- colSums(is.na(datosNA)) / nrow(datosNA) * 100
percent_na

```

Observamos de manera bastante clara que los datos nulos tienen mucho que ver con el tiempo acumulado, los puntos finales, el tiempo de reacción, el tiempo final y el tiempo al paso por el parcial.

A continuación, vamos a intentar clasificar los nulos dependiendo qué falta:

### Valores nulos en los que faltan todas las variables.

Visualicemos los datos donde faltan todas las variables dichas anteriormente:

```{r}
todosNA<-datosNA[is.na(datosNA$points) & is.na(datosNA$reactiontime) & is.na(datosNA$swimtime) & is.na(datosNA$cumswimtime) & is.na(datosNA$splitswimtime), ]

dim(todosNA)
```

Bien, en 59 de las 73 observaciones, faltan, tanto el tiempo de reacción, los puntos finales, el tiempo final, los parciales acumulados...
Es decir, nadadores que posiblemente se dieron de baja en la prueba.

```{r}
summary(todosNA)
```

```{r}
todosNA[todosNA$round=="FIN",]
```

La mayoría de nadadores causaron baja en la ronda preliminar, pero hay uno, el nadador chino Sun Yang, que causó baja en la final del 1500m libres masculino.

Haciendo una pequeña búsqueda en los resultados de la World Aquatics de los mundiales de 2015, observamos que Sun Yang produjo DNS (Did not Start).

```{r}
todosNA[todosNA$firstname=="CESAR",]
```

También, buscando a César Cielo en el 50 libres de las preliminares, observamos que causó baja DNS.
Para ponernos en contexto, Cesar Cielo es a dia de hoy, el poseedor del récord mundial del 50 libres, luego también resultaba raro que causase baja.

Luego todo parece indicar que estos nadadores fueron baja en esa prueba y por ello no sale ningún dato en esas variables.
Vamos a optar por eliminarlos.

```{r}
#Primero datosNA: 
datosNA <- datosNA %>%
  filter(!(is.na(datosNA$points) & is.na(datosNA$reactiontime) & is.na(datosNA$swimtime) & is.na(datosNA$cumswimtime) & is.na(datosNA$splitswimtime)))

#Ahora, los eliminamos de datos2015: 
datos2015<-datos2015 %>%
  filter(!(is.na(datos2015$points) & is.na(datos2015$reactiontime) & is.na(datos2015$swimtime) & is.na(datos2015$cumswimtime) & is.na(datos2015$splitswimtime)))

```

Bien, ahora, tenemos solamente datos en los que falta alguna de las variables.
Analizamos nuevamente para poder reclasificarlos:

```{r}
datosNA
```

Nos quedan solamente 14 filas en los que hay datos nulos.

Si seguimos con nuestra limpieza:

### Valores nulos donde faltan los puntos:

Veamos qué sucede si sólo faltan los puntos:

```{r}
naReactionTime<-datosNA[is.na(datosNA$points),]
naReactionTime
```

Vamos a buscar los resultados de World Aquatics de alguno de ellos, para estimar qué esta sucediendo.
¿Fueron descalificados?.

Nuestro nadador de la primera fila, Ben Treffers, fue descalificado.
Buscamos también a Vladimir Morozov, y también fue descalificado.
Luego, son participantes que nadaron pero quedaron descalificados.
Por tanto, sus datos nos servirán para hacer estudios sobre participación, pero no para cualquier estudio que involucre los resultados.
Luego estos, no los eliminamos del dataframe inicial.

```{r}
datosNA <- datosNA %>%
  filter(!(is.na(datosNA$points)))
```

Me quedan las dos ultimas observaciones por ver:

```{r}
datosNA
```

Tenemos dos observaciones en las cuales no existe el tiempo de reacción.
Seguramente se deba a algún fallo en el sistema electrónico o algún fallo al pasar los datos.
Por lo tanto, al igual que con los anteriores, no lo eliminaremos de nuestro dataframe inicial, pero sí lo tendremos en cuenta cuando tengamos que analizar estudios que tengan que ver con el tiempo de reacción.

```{r}
print(sum(is.na(datos2015)))
```

Luego, de 309 iniciales, vamos a tratar ahora con 14 datos nulos ya controlados.

```{r, echo=FALSE}
#Elimino las cosas creadas para no sobrecargar. Ya que no las vamos a volver a usar.
rm(datosNA, naReactionTime, todosNA, percent_na)
```

## Variable birthdate. Creacion de nueva variable edad

A continuación, vamos a crear una variable llamada *edad*, ya que será más representativo que trabajar con la variable birthdate.
La variable tendrá el valor numérico de la edad de cada participante en el momento del mundial.
Es decir, el 24 de Julio de 2015.

```{r}
datos2015$birthdate <- as.Date(datos2015$birthdate)
#Calculamos la edad
fechaKazan<- as.Date("2015-07-24")
datos2015$edad <- as.numeric(difftime(fechaKazan, datos2015$birthdate, units = "weeks")) %/% 52  # Convertir de semanas a años
```

Además, borramos la variable birthdate:

```{r}
datos2015$birthdate=NULL
```

## Dataframes.

Si visualizamos el dataframe datos2015, observamos por cada prueba de cada nadador, salen n filas que equivalen a los n parciales (de 50m ) en los que constaba la prueba.
Luego, para algunos estudios, usar este dataframe va a suponer duplicar, triplicar e incluso multiplicar por 15 un mismo valor (en el caso de las carreras de 1500m).
Además, no estaríamos haciendo un análisis correcto, puesto que los resultados estarían claramente sesgados hacia los de las distancias más largas.
Por ejemplo, en el caso del tiempo de reacción, los tiempos de los nadadores de 1500 metros se contabilizarían 15 veces.
Mientras que en los nadadores de 50 metros sólo una vez.

A continuación, procedemos a presentar los dataframes que vamos a utilizar dependiendo lo que queramos estudiar:

### Dataframe nadadoresParticipantes.

Utilizaremos este dataframe para realizar análisis sobre el número de nadadores, proporción entre hombres y mujeres, la edad de los participantes, etc.
Es decir, análisis sobre datos que no requieren el conocimiento de la progresión en sus splits.
Para ello, nos bastará con tener la primera fila de cada participante.

Creamos, por tanto, un nuevo dataframe, llamado *nadadoresParticipantes*, el cual constará de todos los participantes sin repetir.
Nos basaremos en la unicidad de la variable athleteid para crearla.

```{r}
nadadoresParticipantes <- datos2015 %>%
  distinct(athleteid, .keep_all = TRUE)

#guardamos una copia de seguridad por si se modifica el dataframe más adelante. 

nadadoresParticipantesCopia<-nadadoresParticipantes
```

```{r}
summary(nadadoresParticipantes)

```

### Dataframe nadadoresPruebas.

Para poder elaborar un estudio de algunas variables como *events*, *reactiontime*, *lane*, *heats* y *daytime*,entre otras cosas, vamos a necesitar un dataframe que refleje a cada nadador y sus pruebas nadadas por filas.

Para poder realizar el dataframe, primero hay que saber si cada prueba, dentro de cada tipo de prueba (preliminar, final, semifinal), tiene un id distinto.

Lo evaluamos seleccionando algún nadador que haya nadado en varias rondas:

```{r}
ejemplo<-datos2015[datos2015$distance == 100 & datos2015$stroke=="BACK" & datos2015$code=="AUS", ]
head(ejemplo,6)
```

Bien, vemos que el australiano nadó tanto las preliminares, como las semifinales como la final y el eventid era distinto entre rondas pero es el mismo en la misma prueba.

```{r, echo=FALSE}
rm(ejemplo)
```

Creamos el siguiente dataframe:

```{r}
nadadoresPruebas <- datos2015 %>%
  distinct(eventid, athleteid, .keep_all = TRUE)

head(nadadoresPruebas,6)

#Copia de seguridad: 
nadadoresPruebasCopia<-nadadoresPruebas
```

Los datos creados, reflejan nadadores y pruebas nadadas por cada uno.

## Estudio sobre el número de nadadores, su género, país y edad.

Usaremos el dataframe nadadoresParticipantes.

Ahora, comenzamos nuestro estudio:

### Edad.

Veamos primeramente un resumen de la edad:

```{r}
summary(nadadoresParticipantes$edad)
```

Observamos que la edad máxima fue de 38 años, la media fue de 21.32 años, y el participante con menos edad fue de 10 años.
Además, el 50% de los participantes estaban entre 19 y 24 años de edad.

Una pregunta razonable sería: ¿El dato relativo al participante de 10 años es un error?

Procedemos a contrastar la información.
De esta forma, podemos ver si de verdad existe este atleta o es un dato mal tomado de nuestra base de datos.
Confirmamos la información, entre otras fuentes, con esta noticia, de la cual añadimos el enlace sobre la joven nadadora de 10 años.
[noticia](https://www.rtve.es/deportes/20150807/nina-10-anos-alzain-tareq-asombra-a-natacion-mundial/1195782.shtml#:~:text=Se%20llama%20Alzain%20Tareq%2C%20tiene,estrella%20medi%C3%A1tica%20de%20la%20jornada.)

Confirmamos mediante su nombre, apellidos y edad, que la noticia se refiere a los datos que tenemos.

```{r}
datos2015[datos2015$edad == 10, ]
```

Se trata de una nadadora de Bahrain que nadó el 50 mariposa y el 50 libres.
Luego podemos concluir que es un dato atípico pero no es erróneo.

De acuerdo con esta nueva variable, vemos cómo se distribuyen las edades.

```{r}
ggplot(nadadoresParticipantes, aes(x = edad)) +
  geom_density(fill = "#0072B2", color = "#0072B2") + # Azul accesible para daltónicos
  ggtitle("Distribución. Edades.")
```

La mayoría de los nadadores parecen tener entre 15 y 25 años, con un pico alrededor de los 20 años.

Esto sugiere que los participantes en la competición están en su mayoría en la etapa juvenil o temprana adultez.

Podríamos preguntarnos si la edad sigue una distribución normal en estos datos, para ello, hacemos uso del test shapiro:

```{r}
shapiro.test(nadadoresParticipantes$edad)
```

El test de shapiro, a priori, nos indica que deberíamos rechazar la hipótesis nula y suponer que no es una normal, aún así, vamos a evaluar de una manera práctica, si podemos suponer su normalidad.
Vamos a realizar 3 evaluaciones para ver si podemos suponer que nuestros datos son normales:

#### Probabilidad de que un nadador tenga más de 29 años:

Para calcular la probabilidad de que un nadador tenga más de 29 años, cuento todos los nadadores que tienen más de 30, y divido sobre el número total de participantes.

```{r}
valor1<- sum(nadadoresParticipantes$edad >=29)/1099
```

#### Calcular media y varianza y calcular la probabilidad Normal.

```{r}
media<-mean(nadadoresParticipantes$edad)
desviacion<-sd(nadadoresParticipantes$edad)

valor2<-1 - pnorm(29, media, sd=desviacion)
```

#### Simular datos de una normal sabiendo media y varianza.

Ahora, simulo datos:

```{r}
datos_simulados <- rnorm(1100, mean = media, sd = desviacion)
## Calculo la probabilidad de 29 o más: 

conteo_mayores_que_29 <- sum(datos_simulados >= 29)

valor3<- conteo_mayores_que_29/1100
```

A continuación, comparo los tres valores obtenidos:

```{r}
valor1
valor2
valor3
```

Y veo que es una diferencia de 0.017 entre el mayor y el menor valor, luego, vamos a suponer la normalidad de nuestros datos.

```{r}
rm(conteo_mayores_que_29, datos_simulados, desviacion, media, valor1, valor2, valor3)
```

Observo que hay una variación de 0.014 entre las probabilidades, al ser una probabilidad tan baja, podríamos asumir normalidad en nuestros datos.

### Análisis de géneros participantes

Veamos el número exacto de mujeres y hombres en la competición:

```{r}
summary(nadadoresParticipantes$gender)
```

Luego, hay 608 hombres y 491 mujeres que participaron en los mundiales de Kazán 2015.

Veamos ahora cómo se distribuyen los hombres y las mujeres y sus respectivas edades:

```{r, warning=FALSE}
ggplot(nadadoresParticipantes, aes(x = edad, colour = gender, linetype = gender)) +
    geom_density(size = 1.2) +  # Aumentar el grosor de las líneas
    scale_color_viridis_d(option = "D", begin = 0.2, end = 0.8) +  # Colores accesibles para daltonismo
    scale_linetype_manual(values = c("solid", "dashed")) +  # Líneas sólidas y punteadas
    theme_minimal() +  # Tema limpio y claro
    labs(
        title = "Densidades de Edad por Género",
        x = "Edad",
        y = "Densidad",
        colour = "Género",
        linetype = "Género"
    )
```

Según observamos, la distribución está ligeramente desplazada a la derecha para los hombres, esto indica que los hombres tienden a ser mayores en promedio que las mujeres.
Esta diferencia en la distribución de edades entre los géneros nos conduce a realizar distintos test estadísticos para confirmar si la diferencia realmente es significativa.

#### Hipótesis:

-   H0: Las medias de los dos grupos son iguales.

-   H1: Las medias de los dos grupos son distintas.

```{r}
t.test(edad~gender,data=nadadoresParticipantes)

```

Hemos comparado las medias de edad entre mujeres (grupo F) y hombres (grupo M), tomando como hipótesis nula que las medias de edad entre mujeres y hombres son iguales, y cómo hipótesis alternativa que las medias de edad entre mujeres y hombres son diferentes.
Aunque el resultado del t-test muestra que hay una diferencia estadísticamente significativa (el p-valor es muy pequeño) entre las edades medias de hombres y mujeres (aproximadamente 1.16 años), en términos prácticos, esta diferencia es relativamente pequeña.
En este caso, puede no ser relevante en términos de la experiencia o desempeño de los nadadores.

No obstante, proseguimos en nuestro análisis exploratorio.

```{r}
tabla1<-table(nadadoresParticipantes$edad>30,nadadoresParticipantes$gender)
chisq.test(tabla1)
```

Por el resultado del siguiente test aplicado, podemos concluir con que **no hay asociación significativa**: Dado que el p-valor es 0.47, entre ser mayor de 30 años y el género de los nadadores en nuestros datos.
En términos sencillos,la edad no parece estar relacionada con el género de los nadadores en cuanto a si son mayores de 30 años.

```{r}
tabla2<-table(nadadoresParticipantes$edad<20,nadadoresParticipantes$gender)
chisq.test(tabla2)
```

Hay una diferencia considerable entre las frecuencias observadas (cuántos hombres y mujeres son menores de 20 años) y las frecuencias esperadas bajo la hipótesis nula (que no hay asociación entre edad y género para menores de 20 años).
Esto sugiere ir un paso más allá, **¿Hay más mujeres menores de edad que hombres menores de edad?**

```{r}
tabla3<-table(nadadoresParticipantes$edad<18,nadadoresParticipantes$gender)
chisq.test(tabla3)
```

Los resultados sugieren que el género y la minoría de edad si que están significativamente relacionados en nuestro conjunto de datos de nadadores.
Esto podría tener implicaciones para el análisis del rendimiento y la participación en competiciones.

Veamos números,

```{r}
tabla3

#Calcular los totales
totales <- colSums(tabla3)

#Calcular el porcentaje de nadadores menores de 18 años por género
porcentajes <- (tabla3[2, ] / totales) * 100  
# fila 2 son los menores de 18

porcentajes
```

De esta forma, ya habiendo confirmado una diferencia significativa.
Podemos ver, de manera más representativa, como existe el doble de proporción de mujeres menores de edad en comparación con los hombres.
Dicho en otras palabras, *2 de cada 10 mujeres son menores de 18 años, mientras que esto sólo ocurre en 1 de cada 10 hombres*:

```{r}

porcentajes <- c(10.88, 21.66)  # 10% para hombres y 20% para mujeres
generos <- c("Hombres", "Mujeres")

porcentajes<- as.data.frame(porcentajes)
#generos<- as.data.frame(generos)

# Crear el gráfico con colores accesibles
ggplot(porcentajes, aes(x = generos, y = porcentajes, fill = generos)) +
  geom_bar(stat = "identity", width = 0.6) +  # Barras con ancho ajustado
  geom_text(aes(label = paste0(porcentajes, "%")), vjust = -0.5, size = 5) +  # Mostrar los porcentajes
  labs(
    title = "Porcentaje de Nadadores Menores de 18 Años por Género",
    x = "Género",
    y = "Porcentaje"
  ) +
  scale_fill_viridis_d(option = "C", begin = 0.2, end = 0.8) +  # Colores accesibles
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),  # Centrar el título
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "none"  # Ocultar la leyenda
  ) +
  ylim(0, 100)  # Ajustar el límite del eje Y
```

```{r, echo=FALSE, warning=FALSE}

#elimino las cosas creadas para no interferir luego. 

rm(tabla1,tabla2, tabla3, generos, porcentajes, totales, datos_porcentajes)

```



## Análisis de nacionalidades. 


## Estudio sobre los eventos, reactiontime, lane, heats, daytime:

### Reactiontime.

Veamos cómo se distribuyen los datos de tiempo de reacción de todos los nadadores.
Para ello, no tenemos en cuenta las dos filas con datos nulos.

```{r}
ggplot(na.omit(nadadoresPruebas), aes(x = reactiontime)) +
  geom_density(color = viridis(1, option = "C"), fill = viridis(1, option = "C", alpha = 0.5), size = 1.2) +
  ggtitle("Distribución de Reaction Time") +
  labs(x = "Tiempo de Reacción", y = "Densidad") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centrar y resaltar el título
    axis.title = element_text(size = 14),  # Aumentar tamaño de etiquetas de los ejes
    axis.text = element_text(size = 12)  # Aumentar el tamaño de los valores de los ejes
  )

```

Parece que los datos siguen una distribución normal a priori.
Igual que antes, vamos a hacer el test de shapiro:

```{r}
shapiro.test(na.omit(nadadoresPruebas$reactiontime))
```

Al tener un p-valor tan bajo, no parece que siga una distribución normal. Aún así, este test puede ser erróneo al tener tantos datos. Vamos a proceder de maenra análoga a como lo hacíamos con la edad. Vamos a ver si la densidad de este gráfico es igual o parecido a una normal haciendo las siguientes comparaciones. 

#### Probabilidad de que un nadador tenga un reactiontime mayor a 0.8.

Primeramente, voy a calcular cuántas filas de nadadoresPruebas tienen un tiempo de 0.8 o mayor sobre el total. Esto, obviamente nos da la probabilidad de reactiontime>0.8 en nuestros datos: 

```{r}
valor1<- sum(na.omit(nadadoresPruebas$reactiontime) >0.8)/2804
```

Bien, ahora, voy a calcular la media y desviación típica de que sigue Reactiontime. Voy a suponer que sigue una distribución normal y voy a calcular su probabilidad teórica. 
```{r}
media<-mean(na.omit(nadadoresPruebas$reactiontime))
desviacion<-sd(na.omit(nadadoresPruebas$reactiontime))

valor2<-1 - pnorm(0.8, media, sd=desviacion)
```

Por último, voy a simular 2804 datos de una normal con la media y desviación típica calculada anteriormente y vamos a ver cuál es la probabilidad de que los datos simulados valgan más de 0.8: 

```{r}
datos_simulados <- rnorm(2804, mean = media, sd = desviacion)

conteo <- sum(datos_simulados > 0.8)

valor3<- conteo/2804
```


Bien, veo los valores obtenidos: 
```{r}
valor1
valor2
valor3
```

Observo que, la diferencia es de menos de 0.01 entre el menor y el mayor valor, luego, podremos suponer que la variable reactiontime sigue una distribución normal. 


```{r, echo=FALSE}
rm(conteo, datos_simulados, desviacion, media, valor1, valor2, valor3)
```



### Reactiontime. Hombres vs Mujeres.

Comparamos las funciones de densidad de mujeres y hombres en general:

```{r message=FALSE, warning=FALSE}
nadadoresPruebas <- nadadoresPruebas %>% filter(!is.na(nadadoresPruebas$reactiontime))
ggplot(nadadoresPruebas, aes(x = reactiontime, colour = gender, linetype = gender)) +
  geom_density(size = 1.2) +
  scale_color_viridis_d(option = "C", begin = 0.3, end = 0.7) +  # Colores accesibles
  scale_linetype_manual(values = c("solid", "dashed")) +  # Líneas sólidas y punteadas
  labs(
    title = "Distribución del Tiempo de Reacción por Género",
    x = "Tiempo de Reacción",
    y = "Densidad",
    colour = "Género",
    linetype = "Género"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centrar el título
    axis.title = element_text(size = 14),  # Tamaño de las etiquetas de los ejes
    axis.text = element_text(size = 12),  # Tamaño de los valores de los ejes
    legend.position = "top",  # Ubicar la leyenda en la parte superior
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 11)
  )
```

De esta gráfica nos podemos plantear realizar un contraste de hipótesis, en el cual analizaremos sobre la posible diferencia significativa del tiempo de reacción en ambos géneros.
Por tanto, realizamos el siguiente test:

-   H0: El tiempo de reacción es igual en mujeres y hombres.
-   H1: El tiempo de reacción es menor en hombres que en mujeres.

```{r}
t.test(reactiontime~gender,data=nadadoresParticipantes)
```

Si observamos los resultados, el p- valor nos indica que hay una evidencia significativa para rechazar la hipótesis nula, y por ende concluir con que hay una diferencia estadística en el tiempo de reacción dependiendo del género.
Ahora que hemos determinado que la diferencia es estadísticamente significativa, es importante considerar si la diferencia es también significativa en la práctica o si tiene relevancia a la hora de los resultados finales.
Calculamos la diferencia relativa, ya que los tiempos de reacción son muy pequeños y de esta forma nos podemos hacer una idea de lo representativa que es la diferencia de medias.

```{r}
mediaTiempoReaccion <- mean(nadadoresPruebas$reactiontime)
mediaTiempoReaccion
(0.7166871-0.6922862)/mediaTiempoReaccion*100
```

Obtenemos que las mujeres tardan un 3.5% más de tiempo que los hombres.
Es decir que, si mantenemos en igualdad todas las demás variables, si un hombre tarda 22 segundos en un 50, una mujer tardará 3.5% más de tiempo, es decir, 22.77 segundos.
Una diferencia **significativamente** grande si hablamos de una prueba tan corta.


### Reactiontime. Distancias largas vs distancias cortas.

Vamos a comparar ahora las funciones de densidad de las chicas en la prueba de 800m libres y 50m libres:

Primeramente calculamos el conjunto de datos:

```{r}
nadadorasComparacionReactionTime<-nadadoresPruebas[(nadadoresPruebas$distance==50 | nadadoresPruebas$distance==800) & nadadoresPruebas$gender=="F" , ]

```


```{r}

ggplot(nadadorasComparacionReactionTime, aes(x = factor(distance), y = reactiontime, fill = factor(distance))) +
  geom_boxplot(alpha = 0.7, size = 1.2, outlier.shape = 16, outlier.size = 4) +  # Mejorar visibilidad de los outliers
  scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8) +  # Usar colores accesibles de viridis
  labs(
    title = "Boxplot de Tiempo de Reacción: 50m vs 800m",
    x = "Distancia (m)",
    y = "Tiempo de Reacción"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centrar y resaltar el título
    axis.title = element_text(size = 14),  # Etiquetas de los ejes más grandes
    axis.text = element_text(size = 12),  # Etiquetas del eje
    legend.position = "none"  # Ocultar leyenda ya que está implícita en las etiquetas
  )
```

El gráfico muestra los boxplots del tiempo de reacción para la prueba de 50 metros y otra para 800 metros.

```{r}
ggplot(nadadorasComparacionReactionTime, aes(x = reactiontime, fill = factor(distance), group = distance)) +
  geom_density(alpha = 0.6, size = 1.2) +  # Curvas semi-transparentes con líneas más gruesas
  scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8) +  # Colores accesibles con viridis
  ggtitle("Distribución del Tiempo de Reacción: 800m vs 50m Libre") +
  labs(fill = "Distancia (m)") +  
  theme_minimal() +  
  xlab("Tiempo de Reacción (s)") +  
  ylab("Densidad") +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centrar y resaltar el título
    axis.title = element_text(size = 14),  # Etiquetas de los ejes más grandes
    axis.text = element_text(size = 12),  # Etiquetas del eje
    legend.position = "top"  # Colocar la leyenda en la parte superior
  )
```

Las curvas se encuentran en un rango de aproximadamente 0.5 a 1 segundos, que representa los tiempos de reacción.
Para los 50 metros, la densidad es más alta en el rango de tiempos de reacción más cortos, lo que indica que las nadadoras tienden a tener tiempos de reacción más rápidos en esta distancia.
Esto es esperado, ya que la carrera de 50 metros es más corta y requiere reacciones más rápidas y explosivas.
En cuanto a la de 800 metros, la curva muestra una mayor dispersión en los tiempos de reacción, con una densidad más amplia.
Esto sugiere que los tiempos de reacción son más variados en esta distancia, probablemente debido a la naturaleza más larga y estratégica de la carrera, donde el triunfo de las nadadoras puede estar influenciado por otras variables más determinantes.

Aquí también podemos hacer un test de hipótesis.

```{r}
t.test(reactiontime~distance,data=nadadorasComparacionReactionTime)
```

Veamos nuestros resultados del test.
Por un lado tenemos el valor del estadístico t calculado, como es un valor negativo indica que la media del primer grupo (50 metros) es menor que la del segundo grupo (800 metros).El valor del p-valor (que es extremadamente bajo) indica que hay una diferencia estadísticamente significativa entre las medias de los dos grupos.
Las nadadoras que participan en distancias más cortas (50 metros) tienen un tiempo de reacción más rápido en comparación con aquellas que nadan distancias más largas (800 metros).Luego, habíamos identificado correctamente la tendencia del gráfico, en términos estadísticos.

A continuación, realizamos el mismo estudio pero con hombres y vemos si la situación es similar.

```{r}
nadadoresComparacionReactionTime<-nadadoresPruebas[(nadadoresPruebas$distance==50 | nadadoresPruebas$distance==800) & nadadoresPruebas$gender=="M", ]
```

```{r}
ggplot(nadadoresComparacionReactionTime, aes(x = factor(distance), y = reactiontime, fill = factor(distance))) +
  geom_boxplot() +
  labs(title = "Boxplot de Reaction Time: 50m vs 800m en hombres",
       x = "Distancia (m)",
       y = "Tiempo de Reacción") +
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  
  theme_minimal()

# Crear el gráfico de densidad con colores por distancia
ggplot(nadadoresComparacionReactionTime, aes(x = reactiontime, fill = factor(distance), group = distance)) +
  geom_density(alpha = 0.6) +  #curvas 
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  
  ggtitle("Distribución del Tiempo de Reacción: 800m libre vs 50m en hombres") +
  labs(fill = "Distancia (m)") +  
  theme_minimal() +  
  xlab("Tiempo de Reacción (s)") +  
  ylab("Densidad")

```

```{r}
t.test(reactiontime~distance,data=nadadoresComparacionReactionTime)
```

Al realizar el t-test para este grupo, vemos también como la diferencia es significativa entre el tiempo de reacción para la prueba de 50 metros y la de 800.

La diferencia entre estos dos extremos en las pruebas es muy significativa.
Dados estos resultados, queremos ver las tendencias en las carreras de distancia intermedia, dada nuestra intuición de que el tiempo de reacción aumente de manera gradual.
Es decir, cuál es la diferencia entre las pruebas de 50 metros, las de 100, 200, etc.

Para ello, realizaremos un gráfico de densidad conjunto.

```{r}
ggplot(nadadoresPruebas, aes(x = reactiontime, color = as.factor(distance), fill = as.factor(distance))) +
  geom_density(alpha = 0.3) +  # Ajustar la transparencia
  ggtitle("Distribución comparada de Reaction time") +
  labs(x = "Tiempo de Reacción", y = "Densidad", color = "Distancia", fill = "Distancia") +
  theme_minimal()
```

Como podemos observar, nuestras suposiciones parecen ser ciertas acerca de que las medias de los tiempos de reacción aumentan según la carrera es más larga.
Si bien es cierto, para distancias largas, como son 800 y 1500 metros, no se observan diferencias en torno a su valor central.
Del mismo modo, para carreras de 100 y 200 tampoco se observa una diferencia signifiticativa.

Contrastamos esto de forma más precisa realizando el test ANOVA de diferencia de medias.

```{r}
anova_tiempoReaccion_distancia <- aov(reactiontime ~ as.factor(distance), data = na.omit(nadadoresPruebas))
summary(anova_tiempoReaccion_distancia)
```

Interpretando estos resultados, tenemos que el p-valor es de orden e\^-16.
Por ello, podemos concluir que hay diferencias significativas en los tiempos de reacción entre al menos uno de los grupos de distancia.
Esto indica que, al menos una distancia tiene un tiempo de reacción diferente en comparación con las otras distancias.
El valor de F es alto (56.98), sugiere que la variación entre los grupos es mucho mayor que la variación dentro de los grupos.
Esto refuerza la idea de que las medias de los tiempos de reacción son significativamente diferentes entre las carreras de diferente distancia.

```{r, echo=FALSE}
rm(anova_tiempoReaccion_distancia, nadadorasComparacionReactionTime, nadadoresComparacionReactionTime, mediaTiempoReaccion)

#restauro nadadoresPruebas para el siguiente estudio: 
nadadoresPruebas<-nadadoresPruebasCopia

```

### Calles usadas.

Veamos cómo se distribuyen las calles usadas:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = nadadoresPruebas$lane, fill = factor(lane))) + 
  geom_bar() +
  scale_fill_viridis_d(option = "D") + # Paleta Okabe-Ito
  theme_bw() +
  labs(fill = "Lane") # Etiqueta para la leyenda

```

Se observa que las calles menos usadas son tanto la 0 como la 9.
Esto es un dato que puede resultar curioso al visualizar los datos, pero tiene una clara explicación.

Las calles 0 y 9 sólo son usadas en las rondas preliminares.
Además, las series de cada prueba se confeccionan rellenando de mejor a peor tiempo con el siguiente orden: 4-5-3-6-2-7-1-8-0-9.
Luego, es obvio que si en una prueba tengo 18 nadadores, una serie ocupará todas las calles, pero otra ocupará sólo 8, luego las calles 0 y 9 quedarán libres.

¿Habrá alguna relación entre la calle usada y el tiempo de reacción?

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = reactiontime, color = factor(lane), fill = factor(lane))) +
  geom_density(alpha = 0.6) + # Densidades con transparencia
  facet_wrap(~ lane) +        # Facetas por lane
  theme_bw() +
  labs(
    title = "Distribución de Densidades de Tiempos de Reacción por Calle",
    x = "Tiempo de Reacción",
    y = "Densidad",
    color = "Lane", 
    fill = "Lane"
  ) +
  scale_fill_viridis_d(option = "D") +  # Paleta daltónica para relleno
  scale_color_viridis_d(option = "D")  # Paleta daltónica para bordes
```

Como podemos ver, no parece haber diferencias significativas según el tipo de calle en los tiempos de reacción.

De nuevo, podemos realizar un test anova sobre la diferencia de medias.

```{r}
anova_tiempoReaccion_Calles <- aov(reactiontime ~ as.factor(lane), data = na.omit(nadadoresPruebas))
summary(anova_tiempoReaccion_Calles)
```

El p-valor de nuestro análisis es menor de 0.005, por lo que podríamos sugerir que sí tiene cierta influencia según el número de calle empleada.
Sin embargo, existen muchas variables en nuestro conjunto de datos que podrían influir, por lo que no tiene sentido seguir con este estudio.

### Daytime.

Si observamos los valores que toma la variable Daytime, observamos que toma valores numéricos de 3 y 4 cifras.
Parece corresponder a la hora y minutos en la que cada nadador nadó la prueba.
Luego vamos a cambiar su formato para intentar sacar conclusiones acerca de esta variable:

```{r}
# Función para convertir
convertir_a_hhmm <- function(tiempo_numerico) {
  # Convertir el número a un string y separar horas y minutos
  horas <- tiempo_numerico %/% 100
  minutos <- tiempo_numerico %% 100
  
  # Crear un objeto de tiempo en formato hh:mm
  tiempo_formateado <- sprintf("%02d:%02d", horas, minutos)
  return(tiempo_formateado)
}

# Aplicar la función a todos los tiempos
tiempos_hhmm <- sapply(nadadoresPruebas$daytime, convertir_a_hhmm)
head(tiempos_hhmm)

```

Bien, ya hemos convertido esos números de 3 y 4 cifras a un formato hora/minutos.
Ahora, lo representamos en una gráfica:

```{r}
# Crear la columna 'tiempo_hhmm'
nadadoresPruebas$tiempo_hhmm <- sapply(nadadoresPruebas$daytime, convertir_a_hhmm)

# Convertir la nueva columna 'tiempo_hhmm' a formato POSIXct
nadadoresPruebas$tiempo_hhmm <- as.POSIXct(nadadoresPruebas$tiempo_hhmm, format = "%H:%M")

# Creo la gráfica.
ggplot(nadadoresPruebas, aes(x = tiempo_hhmm)) +
  geom_histogram(
    binwidth = 3600, 
    color = "black", 
    fill = viridis(1, option = "D")  # Paleta daltónica
  ) +
  scale_x_datetime(date_labels = "%H:%M", breaks = "1 hour") +  # Etiquetas cada hora
  labs(
    x = "Tiempo (hh:mm)",
    y = "Frecuencia de nadadores"
  ) +
  theme_minimal()
```

Luego, podemos observar de manera clara que, cada día de competición constaba de 2 sesiones, una matinal y otra vespertina, y que las franjas horarias van, por la mañana de 9:30 a 12:30, y por la tarde de 17:30 a 19:30.

#### Pruebas matinales y vespertinas.

Observamos que el número de nadadores que nadan por la mañana es mucho mayor al de por la tarde.

Vamos a ver un resumen de qué pruebas se nadan por la mañana y cuáles por la tarde:

```{r}
nadadoresPruebas$tiempo_hhmm<- as.POSIXct(nadadoresPruebas$tiempo_hhmm, format = "%H:%M")
#intervalo para las matinales
limite_inferior1 <- as.POSIXct("09:30", format = "%H:%M")
limite_superior1 <- as.POSIXct("13:00", format = "%H:%M")
#intervalo para las vespertinas
limite_inferior <- as.POSIXct("17:00", format = "%H:%M")
limite_superior <- as.POSIXct("20:00", format = "%H:%M")
#Creamos los dataframes.
pruebasMatinales<-subset(nadadoresPruebas, nadadoresPruebas$tiempo_hhmm >= limite_inferior1 & nadadoresPruebas$tiempo_hhmm <= limite_superior1)

pruebasVespertinas<-subset(nadadoresPruebas, nadadoresPruebas$tiempo_hhmm >= limite_inferior & nadadoresPruebas$tiempo_hhmm <= limite_superior)
```

Bien, dividida ya nuestras pruebas en la sesion matinal y la vespertina, veamos un resumen de los datos:

```{r}
dim(pruebasMatinales)
dim(pruebasVespertinas)
```

De aquí observamos que, mientras que por las mañanas se nada un 75% de las pruebas del mundial, por las tardes sólo se nada un 25%.
Veamos si hay alguna variable que nos pueda ayudar:

```{r}
print("Resumen de rondas nadadas en sesiones matinales.")
summary(pruebasMatinales$round)
print("Resumen de rondas nadadas en sesiones vespertinas.")
summary(pruebasVespertinas$round)
```

Luego podemos concluir que, el formato que sigue el mundial de Kazán 2015 es, nadar por las mañanas las series preliminares de cada prueba, mientras que por las tardes sólo nadan los nadadores clasificados a semifinales y finales.

```{r, echo=FALSE}
rm(limite_inferior, limite_inferior1, limite_superior, limite_superior1, tiempos_hhmm, convertir_a_hhmm,pruebasMatinales, pruebasVespertinas, anova_tiempoReaccion_Calles)

nadadoresPruebas<-nadadoresPruebasCopia
```


## Estudio sobre la variable distancia y su asociación con los tipos de nado.

A continuación, nos preguntamos, ¿existen pruebas por cada estilo y cada distancia?
Es decir, al haber 5 estilos y 6 distancias, ¿hay 30 pruebas distintas?
Vamos a responder a la pregunta analizando el dataframe nadadoresPruebas:

Para analizar la relación entre las distancias y los estilos de nado en este conjunto de datos, examinaremos cómo se distribuyen los distintos estilos (BACK, BREAST, FLY, FREE, MEDLEY) en función de la distancia recorrida en metros (50, 100, 200, 400, 800, 1500).

```{r}
distancia_stroke <- table(nadadoresPruebas$distance, nadadoresPruebas$stroke)
print(distancia_stroke)

```

A partir de la tabla proporcionada, se observa lo siguiente:

-   En 50 y 100 metros, se nadan 4 estilos.
    (BACK, BREAST, FLY, FREE).
    No se nada MEDLEY ya que, al ser un mundial en piscina de 50m, no podemos cumplir que se nade como mínimo un largo a cada estilo, ya que en estas pruebas sólo se nada 1 o 2 largos en total.

-   En las pruebas contempladas para 200m, entran los 5 estilos.
    (BACK, BREAST, FLY, FREE).

-   En la distancia de 400m, sólo hay 2 pruebas.
    400m Medley y 400m Free.

-   En 800 y 1500m, sólo hay 1 prueba respectivamente, cuyo estilo (stroke) es libre (FREE)

Estas conclusiones se ven muy claras en el siguiente gráfico: 

```{r}
ggplot(nadadoresPruebas, aes(x = factor(distance), y = stroke)) +
  geom_count(aes(color = ..n.., size = ..n..)) +  # Color y tamaño según la frecuencia
  scale_color_viridis_c(option = "D") +          # Paleta continua para daltónicos
  labs(
    x = "Distancia",
    y = "Estilo de Nado",
    size = "Frecuencia",
    color = "Frecuencia"
  ) +
  ggtitle("Frecuencia de Estilos de Nado según la Distancia") +
  theme_minimal()
```

Además, podemos observar que contra más larga es la prueba, menos frecuencia tiene, es decir, menos nadadores participan. Esto tiene sentido ya que, si participasen los mismos nadadores en una prueba de 50 metros que en una de 1500, entonces las sesiones durarían todo el día o incluso habría que extender los días que comprenden el mundial. 


Ahora nos preguntamos, ¿hay las mismas pruebas para mujeres y hombres?

Primero, crearemos subconjuntos de datos para cada género.

```{r}
# Filtrar los datos por género
nadadoresFemeninas <- subset(nadadoresPruebas, gender == "F")
nadadoresMasculinos <- subset(nadadoresPruebas, gender == "M")
```

```{r}
#género femenino
nadadorasPruebas<- nadadoresPruebas[nadadoresPruebas$gender=="F", ]

ggplot(nadadorasPruebas, aes(x = factor(distance), y = stroke)) +
  geom_count(aes(color = ..n.., size = ..n..)) +  # Color y tamaño según la frecuencia
  scale_color_viridis_c(option = "D") +          # Paleta continua para daltónicos
  labs(
    x = "Distancia",
    y = "Estilo de Nado",
    size = "Frecuencia",
    color = "Frecuencia"
  ) +
  ggtitle("Frecuencia de Estilos de Nado según la Distancia para Mujeres") +
  theme_minimal()

nadadoresPruebasM<- nadadoresPruebas[nadadoresPruebas$gender=="M", ]

ggplot(nadadoresPruebasM, aes(x = factor(distance), y = stroke)) +
  geom_count(aes(color = ..n.., size = ..n..)) +  # Color y tamaño según la frecuencia
  scale_color_viridis_c(option = "D") +          # Paleta continua para daltónicos
  labs(
    x = "Distancia",
    y = "Estilo de Nado",
    size = "Frecuencia",
    color = "Frecuencia"
  ) +
  ggtitle("Frecuencia de Estilos de Nado según la Distancia para Hombres") +
  theme_minimal()

```

Parece que todo está funcionando como esperábamos, tanto en el análisis conjunto como en los análisis individuales.
Esto confirma que los resultados son consistentes y los datos están bien estructurados para las pruebas. 


```{r, echo=FALSE}
rm(nadadorasPruebas, nadadoresPruebasM, distancia_stroke, nadadoresFemeninas, nadadoresMasculinos)

```



## Estudio sobre la relación entre la edad de los nadadores y las distancias que nadan.

A continuación, vamos a tratar de estudiar si existe algún tipo de relación entre la edad que tienen los nadadores y las pruebas que nadan. Para ello, voy a clasificar en 4 grupos: 
-   Grupo 1: Menores de 18. 
-   Grupo 2: Entre 19 y 24 años.
-   Grupo 3: Entre 25 y 29 años. 
-   Grupo 4: Mayores de 30 años.

Para ello, vamos a crear una nueva variable en nuestro dataframe nadadoresPruebas: 

```{r}
nadadoresPruebas$grupo_edad <- cut(
  nadadoresPruebas$edad,
  breaks = c(-Inf, 18, 24, 29, Inf),
  labels = c(1, 2, 3, 4),
  right = FALSE
)

```

Bien, una vez creada la nueva variable, ahora voy a construir una tabla que, para cada distancia, ponga el número de nadadores que nada esa prueba. 

```{r}
# Contar el número de nadadores en cada grupo de edad y distancia
tabla_grupos <- nadadoresPruebas %>%
  group_by(grupo_edad, distance) %>%
  summarise(num_nadadores = n(), .groups = 'drop')

# Convertir a una tabla de contingencia para que los grupos de edad sean filas y las distancias columnas
tabla_final <- tidyr::pivot_wider(tabla_grupos, names_from = distance, values_from = num_nadadores, values_fill = list(num_nadadores = 0))

# Ver la tabla resultante
print(tabla_final)
```

Vamos ahora a calcular en porcentaje sobre el total de cada grupo, el porcentaje de nadadores que nadan cada prueba agrupado por grupo de edad. Para ello: 

```{r}
# Calcular el total de nadadores por grupo de edad
total_por_grupo <- rowSums(tabla_final[, -1])

# Calcular el porcentaje y añadirlo a la tabla
tabla_porcentajes <- tabla_final %>%
  mutate(across(-grupo_edad, ~ . / total_por_grupo[grupo_edad] * 100))

# Ver la tabla de porcentajes
print(tabla_porcentajes)
```

Si observo esta tabla, puedo ver que, los menores de 18 años nadan en general más pruebas de 50 y 100 metros. En las edades medias, hay una distribución muy igual para las pruebas tanto de 50, 100 y 200 metros. 

A continuación, vamos a evaluar el porcentaje de nadadores de cada grupo por prueba compardo con los nadadores totales que hubo en dicha prueba. Es decir, la siguiente gráfica: 

```{r}
# Calcular los porcentajes de cada columna sobre la suma total de la columna
tabla_porcentajes2 <- tabla_grupos %>%
  group_by(distance) %>%
  mutate(
    porcentaje_columna = (num_nadadores / sum(num_nadadores)) * 100  # Porcentaje sobre la suma de la columna
  ) %>%
  ungroup()

# Ver la tabla resultante con los porcentajes por columna
print(tabla_porcentajes2)
```

Aquí, observamos que sobre el total de nadadores, la distancia que menos nada el grupo 1 es el 200. Sobre el total, las pruebas que en porcentaje nadan menos el grupo 2 son los 50 y los 100.El grupo 3, tiende a nadar pruebas más cortas en lugar de largas. Y el último grupo también. 

Luego, podríamos concluir que la distribución para los menores de 18 años es bastante simétrica, es decir, son aptos para nadar cualquier tipo de prueba. Para los del grupo 2, nadan en menos proporción pruebas explosivas como el 50 y 100 y es más frecuente verlos en distancias un poco mayores, esto es razonable ya que el pico de rendimiento en los nadadores se alcanza en las edades de este segundo grupo, luego están más y mejor preparados para nadar distancias más largas. Para el grupo 3 y 4, las distancias largas y de resistencia ya no son pruebas en las que destaquen (en general), por ello, tienden a ser nadadores que nadan pruebas cortas. 




```{r, echo=FALSE}
rm(tabla_final, tabla_grupos, tabla_porcentajes, tabla_porcentajes2,total_por_grupo)

nadadoresPruebas<-nadadoresPruebasCopia

```



## Estudio sobre la variable round.

A continuación, vamos a intentar entender más sobre la variable ronda.
Para ello, primero vemos un resumen:

```{r}
summary(datos2015$round)
```

Observamos que toma 5 posibles valores, tenemos controlados tanto FIN (final), como PRE (preliminar) y SEM (semifinal).
Pero SOP y SOS no parece tan claro saber qué es.
Vamos a comenzar dejando de lado SOP y SOS, nos vamos a centrar en controlar los otros 3 valores.

### ¿Cuántos nadadores nadan cada ronda?

Una pregunta natural podría ser, ¿cuántos nadadores pasan de ronda?
¿Todos?
Está claro que al ver que por la mañana en preliminares nadan el 75% y por las tardes son semifinales y finales y son un 25%.
Veamoslo con distintas pruebas:

#### 50 libre femenino:

Seleccionamos las nadadoras que nadaron preliminares en el 50 libre femenino:

```{r}
free50PrelimWomens<- nadadoresPruebas[nadadoresPruebas$round=="PRE" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]

head(free50PrelimWomens,10)
```

Ahora, vamos a hacer el ranking de resultados de esta prueba, para ello:

```{r}
free50PrelimWomens<-free50PrelimWomens[order(free50PrelimWomens$swimtime), ]

dim(free50PrelimWomens)
```

Observamos que hubo 119 nadadoras que nadaron las preliminares del 50 libres.
Veamos ahora cuántas nadaron las semifinales:

```{r}
free50SemisWomens<-nadadoresPruebas[nadadoresPruebas$round=="SEM" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]
```

Antes de ordenarlas, veamos cuántas filas tengo en mi nuevo data frame:

```{r}
dim(free50SemisWomens)
```

Es decir, de 119, sólo se clasificaron 16.
Veamos si fueron las 16 primeras.
Para ello, voy a coger las 16 primeras de las prelims, voy ahora a ordenarlas por athleteid, y hacer lo mismo con las de las semifinales, a ver si coincide:

```{r}
free50PrelimWomens<-head(free50PrelimWomens, 16)

#Ordeno: 

free50PrelimWomens<-free50PrelimWomens[order(free50PrelimWomens$athleteid), ]
free50SemisWomens<-free50SemisWomens[order(free50SemisWomens$athleteid), ]

free50PrelimWomens
free50SemisWomens

```

Luego, podemos observar claramente que, las 16 primeras de las preliminares, consiguieron clasificarse a las semifinales.
Hagamos el mismo trabajo con el dataframe *free50SemisWomens* para ver cuántas nadadoras se clasificaron en la final:

```{r}
free50SemisWomens<-free50SemisWomens[order(free50SemisWomens$swimtime), ]

```

Al igual que antes, confeccionamos el dataframe de la final:

```{r}
free50FinalWomens<-nadadoresPruebas[nadadoresPruebas$round=="FIN" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]

dim(free50FinalWomens)
```

Observamos que hay 8, luego las 8 primeras se clasificaron a la final.

### ¿Se nadan las 3 rondas en cada prueba?

Esta cuestión nos surge ya que, algunas pruebas requieren más esfuerzo y el tiempo de descanso para la recuperación total es más largo, por ello alomejor hay pruebas en las que sólo hay 1 ronda, o 2, o esta suposición es falsa y en cada prueba se nadan 3 rondas.
Para ello, echemos un cálculo inicial.
Hay 2 géneros, pruebas de 50, 100, 200, 400, 800 y 1500 metros.
Veamos qué valores toman las rondas en cada una de estas pruebas.
Para ello:

```{r}
print("Rondas que se nadan en las pruebas de 50 metros: ")
summary(nadadoresPruebas[nadadoresPruebas$distance==50, ]$round)
print("Rondas que se nadan en las pruebas de 100 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==100, ]$round)
print("Rondas que se nadan en las pruebas de 200 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==200, ]$round)
print("Rondas que se nadan en las pruebas de 400 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==400, ]$round)
print("Rondas que se nadan en las pruebas de 800 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==800, ]$round)
print("Rondas que se nadan en las pruebas de 1500 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==1500, ]$round)
```

Luego, observamos que en las pruebas de 400, 800 y 1500 metros no hay semifinales, tan sólo una ronda preliminar y una ronda final.

También podemos sacar conclusiones gracias al estudio hecho en el apartado anterior.
En los 50 por ejemplo, hay 128 nadadores que nadan semifinales, hay dos géneros, luego 64 nadadores por género nadaron semifinales, además, hay 4 estilos, luego 16 nadadores nadaron las semifinales de cada prueba, lo cual concuerda con lo visto anteriormente.

Destaca a la vista que, en las pruebas de 200 metros, hay más nadadores.
¿Por qué sucede esto?.
Veamos:

```{r}
print("Estilos que se nadan en pruebas de 50 metros: ")
summary(nadadoresPruebas[nadadoresPruebas$distance==50, ]$stroke)
print("Estilos que se nadan en pruebas de 200 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==200, ]$stroke)
```

Hay más nadadores que nadan semifinales puesto que hay 5 pruebas, no 4.
Si echamos los cálculos, 160/(2\*5)=16 nadadores, igual que en las demás.

Se puede ver de manera análoga que nadan 8 nadadores cada final.

Ahora, ya que hemos analizado a fondo qué sucede con las finales, semifinales y preliminares, vamos a ver qué significan los otros dos valores que toma la variable *round*.

### Rondas SOP

Bien, primeramente, vamos a observar las filas tales que toman ese valor.
Lo hacemos de la siguiente manera:

```{r}
datosSOP<-datos2015[datos2015$round=="SOP",]

datosSOP
```

Observamos 4 filas, que se trata, viendo que es el mismo *eventid*, de una prueba que nadan sólo 2 nadadoras, Osman y Kelly.
En este caso, un 100 mariposa.
Es curioso que estas dos nadadoras naden una sóla prueba.
Además, nadaron a las 11:56, por la mañana, donde sólo se nadan preliminares.
Vamos a ver si descubrimos algo viendo la clasificación de ese 100 mariposa en la ronda preliminar:

```{r}
fly100PREWomen<-nadadoresPruebas[nadadoresPruebas$distance==100 & nadadoresPruebas$stroke=="FLY" & nadadoresPruebas$round=="PRE" & nadadoresPruebas$gender=="F", ]

#Ahora ordenamos por tiempo
fly100PREWomen<-fly100PREWomen[order(fly100PREWomen$swimtime), ]
#Las ordeno
rownames(fly100PREWomen) <- 1:nrow(fly100PREWomen)
head(fly100PREWomen,20)

```

Si busco a Osman y Kelly en el anterior dataframe, observo que se encuentran en el puesto 16 y 17 respectivamente y que, hicieron el mismo tiempo.
Luego tiene sentido razonar que, las rondas SOP son rondas de desempate para ver quién pasa a la siguiente ronda.

### Rondas SOS 

Viendo el razonamiento de las rondas SOP, intuimos que las rondas SOS deben ser rondas de desempate entre nadadores de las semifinales.
De todas maneras, vamos a verlo.
Para ello, si nos fijamos en una de los dataframes anteriores, en la prueba de 200 metros había 4 nadadores que nadan la ronda SOS.
Vamos a visualizarlo:

```{r}
datosSOS<-nadadoresPruebas[nadadoresPruebas$round=="SOS" & nadadoresPruebas$distance==200, ]
datosSOS
```

Vemos que se nadaron dos rondas SOS, una para la prueba de 200m braza femenino, y otra para la prueba de 200 estilos masculino.
Elijamos el 200 estilos masculino, visualicemos el ranking de las semifinales y veamos si están Roberto Pavoni y Conor Dwyer empatados en el 8vo y 9no puesto:

```{r}
medley200SEM<-nadadoresPruebas[nadadoresPruebas$round=="SEM" & nadadoresPruebas$distance==200 & nadadoresPruebas$gender=="M" & nadadoresPruebas$stroke=="MEDLEY", ]

#Ahora, ordeno igual que antes: 

medley200SEM<-medley200SEM[order(medley200SEM$swimtime), ]
#Las ordeno
rownames(medley200SEM) <- 1:nrow(medley200SEM)
medley200SEM
```

Y efectivamente, empataron con un tiempo de 118.54 segundos, luego SOS equivale a las rondas de desempate producidas en las rondas semifinales.
Además, observamos que se realizan por las tardes.

Luego, ya hemos resuelto las dudas acerca de Round.

```{r, echo=FALSE}
rm(datosSOP, datosSOS, fly100PREWomen, free50FinalWomens, free50PrelimWomens, free50SemisWomens, medley200SEM)

```

## Estudios relacionados con los puntos.

Veamos las posibles relaciones de puntos con las demás variables:

Antes de ello, vamos a tener que eliminar de este estudio a los nadadores descalificados (es decir, los que tienen NA points).

```{r}
nadadoresPruebas <- nadadoresPruebas %>% filter(!is.na(nadadoresPruebas$points))
```

### Mejor nadador por prueba nadada. MVP de los mundiales.

Veamos ahora cómo se distribuyen los puntos.

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = points)) +
  geom_density(fill = viridis(1, option = "D"), color = "black", alpha = 0.8) + # Color accesible
  ggtitle("Distribución de Puntos") +
  labs(x = "Puntos", y = "Densidad") + # Etiquetas descriptivas
  theme_minimal(base_size = 14) + # Tema limpio y texto más grande
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), # Centrar título
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14)
  )
```

Observamos que la mayoría de puntos se encuentran a partir de los 750/800 puntos, y esto, tiene sentido si razonamos que para entrar a los mundiales de natación, se necesitan unas marcas mínimas (una cantidad de puntos preestablecida).
Luego es normal encontrar una gran cantidad de datos que tengan más de 750 puntos ya que había un "corte" para la inscripción en la competición.
Esto hace que la gráfica no esté más distribuida por todos los posibles valores de puntos.

Ahora nos surge la siguiente pregunta: *¿Quién rindió mejor en los campeonatos?*.

Podemos buscar el nadador que hizo más puntos:

```{r}
datos2015[which.max(datos2015$points), ]
```

Observamos que la nadadora que cosechó más puntos en una prueba fue Katie Ledecky en los 1500 metros.
Buscando, casualmente observamos que batió el récord[<https://www.rtve.es/deportes/20150803/ledecky-bate-record-del-mundo-1500-libres/1193160.shtml>] del mundo en dicha prueba.

Ahora, vamos a buscar al nadador que, en promedio, consiguió más puntos, podríamos denominarlo el *MVP* del Mundial Kazán 2015.
Para ello:

```{r}
#Usamos nadadoresPruebas, donde tenemos cada nadador y la prueba que realizó. 

media_puntos <- aggregate(nadadoresPruebas$points ~ nadadoresPruebas$athleteid, data = nadadoresPruebas, FUN = mean)
media_puntos <- media_puntos[order(media_puntos$`nadadoresPruebas$points`, decreasing = TRUE), ]
media_puntos<- rename(media_puntos, "athleteid"="nadadoresPruebas$athleteid")
media_puntos<-rename(media_puntos, "meanPoints"="nadadoresPruebas$points")

head(media_puntos,5)
```

El atleta con id 108588 es el que hizo más puntos, veamos quien es:

```{r}
nadadoresPruebas[nadadoresPruebas$athleteid==108588	, ]
```

Luego, el MVP fue el británico Adam Peaty, que nadó 50, 100 y 200 braza.
Veamos quiénes fueron los integrantes del podio:

```{r}
nadadoresParticipantes[nadadoresParticipantes$athleteid==102630 | nadadoresParticipantes$athleteid==105594, ]
```

Completaron el podio Cameron Van der Burgh, de Sudáfrica, y Katie Ledecky.

### Puntos. Hombres vs Mujeres

A continuación, vamos a comparar los puntos realizados por hombres y mujeres, para ver si podemos sacar alguna conclusión.

Primeramente, vamos a ver la función de densidad:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = points, colour = gender)) +
  geom_density() +
  ggtitle("Distribución de Puntos por Sexo") +
  labs(x = "Puntos", y = "Densidad") +
  scale_colour_viridis(discrete = TRUE, option = "D") + # Paleta accesible
  theme_minimal(base_size = 14) + # Tema limpio y texto más grande
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), # Centrar título
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```

A priori, parece haber dos distribuciones muy igualadas. Tiene sentido ya que, los puntos se definen de manera separada para cada sexo. Es decir, la distribución de los puntos se calculan con un algoritmo que se basa en la distribución de tiempos para esa prueba y ordenada respecto al récord mundial en dicha prueba. Nadadores con puntos cercanos a 1000 son nadadores élite cuyo tiempo está muy cerca del récord mundial. En este caso, hay dos distribuciones por cada prueba, una para las chicas y otra para los chicos, luego tiene sentido que la gráfica anterior sea tan parecida. 

### Puntos. ¿La edad influye?

Una buena manera de medir el rendimiento con respecto a la edad del nadador, es verlo a través de los puntos obtenidos.

```{r, warning=FALSE}
# Resumen de puntos por edad
resumen_puntos <- nadadoresPruebas %>%
  group_by(edad, points) %>%
  summarise(frecuencia = n(), .groups = 'drop')

# Crear el gráfico de calor
ggplot(resumen_puntos, aes(x = edad, y = points)) +
  geom_tile(aes(fill = frecuencia), color = "black") +
  # Usar una paleta de colores divergente
  scale_fill_gradientn(colors = brewer.pal(9, "Reds"), 
                       limits = c(min(resumen_puntos$frecuencia), max(resumen_puntos$frecuencia))) + 
  theme_bw() +
  labs(title = "Gráfico de Calor: Edades y Puntos Obtenidos",
       x = "Edad",
       y = "Puntos Obtenidos") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

```{r}
# Crear una nueva columna que clasifica a los nadadores en grupos de edad
nadadoresPruebas <- nadadoresPruebas %>%
  mutate(grupo_edad = case_when(
    edad < 18 ~ "Menores de 18",
    edad >= 18 & edad <= 30 ~ "Entre 18 y 30",
    edad > 30 ~ "Mayores de 30"
  ))

# Calcular el promedio de puntos por grupo de edad
promedio_puntos <- nadadoresPruebas %>%
  group_by(grupo_edad) %>%
  summarise(promedio = mean(points, na.rm = TRUE))

# Crear un gráfico de barras para visualizar el promedio de puntos
ggplot(promedio_puntos, aes(x = grupo_edad, y = promedio, fill = grupo_edad)) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_brewer(palette = "Reds") +  # Cambiar la paleta si es necesario
  theme_bw() +
  labs(title = "Promedio de Puntos por Grupo de Edad",
       x = "Grupo de Edad",
       y = "Promedio de Puntos") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none")
```

Vamos a comparar los puntos con la edad.
Para ello, vamos a dividir en 3 grupos por edades (menores de 18, entre 18 y 30 y mayores de 30) y a comparar el promedio de puntos cosechados por cada franja de edad.

```{r}
# Mostrar el promedio de puntos en una tabla
promedio_puntos %>%
  kable(caption = "Promedio de Puntos por Grupo de Edad", 
        col.names = c("Grupo de Edad", "Promedio de Puntos"))

```

En el grupo de edad entre 18 y 30, el promedio de Puntos es 817.76.Este grupo presenta el promedio más alto en comparación con los otros grupos.
Esto podría indicar que los nadadores en este rango de edad tienen un rendimiento superior en términos de puntos acumulados.
Esto puede ser atribuible a varios factores, como una mayor experiencia.
El grupo de Edad Mayores de 30 tiene un promedio de 806.32 puntos.
Los nadadores mayores de 30 años tienen un promedio de puntos ligeramente inferior al grupo de 18 a 30 años.
Sin embargo, el rendimiento sigue siendo fuerte, lo que sugiere que, aunque pueden enfrentar desafíos relacionados con la edad, muchos continúan siendo competitivos.
El grupo de Edad Menores de 18 tiene un promedio de 621.36 puntos.
Este grupo muestra el promedio más bajo en comparación con los otros dos.
Esto puede ser indicativo de que los nadadores jóvenes aún están en desarrollo y adquiriendo habilidades y experiencia.
Es natural que los nadadores más jóvenes, al estar en una etapa temprana de su carrera, acumulen menos puntos.

La diferencia significativa en el rendimiento entre los grupos puede sugerir que la edad tiene un impacto positivo en el rendimiento de los nadadores, al menos hasta cierto punto.
Esto también resalta la importancia del entrenamiento y la experiencia que se adquiere con la edad.
Es posible que los nadadores más jóvenes tengan que enfocarse en su desarrollo técnico y competitivo para alcanzar a sus contrapartes mayores.
Esto podría incluir mejorar sus técnicas de natación, preparación física, y estrategias de carrera.

Realizamos un test para ver si la diferencia es significativa

```{r}
# Realiza la prueba de Kruskal-Wallis
kruskal_result <- kruskal.test(points ~ grupo_edad, data = nadadoresPruebas)
print(kruskal_result)
```

El p-value \< 2.2e-16: Este valor p es extremadamente bajo, lo que indica que hay diferencias significativas en los puntos entre al menos uno de los grupos de edad.
Dado que el valor p es muy pequeño, puedes rechazar la hipótesis nula, que sostiene que no hay diferencias en las medianas de los puntos entre los grupos.

Aunque Kruskal-Wallis indica que hay diferencias, no te dice cuáles son esos grupos que difieren.
Por lo tanto, es recomendable realizar pruebas post-hoc para identificar qué grupos son significativamente diferentes entre sí.

```{r, warning=FALSE}
# Prueba de Dunn
dunn_test <- dunnTest(points ~ grupo_edad, data = nadadoresPruebas, method = "bonferroni")
print(dunn_test)
```

Entre 18 y 30 vs. Mayores de 30: No hay evidencia suficiente para afirmar que hay una diferencia significativa en los puntos entre estos dos grupos de edad.
Entre 18 y 30 vs. Menores de 18: Hay una diferencia altamente significativa en los puntos entre estos dos grupos.
Esto indica que los nadadores menores de 18 años obtienen significativamente menos puntos que los nadadores entre 18 y 30.
Mayores de 30 vs. Menores de 18: También hay una diferencia altamente significativa entre estos grupos, sugiriendo que los nadadores mayores de 30 años obtienen significativamente más puntos que los nadadores menores de 18.

La comparación muestra que, mientras que no hay diferencia significativa entre los grupos de 18-30 y mayores de 30, los menores de 18 años se desempeñan significativamente peor en términos de puntos en comparación con ambos grupos de mayores edad.

```{r}
ggplot(nadadoresPruebas, aes(x = grupo_edad, y = points, fill = grupo_edad)) +
  geom_boxplot() +
  labs(
    title = "Distribución de Puntos por Grupo de Edad", 
    x = "Grupo de Edad", 
    y = "Puntos"
  ) +
  scale_fill_viridis(discrete = TRUE, option = "D") + # Paleta viridis para colores accesibles
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```


```{r, echo=FALSE}
#vuelvo de nuevo a la original

rm(anova_puntos_genero, dunn_test, kruskal_result, media_puntos, modelo, promedio_puntos, resumen_puntos)
nadadoresPruebas<-nadadoresPruebasCopia
```

### Modelo de regresión lineal: reactiontime vs swimtime.

Empezamos viendo la relación lineal (que ya sabemos que será alta) entre puntos y tiempo.
Es evidente que a mayor tiempo, hay menos puntos.
Veámoslo

```{r}
nadadoresPruebas50crol<- nadadoresPruebas[nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=='FREE', ]
t= nadadoresPruebas50crol$swimtime
p= nadadoresPruebas50crol$points
cor(nadadoresPruebas50crol$swimtime,nadadoresPruebas50crol$points)
head(nadadoresPruebas50crol,10)

```

Esto no es de mucho estudio, ya que es lo lógico.

Veamos los puntos respecto al tiempo de reacción:

```{r}
nadadoresPruebas<- na.omit(nadadoresPruebas)
x= nadadoresPruebas$points
y=nadadoresPruebas$reactiontime
```

```{r}
cor(x,y)
```

Parecen no estar correlacionadas el tiempo de reaccion y los puntos de manera lineal.
Pero a lo mejor, en pruebas específicas , como las pruebas de distancias cortas la correlación es mayor.

```{r}
nadadoresPruebas50<- nadadoresPruebas[nadadoresPruebas$distance==50, ]
X=nadadoresPruebas50$reactiontime
Y=nadadoresPruebas50$points
cor(X,Y)
```

Ya tenemos nuestro objetivo de estudio ya que para comenzar con la modelización estadística, debemos contextualizar el problema, definiendo objetivos y variables.

Queremos investigar si existe relación entre el tiempo de reacción y puntos.
Una pregunta que puede surgirnos es, ¿A mayores valores del tiempo de reacción, hay mayores valores de puntos?
Luego, nuestro objetivo será saber si hay algún tipo de relación lineal, y las variables, por ende, serán tiempo de reacción y puntos.
La variable tiempo de reacción, será nuestra variable independiente, y puntos será la variable dependiente.

A continuación, procedemos a realizar una inspección gráfica simple, para identificar tendencias.

```{r}
plot(X,Y,xlab="Tiempo de reacción",ylab="Puntos")
```

```{r}
cov(X,Y)
```

Esta covarianza, positiva y grande en valor absoluto, nos indica que hay relación negativa entre las variables(ya lo habíamos intuido pero gracias al signo lo hemos confirmado).

A pesar de la confirmación, en este momento nos surge un problema, pues, la covarianza toma valores en todos los números reales, dependiendo de las magnitudes del tiempo de reacción y puntos, y de sus unidades .
Por eso, calcularemos el coeficiente de correlación lineal, que se obtiene tipificando la covarianza, es decir, dividiendo la covarianza entre las desviaciones típicas muestrales (obteniendo un coeficiente entre -1 y 1)

```{r}
cor(X,Y)
```

De manera adicional, podemos incluir histogramas marginales en cada eje del gráfico, para ello usamos las librerías `ggplot2` y `ggExtra`.

```{r}
datos<-data.frame(x=X,y=Y)

p<-ggplot(datos, aes(x = X, y = Y)) +
  geom_point()
#vemos la nube de puntos 
print(p)
#Especificamos que se añadan histogramas en los márgenes
ggMarginal(p, type = "histogram")

```

Como hemos visto, si la relacion lineal es fuerte tiene sentido querer ajustar una recta a la nube de puntos.
Es decir, considerar un modelo de regresion lineal simple.

La función que ajusta el modelo de regresión lineal simple en R es `lm`(con parametros B_0,B_1 y sigma\^2), directamente hacemos un `summary` para que nos devuelva la información más importante, aunque realmente `lm` calcula muchas cosas: estimaciones, residuos, predicciones, etc.

```{r}
lm=lm(Y~X)
summary(lm)
```

Podemos añadir la recta de regresión al gráfico usando el comando `abline`, y el objeto donde hemos guardado el ajuste de la recta, en este caso `lm4`:

```{r}
#representamos
plot(X,Y)
#añadimos la recta de regresion
abline(lm)
```

Los coeficientes de la regresión estimados también están en el objeto donde hemos guardado el ajuste, en `lm`

```{r}
#generamos un vector con los coeficientes de la regresion
coeficientes=lm$coefficients
#comprobamos que es lo mismo que nos salía en el summary
coeficientes
```

Sabemos que el valor de los puntos cuando X=0, es decir, que el tiempo de reacción sea cero, es de 1809 aproximadamente.
Este parámetro no tendría sentido, pues el tiempo de reacción nunca va a ser cero.
Por otro lado la pendiente es -1562.315, lo que nos muestra que por cada valor que aumenta X, Y aumenta lo indicado.

```{r, echo=FALSE}

#Este código al final del estudio para no sobrecargar el entorno (Enviroment)
rm( datos, lm, coeficientes, t, x, X, y, Y, nadadoresPruebas50, nadadoresPruebas50crol, p)

nadadoresPruebas<- nadadoresPruebasCopia

```

## Prueba 800m Libre femenino.

Quiero evaluar la prueba 800m libres.

Veamos qué nadadores nadaron el 800 libre femenino:

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
nadadoras800free<-nadadoresPruebas[nadadoresPruebas$distance==800 & nadadoresPruebas$gender=="F", ]

dim(nadadoras800free)
```

Se observa que no hay descalificaciones en el 800 libres femenino.
Tenemos que 51 chicas nadaron el 800 libres, algunas de ellas dos veces ya que pasaron a la final.

Nos vamos a fijar en la final, para ello, filtramos otra vez los datos:

```{r}
nadadoras800free<-datos2015[datos2015$gender=="F" & datos2015$distance==800 & datos2015$round=="FIN", ]

```

#### Estudio sobre los parciales de la carrera.

Vamos a evaluar cómo fueron los parciales de las nadadoras, para ello hacemos el siguiente gráfico:

```{r, warning=FALSE}
ggplot(nadadoras800free, aes(y=nadadoras800free$lastname, x=nadadoras800free$splitswimtime, fill=nadadoras800free$lastname))+
  geom_boxplot()+
  labs(x="Parciales", y="Nadadoras")
```

De aquí podemos observar la media y los cuantiles de los parciales de las nadadoras.
Observamos que casi todas tienen 1 o incluso 2 puntos atípicos, seguramente se deban al primer y último parcial de la prueba.
Además, podemos observar que algunas nadadoras como Kapas y Friis, tuvieron una desviación muy pequeñita en sus parciales, es decir, fueron a un ritmo constante durante toda la prueba clavando sus parciales.

Vamos a observar, para cada nadador, los parciales realizados para ver si podemos conseguir algún patrón de tipo de carrera:

```{r, warning=FALSE}
ggplot(nadadoras800free, aes(x=nadadoras800free$splitdistance, y=nadadoras800free$splitswimtime, group = lastname, colour =lastname )) + 
  geom_line()  + 
  geom_point( size=2, shape=21, fill="white") + 
  theme_minimal()+
  labs(x="Parciales", y="Tiempos por parcial.")
```

Observamos que todas nadan muy rápido tanto el primer parcial como el último.
Además, vemos de manera clara como Ledecky parece que alterna un largo un poco más rapido y luego otro más lento durante toda su prueba.
¿Puede ser una estrategia de carrera?
Lo veremos más adelante.
También vemos alguna otra nadadora más que hace algo similar como Van Rouwendaal.
Otras en cambio, intentan conservar el ritmo marcado desde el inicio y ser constantes.
Carlin mete un cambio de ritmo muy drástico al paso de los 650m de 31s altos a 31s bajos y sigue luego bajando.

#### Visualización de la carrera.

Ahora, vamos a definir un dataframe en el que nos va a importar el nombre, la suma total de tiempo al paso de cada parcial:

```{r}
nadadoras800free <- nadadoras800free %>%
  dplyr::select(lastname,firstname,gender,reactiontime,splitdistance,cumswimtime, swimtime)

```

Visualizamos la carrera:

```{r}
# Ordenar los datos por tiempo
nadadoras800free <- nadadoras800free %>%
  arrange(splitdistance, cumswimtime)

# Crear un índice de posición
nadadoras800free <- nadadoras800free %>%
  group_by(splitdistance) %>%
  mutate(Posicion = rank(cumswimtime, ties.method = "first"))



ggplot(nadadoras800free, aes(x = splitdistance, y = Posicion, group = lastname)) +
  geom_line(aes(color = lastname, alpha = 1), size = 2) +
  geom_point(aes(color = lastname, alpha = 1), size = 4) +
  scale_y_reverse(breaks = 1:nrow(nadadoras800free))
```

Observamos como Ledecky lidera toda la carrera, Boyle alcanza al paso de los 100 metros la segunda posición y la mantiene.
La pelea por la última medalla en juego dura hasta los 700 metros, donde un adelantamiento de Carlin a Ashwood hace que la nadadora Jaz Carlin alcance el bronce olímpico.

```{r, echo=FALSE}
rm(nadadoras800free)
```



# PCA's

Realizaremos ahora el análisis de componentes principales del 800m libres femenino:

## Análisis de componentes principales. 200 mariposa masculino preliminares (Salma)

La idea de realizar el siguiente PCA es porque disponemos de gran cantidad de variables, algunas de las cuales están correlacionadas entre sí, lo que complica su análisis.
En estas situaciones es conveniente aplicar el método de componentes principales, que permita reducir el número de variables sin pérdida sustancial de información, y consiguiendo que estas nuevas variables sean incorreladas evitando así que haya información redundante.

Comenzamos,cargando los datos:

```{r}
prueba200MariposaMasc<- datos2015[datos2015$distance==200 & datos2015$gender=="M" & datos2015$stroke=="FLY"& datos2015$round=="PRE", ]

prueba200MariposaMasc <- prueba200MariposaMasc %>%
    dplyr::select(lastname, reactiontime, splitdistance, splitswimtime, edad)
```

Creamos un dataframe en la que nos quedamos con el nombre, apellidos y parciales

```{r, warning=FALSE}
pruebita <- prueba200MariposaMasc %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
head(pruebita,10)
#omito los valores nulos: 
pruebita<- na.omit(pruebita)
row.names(pruebita) <- pruebita$lastname # esto es para llamar a las filas con el nombre de los nadadores
head(pruebita,10)
```

Calculas estadísticas descriptivas utilizando 'pastecs::stat.desc' para entender mejor tus datos:

```{r}
pastecs::stat.desc(pruebita, basic = F)
```

Se puede observar que hay grandes diferencias entre las varianzas de las variables, lo que puede afectar a los resultados de un análisis de componentes principales (ACP), debido a que las variables con mayor varianza tendrán más influencia en la generación de un componente.

El ACP tiene sentido cuando hay correlación entre las variables pues permite eliminar información redundante.
Si se analiza la matriz de correlaciones se puede ver, a modo de ejemplo, que hay correlaciones fuertes.Luego, procedemos con el PCA

```{r}
prueba200MariposaMasc2<- datos2015[datos2015$distance==200 & datos2015$gender=="M" & datos2015$stroke=="FLY"& datos2015$round=="PRE", ]

prueba200MariposaMasc2 <- prueba200MariposaMasc2 %>%
    dplyr::select( reactiontime, splitdistance, splitswimtime, edad)

R <- cor(prueba200MariposaMasc2)
corrplot::corrplot(R, method = "number", 
                   number.cex = 0.75) # Matriz de correlaciones con números en letra pequeña
```

Para la obtención de los componentes principales utilizamos la función princomp.
Para evitar la influencia de la diferencia en magnitud de las varianzas se puede emplear los datos originales y el argumento cor = TRUE o los datos originales estandarizados y el argumento cor = FALSE.Utilizaremos el primer caso,ya que conseguimos que la suma de las varianzas de las variables originales y la de los componentes coincida con el número de variables de la matriz de datos original.

```{r, warning=FALSE}
componentess=prcomp(pruebita[,-1], cor = TRUE)
summary(componentess)
```

Los componentes están ordenados en función de la varianza que explican y el porcentaje acumulado permite decidir con cuántos componentes trabajar.
En este caso con solo dos se explica el 96%, con tres el 98%, con uno el 68%...

Generalmente, hay un número pequeño de componentes, los primeros, que contienen casi toda la información y el resto suele contribuir relativamente poco.
Ya lo hemos visto en nuestro estudio.
Podemos directamente coger 2, trabajar sobre el plano y tener una alta varianza explicada, pero vamos a demostrarlo de una manera un poco más empírica.
Utilizamos el criterio del autovalor superior a la unidad (regla de Kaiser) y el gráfico de sedimentación (scree test).

Para el primero, tenemos que saber que este criterio retiene aquellos componentes cuyos valores propios son superiores a la unidad y funciona bastante bien salvo con un gran número de variables, que no es nuestro caso.Luego, será muy preciso.
Las raices de los autovalores asociados a la matriz de correlaciones son las desviaciones típicas de los componentes y se encuentran en '\$sdev' del objeto componentes creado con la función princomp.

```{r}
auto<-componentess$sdev^2
auto
```

El número de componentes a retener según este criterio sería 2, ya que únicamente hay 2 autovalores mayores que uno.
Como ya se ha visto, esta decisión implicaría quedarnos con un 96% de la varianza total de los datos, que es bastante.

Otra manera de ver el número de componentes que escojamos, más gráfica, es un gráfico de sedimentación (scree test).
Este gráfico muestra en el eje de ordenadas los autovalores y en el eje de abscisas los componentes.
Los cambios en la pendiente nos permiten observar cuánta capacidad explicativa va aportando cada componente.

Se escoge el número de componentes a partir del cual los autovalores restantes son relativamente más pequeños en comparación con él.

```{r}
plot(componentess, type="lines", main = "Gráfico de sedimentación")
abline(h=1, lty=3, col="red")
```

El gráfico de codo nos aconseja también quedarnos con 2 componentes.
Ambos criterios ofrecen la misma conclusión, que el número de componentes a retener es 2.

Una vez pasamos a la interpretación de las componentes debemos estudiar sus relaciones con cada una de las variables originales.
Para ello se obtienen e interpretan las correlaciones entre los componentes (componentes\$scores) y las variables.
Una forma de calcularla es con la función cor:

```{r}

Cor_CompVar <- round(cor(pruebita[,-1], componentess$scores), 4) # con round se redondea, en este caso concreto, a 4 decimales 
Cor_CompVar
```

Estos coeficientes que se acaban de calcular son los que se utilizan para interpretar los componentes.
Como se ha decidido retener solo dos componentes, es conveniente crear un objeto que contenga solo las correlaciones con esos tres componentes, que será el objeto a analizar:

```{r}
Cor_CompVar_retenidos <- Cor_CompVar[, 1:2]
Cor_CompVar_retenidos
```

Antes de seguir con la interpretación de los componentes, es conveniente analizar si con el número de componentes elegido (dos) están todas las variables bien representadas.
Para ello se utiliza el coeficiente de correlación al cuadrado.El valor de la correlación al cuadrado se utiliza para estimar la calidad de la representación.
Cuanto más cercano esté a la unidad, mejor será esta.

```{r}
round(Cor_CompVar[,1:2]^2, 4) # con round se redondea, en este caso concreto, a 4 decimales
```

Estos resultados se pueden visualizar con corrplot:

```{r}
corrplot::corrplot(factoextra::get_pca_var(componentess)$cos2[, 1:2], is.corr = F)
```

La variable correspondiente a 200m se explica principalmente por la componente 1, lo que sugiere que el rendimiento en esta distancia está fuertemente asociado a la variabilidad que captura este componente.
La visualización indica que esta relación tiene un porcentaje de varianza explicada de aproximadamente 37% lo cual es significativo.La variable 150m también tiene una correlación notable con el componente 1, aunque en menor medida que la variable de 200m.
Esto indica que el rendimiento en 150m también está influenciado por las mismas características que se reflejan en el componente 1.

La variable edad tiene un fuerte impacto en el componente 1, con un porcentaje de varianza explicada alrededor del 74%.
Esto sugiere que este componente refleja características que son particularmente relevantes para la edad de los nadadores, implicando que, a medida que los nadadores envejecen, sus tiempos y capacidades en el agua podrían verse influidos por la edad.
Este hallazgo es importante porque indica que la edad no solo es un factor en el rendimiento, sino que también está profundamente integrada en los componentes que explican la variabilidad del rendimiento en natación.

```{r}


factoextra::fviz_cos2(componentess, choice = "var", 
                      axes = 1:2, # axes recoge los componentes a utilizar
                         title = "Cos2 de las variables para los componentes 1 a 2") 
```

En este caso, se representa la suma de cos2 para los 2 componentes.La proporción de variabilidad explicada por los dos componentes retenidos es bastante baja.

Procedemos, con la función fviz_pca_var del paquete factoextra, donde sobre un círculo de radio unidad, se sitúan las variables, utilizando como coordenadas sus correlaciones con cada uno de los componentes en el plano.
Además, las variables se pueden colorear en función de distintas características, entre las que destacan su contribución y el valor del cos2 (por ejemplo, verde, naranja o rojo dependiendo de que sean valores bajos, medios o altos, respectivamente).

En edad,la recta formada por la primera componente solo explica el 0,28% de la varianza de edad, lo que significa que está pobremente representado por esta dimensión.

```{r}

factoextra::fviz_pca_var(componentess, col.var = "cos2", 
                         gradient.cols = c("green", "orange", "red"),
                         repel = TRUE,
                         title = "Cos2 de las variables en el plano 1")
```

Cuanto más cercana esté una variable al borde, mejor será la calidad de la representación en el conjunto de las dos componentes.

La variable reactiontime también se observa en una posición cercana al centro del círculo, lo que sugiere que su variabilidad no está suficientemente capturada por los dos componentes principales.
Esto refuerza la idea de que el tiempo de reacción podría requerir un análisis más profundo o considerar otros componentes adicionales para una representación más adecuada.
Por el contrario, otras variables relacionadas con las distancias (como las variables de 50m, 100m, 150m, y 200m) están más alejadas del centro, lo que indica que están bien representadas por los dos primeros componentes.
Esto sugiere que estos componentes capturan la mayor parte de la variabilidad del rendimiento en natación en estas distancias.
Este PCA, dadas las conclusiones que hemos obtenido, y las variables que hay, simplemente se utilizará para entender la manera de proceder

## Análisis de componentes principales del 800 libres femenino. Ronda preliminar [Alonso]

Lo primero que debemos hacer es cargar los datos:

```{r}
prueba800libresPreliminar<- datos2015[datos2015$distance==800 & datos2015$gender=="F" & datos2015$stroke=="FREE" & datos2015$round=="PRE", ]

prueba800libresPreliminar <- prueba800libresPreliminar %>%
    dplyr::select(lastname, reactiontime, splitdistance, splitswimtime, edad)
```

Bien, ahora, debemos encontrar la manera de crear un dataframe en la que nos quedemos con el nombre, apellido y parciales.

```{r, warning=FALSE}
pruebawide <- prueba800libresPreliminar %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
#omito los valores nulos: 
pruebawide<- na.omit(pruebawide)
pruebawide<- as.data.frame(pruebawide)
rownames(pruebawide) <- pruebawide$lastname

```

Ahora que ya tenemos nuestro dataframe hecho, vamos a hacer el PCA:

```{r}
pca800libres<-prcomp(pruebawide[,-1], scale=T)

plot(pca800libres)

```

Vemos la importancia de cadad componente.

Observemos además, un resumen numérico:

```{r}
summary(pca800libres)
```

Viendo el pca, observamos que con la primera componente, tenemos un 84% de la varianza.
Con pc2 un 6%, luego con esas dos logramos explicar un 90% de los datos.

Hagamos una interpretación previa a la graficación de los datos:

```{r}
pca800libres
```

La PCA1 corresponde a una media ponderada en la cual, lo que más ponderan son los parciales de la prueba, siendo los más significativos del 200 al 650.
También toma algo de importancia la edad pero no se verá reflejada.
Luego, nos esperaremos más a la izquierda los nadadores cuyo tiempo medio sea menor (es decir, las más rapidas de las preliminares), y a la derecha las nadadoras más lentas en promedio.

La PCA2, cobra muchísima importancia el tiempo de reacción y la edad.
Luego, esperaremos, contra más arriba se encuentren, nadadoras con un buen tiempo de reacción o pocos años, y abajo nadadoras con mal tiempo de reacción o muchos años.

Ahora, veamos cómo se ven los datos:

```{r}
plot(pca800libres$x[,1:2], type="n")
text(pca800libres$x[,1:2],rownames(pruebawide), cex = 0.4)

```

Luego, podríamos decir que, el grupo de Ledecky, Carlin...
fueron las más rapidas de las preliminares.
Chentson, Holowchak y Rannvaardottir las más lentas.

También, podríamos decir que, nadadoras como Jo, corresponden a un tiempo de reacción muy bajo junto con una edad baja.
Nadadoras como Kobrich y Elhenicka, serán nadadoras con más años y que además tienen un mal tiempo de reacción en comparación con todas las demás.

Veámos la ponderación de las variables con el siguiente gráfico:

```{r}
fviz_pca_var(pca800libres, col.var = "red")
```

Viendo esta interpretación, podemos observar de una mejor manera, cuando un nadador va a estar más "arriba" o "abajo", si es causa de la edad o del tiempo de reacción.
Luego, si nos fijamos en las nadadoras del gráfico anterior, podremos asegurar que, Gill, tiene un tiempo de reacción pésimo, ledecky es rápida y joven y buen tiempo de reacción.
Hassler es una nadadora con más edad pero de las más rapidas pero con mal tiempo de reacción.

```{r}
#biplot(pca800libres)

fviz_pca_biplot(pca800libres, repel = TRUE)
```

```{r, echo=FALSE}
rm(pca800libres, prueba800libresPreliminar, pruebawide)
```

## Análisis de componentes principales del 100m mariposa femenino. [JAVIER]

En primer lugar, vamos a crear un nuevo dataframe llamado prueba100MariposaFem en la cuál nos quedamos con todas las pruebas de atletas femeninos, de distancia igual a 100 metros y de estilo de nado mariposa.
A continuación, nos quedamos con las columnas de lastname, reactiontime, splitdistance, splitswimtime y swimtime del dataframe prueba100MariposaFem.

```{r}
# Filtro de pruebas de 100m mariposa femenino
prueba100MariposaFem <- datos2015[datos2015$distance==100 & datos2015$gender=="F" & datos2015$stroke=="FLY" & datos2015$round =="PRE",]

# Selección de columnas relevantes
prueba100MariposaFem <- prueba100MariposaFem %>% dplyr::select(lastname, reactiontime, splitdistance, splitswimtime)
head(prueba100MariposaFem, 10)
```

A continuación, vamos a organizar los datos del dataframe *prueba100MariposaFem*.
de modo que cada nadador tiene una fila única con columnas para cada distancia.

```{r}
prueba <- prueba100MariposaFem %>%
  pivot_wider(names_from = splitdistance,       # Las diferenetes distancias se convierten en los nombres de las columnas
              values_from =splitswimtime)     #los valores de las celdas serán los tiempos de nado

#Eliminamos duplicados y NA de la columna 'lastname'
prueba <- prueba[!duplicated(prueba$lastname) & !is.na(prueba$lastname), ]

#Convertimos a data frame
prueba <- as.data.frame(prueba)

# Asignar los nombres de fila como el apellido del nadador
row.names(prueba) <- prueba$lastname

#Eliminamos filas con NA restantes
prueba <- na.omit(prueba)
head(prueba,10)
```

Con todo esto, estamos preparados para realizar el PCA.

```{r}
#Realizamos el PCA (estandarizamos los datos)
pca_100mariposafemenino <- prcomp(prueba[,-1], scale=T)
pca_100mariposafemenino

```

Observamos que la primera y segunda componente son las que tienen mayor valor de standard deviations, luego serán las más relevantes a efectos de la visualización.
Veamos la importancia relativa de cada componente

```{r}
plot(pca_100mariposafemenino)
summary(pca_100mariposafemenino)
```

El resultado del análisis de componentes principales (PCA) muestra tres componentes principales (PC1, PC2, PC3).
Veamos cada aspecto de la salida: Los datos de la fila de desivación estándar (Standard deviation), cuanto mayores sean, mas variabilidad de los datos se captura.
En este caso, la componente principal PC1 es la que tiene mayor desviación estándar, lo que sugiere que capta la mayor parte de la varianza.

En segundo lugar, la proporción de la varianza (proportion of variance) indica qué porcentaje de la varianza total de los datos está capturado por cada componente.
Aquí, PC1 captura el 74.23% de la varianza, mientras que PC2 captura el 23.28%, y PC3 solo el 2.493%.
Esto significa que PC1 es el componente más relevante para representar la estructura de los datos, mientras que PC3 aporta muy poco.
(como habiámos adelantado anteriormente)

Por último, para la variable de proporción acumulada (cumulative proportion) indica la varianza total capturada al considera las componentes en conjunto.
PC1 junto con PC2 explican el 97,51% de la variabilidad de los datos (bastante alto).
Esto sugiere que podemos reducir la dimensionalidad a estas dos primeros componentes sin perder mucha información.

El análisis PCA muestra que los datos prueba pueden ser bien representados con solo dos componentes principales (PC1 y PC2).
Este resultado implica que la mayor parte de la variabilidad de los tiempos de nado de los participantes se puede resumir en estas dos dimensiones.

Por último, dibujamos los datos proyectados sobre las dos primeras componentes

```{r}
plot(pca_100mariposafemenino$x[,1:2])
text(pca_100mariposafemenino$x[,1:2], rownames(prueba[,-1]))
biplot(pca_100mariposafemenino) 
```

```{r, echo=FALSE}
rm(pca_100mariposafemenino, prueba100MariposaFem)
```

## Análisis de componentes principales en la carrera preliminar de 1500 metros (INES)

Vamos a ver en qué estilo predominan los nadadores de 1500 metros.

```{r}
summary(nadadoresPruebas$stroke[nadadoresPruebas$distance == 1500])
summary(nadadoresPruebas$round[nadadoresPruebas$distance == 1500])
```

Como podemos observar, todos los nadadores nadan en estilo libre.
Por tanto, no seleccionaremos según esa imposición, ya que nos viene de los propios datos.
Gracias a ello, tenemos un enfoque más global de la carrera de 1500 metros.

Además, tenemos 70 participantes en rondas preliminares y 15 finales.
Por tanto, tomaremos la ronda preliminar para hacer nuestro análisis de componentes principales.

```{r}
# Filtro de pruebas de 1500m masculino
datos1500Masc <- datos2015[datos2015$distance==1500 & datos2015$gender=="M" & datos2015$round =="PRE",]

# Selección de columnas relevantes
datos1500Masc <- datos1500Masc %>% dplyr::select(lastname, reactiontime, splitdistance, splitswimtime)
head(datos1500Masc,15)
```

```{r}
prueba1500 <- datos1500Masc %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas

#Eliminamos duplicados y NA de la columna 'lastname'
prueba1500 <- prueba1500[!duplicated(prueba1500$lastname) & !is.na(prueba1500$lastname), ]

prueba1500 <- as.data.frame(prueba1500)

# Asignar los nombres de fila como el apellido del nadador
row.names(prueba1500) <- prueba1500$lastname

#Eliminamos filas con NA restantes
prueba1500 <- na.omit(prueba1500)
head(prueba1500,15)
```

Con todo esto, estamos preparados para realizar el PCA:

```{r}
#Realizamos el PCA
pca_1500masculino <- prcomp(prueba1500[,-1], scale=T)

# Resultados del PCA
summary(pca_1500masculino)

```

Por tanto, vemos el Análisis de Componentes Principales (PCA) en los datos de nadadores masculinos en la carrera de 1500 metros, excluyendo la primera variable, que es el nombre.

Observamos que el primer componente principal (PC1) tiene una desviación estándar de 5.0272 y explica el 81.52% de la varianza total.
Este componente captura la mayor parte de la variabilidad en los datos, lo que sugiere que una sola dirección en el espacio de los datos contiene gran parte de la información relevante.
Los siguientes componentes, como PC2 y PC3, explican 7.75% y 3.47% de la varianza respectivamente.
Estos valores disminuyen progresivamente, lo que indica que los componentes adicionales explican cada vez menos de la variabilidad total.
Así pues, los primeros dos componentes principales explican el 89,27% de la varianza.
Si añadimos el tercer componente, logran explicar el 92.73% de la varianza, lo que puede ser suficiente para una interpretación efectiva de los datos.

Visualizamos ahora cómo se distribuyen los datos en las dos primeras componentes principales y observamos la influencia de las variables en estas componentes.

```{r}
fviz_pca_biplot(pca_1500masculino, repel = TRUE)

```

Viendo el gráfico, podemos interpretar la primera componente como la rapidez en cada split de los participantes.
Cuantos mayores tiempos tienen en cada split, mas desplazados estarán hacia la izquierda.
Por tanto, los nadadores mas a la derecha serán aquellos con mejores resultados.
Vemos como el 81,5% de la varianza de los resultados está explicado por estos tiempos, como podría imaginarse en un principio.
Si nos enfocamos en lo que explica la componente 2, vemos que mayores tiempos de los primeros splits condicionan su desplazamiento hacia abajo, y los tiempos mayores en los ultimos splits desplazan los puntos hacia arriba.
Esto parece indicar que la componente 2 captura las diferencias entre el rendimiento en las etapas iniciales y finales de la prueba, posiblemente destacando la resistencia o la fatiga en los nadadores.
Además, es claramente visible como el tiempo del último split (cuando se completan los 1500m) es muy influyente en la posición de estos nadadores.
Es decir, los tiempos en esta última parte parecen ser muy decisivos en cuanto a su resultado final.

Si observamos la influencia del tiempo de reacción, los tiempos de reacción altos ejercen influencia a favor del eje x e y, en sus sentidos positivos.
Con lo cual, el tiempo de reacción alto parece estar asociado con un rendimiento positivo en los splits y posiblemente en la resistencia hacia el final de la prueba.

Para ver si estas cuestiones se cumplen, vamos a observar si los primeros puestos del ranking de puntos de esta categoría coincide con lo visto en el gráfico.

```{r}
# Filtro de pruebas de 1500m masculino
resumen1500 <- datos2015[datos2015$distance==1500 & datos2015$gender=="M" & datos2015$round =="PRE",]

# Selección de columnas relevantes
resumen1500 <- resumen1500 %>% dplyr::select(lastname,points) %>%
    distinct() %>%         
    arrange(desc(points))


resumen1500
```

Como podemos comprobar, Paltrinieri, Jaeger, Sun y Milne aparecen en los puntos más extremos del eje x.
Además, se localizan en la posición central, lo que parece indicar que sus tiempos son bastante estables durante todo el recorrido.
Si visualizamos los últimos nadadores, que son Arias Dourdet, Butler y Sim Wee Sheng, observamos que efectivamente están en los extremos izquierdos del eje x.
Además, Arias Dourdet y Butler están desplazados hacia el eje y, lo que parece indicar que obtuvieron tiempos más largos en sus splits finales, posiblemente debido a una falta de resistencia y mayor fatiga en estos tiempos, que es un factor crucial para el desarrollo de este tipo de pruebas.

```{r, echo=FALSE}
rm(datos1500Masc, pca_1500masculino, resumen1500)
```

# Clusters

## Cluster sobre el 800m libres femenino. Análisis de estrategias de las nadadoras. [Alonso]

Voy a crear a continuación un dataframe en el cual, contenga el nombre de las nadadoras del 800 libres femenino.
Además, quiero los parciales al paso por cada 50 y el tiempo final.

Vamos a intentar, normalizar de cierta manera los parciales respecto del tiempo final, para intentar ver estrategias de carrera en las nadadoras.
Obsérvese que, normalizamos los datos porque pueden existir dos nadadoras cuya estrategia de carrera sea la misma, pero que se encuentren muy alejadas en el cluster debido a que sus tiempos son lo suficientemente distintos.
Es por ello que normalizaremos los datos.

Empecemos creando los dataframes de manera análoga a como lo hicimos en el PCA:

```{r, warning=FALSE}
prueba800libresPreliminar<- datos2015[datos2015$distance==800 & datos2015$gender=="F" & datos2015$stroke=="FREE" & datos2015$round=="PRE", ]

prueba800libresPreliminar <- prueba800libresPreliminar %>%
    dplyr::select(lastname, splitdistance, splitswimtime,swimtime)

free800WomensPre <- prueba800libresPreliminar %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
#omito los valores nulos: 
free800WomensPre<- na.omit(free800WomensPre)

free800WomensPre <- as.data.frame(free800WomensPre)

rownames(free800WomensPre) <- free800WomensPre$lastname
```

A continuación, vamos a echar un vistazo a lo creado:

```{r}
head(free800WomensPre, 10)
```

Ahora, voy a normalizar los datos dividiendo cada pacial por el tiempo total, que dará una especie de "porcentaje" de cuánto tardan en cada parcial:

```{r}
free800WomensNormalizado <- free800WomensPre %>%
  mutate(across(c(`50`, `100`, `150`, `200`, `250`, `300`, `350`, `400`, `450`, 
                  `500`, `550`, `600`, `650`, `700`, `750`, `800`), 
                ~ . / swimtime))

#free800WomensNormalizado$swimtime=NULL
free800WomensNormalizado <- as.data.frame(free800WomensNormalizado)
rownames(free800WomensNormalizado) <- free800WomensNormalizado$lastname


```

Bien, ahora, voy a tratar de hacer un cluster:

En primer lugar vamos a calcular la distancia Euclídea entre las observaciones de la base de datos.

```{r}
distance <- get_dist(free800WomensNormalizado[,-c(1,2)])

fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Esto empieza a ilustrar qué estados tienen grandes disimilitudes (rojo) frente a los que parecen ser bastante similares (verde azulado).

Veamos ahora, mediante el método de las siluetas, el número óptimo de clusters:

```{r}
fviz_nbclust(free800WomensNormalizado[,-c(1,2)], kmeans, method = "silhouette")
```

A continuación, hacemos el cluster:

```{r}
cluster800libres <- kmeans(free800WomensNormalizado[,-c(1,2)], centers = 3, nstart = 25)
cluster800libres
```

```{r}
fviz_cluster(cluster800libres, data = free800WomensNormalizado[,-c(1,2)])
```

Bien, ahora para poder sacar las conclusiones debidas, voy a querer graficar el dataframe, donde cada nadadora (fila), va a tener asociado un cluster.

```{r}
free800WomensNormalizado$cluster<-cluster800libres$cluster

```

A continuación, vuelvo al formato long, para ello:

```{r}
prueba800long <- free800WomensNormalizado %>%
  pivot_longer(cols = c("50", "100", "150", "200", "250", "300", "350", 
                         "400", "450", "500", "550", "600", "650", 
                         "700", "750", "800"), 
               names_to = "splitdistance", 
               values_to = "splitswimtime")



```

Gráfica:

```{r}
ggplot(prueba800long, aes(x = as.numeric(splitdistance), 
                          y = splitswimtime, 
                          group = lastname, 
                          color = factor(cluster))) +
  geom_line(alpha = 0.6) +  # Agrega líneas para cada nadadora
  geom_point() +             # Agrega puntos en cada parcial
  labs(x = "Parcial (m)", 
       y = "Tiempo de Nado (segundos)", 
       color = "Cluster") +
  theme_minimal() +
  ggtitle("Tiempos de Nado por Parciales Agrupados por Cluster")
```

Parece que este gráfico no es lo suficientemente claro, voy a evaluar nadadoras por cluster de manera separada:

```{r}
# Filtrar datos por cluster y graficar
for (i in unique(prueba800long$cluster)) {
  p <- ggplot(prueba800long[prueba800long$cluster == i, ], 
               aes(x = as.numeric(splitdistance), 
                   y = splitswimtime, 
                   group = lastname, 
                   color = factor(cluster))) +
    geom_line(alpha = 0.6) + 
    geom_point() +
    labs(x = "Parcial (m)", 
         y = "Tiempo de Nado (segundos)", 
         color = "Cluster") +
    theme_minimal() +
    ggtitle(paste("Tiempos de Nado del Cluster", i))

  print(p)  # Imprime la gráfica
}
```

Para analizar mejor las estrategias, intentamos no fijarnos en el primer y último largo, ya que corresponden para todas las nadadoras, a largos en los que van más rápido.
Tras ver las tres gráficas, se ve que, las nadadoras pertenecientes al cluster 1, son nadadoras que empiezan relativamente rápido pero que con el paso de los metros, empiezan a subir de tiempos cada parcial.

Las nadadoras del cluster 2, se aprecia que sus parciales tienen una forma de U invertida, empiezan rápido, sobre la mitad de la prueba, es donde más lento van, y luego vuelven a acelerar.

Las nadadoras del último cluster, observamos que son nadadoras muy constantes en cuanto a los parciales.

Vamos a evaluar estas 3 últimas gráficas graficando los centroides de cada cluster:

```{r}
centroides <- as.data.frame(cluster800libres$centers)
centroides$cluster<- factor(rownames(centroides)) 
#Los vuelvo long: 
centroideslong <- centroides %>%
  pivot_longer(cols = c("50", "100", "150", "200", "250", "300", "350", 
                         "400", "450", "500", "550", "600", "650", 
                         "700", "750", "800"), 
               names_to = "splitdistance", 
               values_to = "splitswimtime")


# Gráfico
ggplot(centroideslong, aes(x = as.numeric(splitdistance), y = splitswimtime, color = cluster, group = cluster)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_viridis_d() +  # Colores amigables para daltónicos
  labs(x = "Split Distance (m)", y = "Split Swim Time (s)", color = "Centroide") +
  theme_minimal()

```

### Mejor cluster.

A continuación, vamos a evaluar cuál cluster tiene las mejores nadadoras, es decir, las nadadoras que pasaron a la final:

Vamos a ordenar el data frame *free800WomensNormalizado*:

```{r}
free800WomensNormalizado <- free800WomensNormalizado[order(free800WomensNormalizado$swimtime), ]

finalistas<-head(free800WomensNormalizado, 8)

conteo <- table(finalistas$cluster)
conteo
```

Observamos que, hay nadadoras tanto del 3er cluster como del 1ro (5 y 3).
Ahora, vamos a calcular la media de tiempos de cada cluster para ver "cuál" es el más rapido en media.

```{r}
media_swimtime_por_cluster <- aggregate(free800WomensNormalizado$swimtime ~ free800WomensNormalizado$cluster, data = free800WomensNormalizado, FUN = mean, na.rm = TRUE)

media_swimtime_por_cluster
```



##Cluster 100 mariposa femenino.

Vamos a escalar los datos de *prueba[,-1]* (los relativos al PCA de 100 mariposa femenimo), es decir, restamos la media y dividimos por la desviación estándar, para que cada columna tenga media 0 y desviación estándar 1.

```{r}
cluster100mariposafem <- scale(prueba[,-1])
cluster100mariposafem
```

Ahora, calculamos y visualizamos la matriz de distancias entre las observaciones de *cluster100mariposafem* (REVISAR)

```{r}
#Calulamos la matriz de distancias
distancias <- get_dist(cluster100mariposafem)
#Vemos la matriz de distancias como un mapa de calor
fviz_dist(distancias, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Aquí: - low = "#00AFBB" (azul claro) representa las distancias pequeñas entre observaciones.
- mid = "white" representa las distancias medias.
- high = "#FC4E07" (rojo) representa las distancias grandes.

Aplicamos el algoritmo de las k-medias con k=2 con la función k-means, ejecutando el algoritmo 25 veces, por ejemplo

```{r}
k100Mariposafemenino <- kmeans(cluster100mariposafem, centers = 2, nstart = 25)
k100Mariposafemenino
```

La técnica aplicada genera 2 agrupaciones de 48 y 21 observaciones cada una.
Además se especifica a qué conglomerado pertenece cada asignación (por ejemplo, Borshi pertenece al la agrupación 2, Nobrega a la 2, Mckeon a la 1...)

Ahora, visualicemos los resultados con fviz_cluster

```{r}
fviz_cluster(k100Mariposafemenino, data =cluster100mariposafem)
```

Observamos gráficamente las dos agrupaciones mencionadas.

```{r}
rm(cluster100mariposafem, k100Mariposafemenino, prueba, prueba100MariposaFem, distancias)
```

## Cluster 200 mariposa masculina.

```{r}
clusterprueba200 <- scale(pruebita[,-1])

summary(clusterprueba200)
```

```{r}
distancias <- get_dist(clusterprueba200)
fviz_dist(distancias, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k200 <- kmeans(clusterprueba200, centers = 2, nstart = 25)
str(k200)
```

```{r}
fviz_cluster(k200, data = clusterprueba200)
```

Como vemos, con 2 clusters nos divide a los participantes según el tiempo de reacción (vemos como el 5, que ya habiamos mencionado, aparece en los más rápidos).
Los medios, son más, y están en el rojo.

Realmente parece que dos grupos no son suficientes.
Vamos a verlo empíricamente.

```{r}
# Reproducible
set.seed(123)

fviz_nbclust(clusterprueba200, kmeans, method = "wss")
```

Parece que deberiamos aumentar el número de grupos, incluso 5 grupos.
A partir de 5 grupos, parece muy baja mejora.

Utilizamos otros métodos.
Para ello, como el de la silueta.

```{r}
fviz_nbclust(clusterprueba200, kmeans, method = "silhouette")
```

Parece que con dos grupos, podemos excluir a valores muy discriminados en nuestro estudio.
Luego, depende de si nuestro objetivo es encontrar valores peculiares.

Probamos con k=5

```{r}
k5_200 <- kmeans(clusterprueba200, centers = 5, nstart = 25)

fviz_cluster(k5_200, data = clusterprueba200)
```

El cluster 5 representa un grupo de nadadores que tienen un comportamiento peculiar en cuanto a los tiempos de reacción, y la edad no parece ser un factor determinante para ellos.

El grupo azul (cluster 4) tiene varias observaciones distribuidas más arriba a la derecha del gráfico, a lo largo de Dim1.
Estos nadadores parecen tener una mayor edad y mayor tiempo de reacción.
Esto tiene sentido, ya que el eje de Dim1 parece estar relacionado con el rendimiento en la prueba (donde mayor puntuación indicaría menor rendimiento).

Este cluster verde está ubicado hacia el centro del gráfico, alrededor del origen de los ejes de Dim1 y Dim2.
Esto sugiere que los nadadores en este grupo tienen un rendimiento promedio o neutral en las variables consideradas (edad y tiempo de reacción).

Los puntos 5 y 26 están en un cluster aislado, probablemente por tener características atípicas en cuanto a su tiempo de reacción, pero con una edad no influyente.
El cluster azul representa a nadadores mayores con tiempos de reacción más lentos, lo que afecta negativamente su rendimiento.
Los otros clusters agrupan a los nadadores con características más cercanas entre sí en cuanto a edad y tiempos de reacción.

## Cluster divisivo 200.

```{r}
# Clustering jerárquico divisivo
hc200 <- diana(clusterprueba200)

# Coeficiente de división; cantidad de estructura de agrupación encontrada
hc200$dc
```

Podemos proceder a realizar el dendograma(cercano a 1).

```{r}
# Drendrograma
pltree(hc200, cex = 0.6, hang = -1, main = "Dendrogram de DIANA")
```

Utilizamos k=5

```{r}
# Método de Ward
# Matriz de disimilaridades
d200 <- dist(clusterprueba200, method = "euclidean")
hc5_200 <- hclust(d200, method = "ward.D2" )

# Cortamos en 4 clusters
sub_grp <- cutree(hc5_200, k = 5)

# Visualizamos el corte en el dendrograma
plot(hc5_200, cex = 0.6)
rect.hclust(hc5_200, k = 5, border = 2:5)
```

Veamos si coincide con los clusters anteriores

```{r}
# Visualización
#Cluster realizado con el método de división
fviz_cluster(list(data=clusterprueba200,cluster=sub_grp))

#Cluster realizado con kmeans
fviz_cluster(k5_200, data = clusterprueba200)
```

Vemos que coinciden.

## Cluster para la prueba de 1500 masculina

```{r}
# escalado de todas las variables
clusterprueba1500 <- scale(prueba1500[,-1])

summary(clusterprueba1500)
```

```{r}
distance <- get_dist(clusterprueba1500)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k2 <- kmeans(clusterprueba1500, centers = 2, nstart = 25)
str(k2)
```

```{r}
fviz_cluster(k2, data = clusterprueba1500)
```

Como vemos, con 2 clusters nos divide a los participantes según la velocidad.
Es decir, los que pertenecen al cluster rojo serían los de tiempos más altos, y los azules los que están en mejores posiciones de resultados.

Nos preguntamos, si el número óptimo de clústeres para dividir a nuestro grupo total es realmente 2, o podemos dividirlos en más grupos.
Para ello, utilizamos el método del codo.

```{r}
# Reproducible
set.seed(123)

fviz_nbclust(clusterprueba1500, kmeans, method = "wss")
```

Parece que sí que tenemos una mejoría si continuamos diviendo nuestro grupo en 3 o incluso 4.
Por encima de estos números, no obtenemos grandes mejoras en nuestro análisis.

Por tanto, probamos con k=3 y k=4 y observamos los resultados

```{r}
k3 <- kmeans(clusterprueba1500, centers = 3, nstart = 25)

fviz_cluster(k3, data = clusterprueba1500)
```

```{r}
k4 <- kmeans(clusterprueba1500, centers = 4, nstart = 25)

fviz_cluster(k4, data = clusterprueba1500)
```

Como podemos observar en ambos gráficos, la segregación de nadadores sigue estando bastante influida por su posición relativa al eje x.
Es decir, nos clasifica los grupos según sus velocidades.
Con 3 clústeres, tendríamos los nadadores lentos, los intermedios, y los muy rápidos.
En el segundo gráfico con 4 clusteres, podemos observar los grupos muy lentos (prácticamente valores outiers), los centrales divididos en mas y menos lentos y un último grupo, de competidores de alta calificación.
Observando ambos, los dos grupos de la derecha contienen prácticamente los mismos puntos.
Sin embargo,si que existe una división entre los puntos de la izquierda.
La elección de k=3 o k=4 vendrá por el interés del estudio que queramos realizar.
Si no nos interesan los nadadores de peor cualificación, no será necesario segregar a los nadadores en 4 grupos.
Sin embargo, si queremos analizar estos nadadores con peores marcas parece interesante ajustarnos a un nivel de k=4.

Utilizamos otros métodos para decidir si nuestro razonamiento es correcto.
Para ello, utilizamos el método de "silueta" y el método "GAP".

```{r}
fviz_nbclust(clusterprueba1500, kmeans, method = "silhouette")
```

```{r}
set.seed(123)
gap_stat <- clusGap(clusterprueba1500, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)

print(gap_stat, method = "firstmax")
fviz_gap_stat(gap_stat)
```

Utilizando estos dos últimos métodos, nos dan el resultado de que el número óptimo de clústers son dos en "silueta" y uno en "Gap".
Puesto que cada método nos determina un número distinto de k, utilizaremos la división en grupos según el objetivo a tratar, como hemos comentado recientemente.

##Cluster jerarquico prueba de 1500 metros masculina

### Cluster aglomerativo. AGNES.

Queremos hacer un cluster jerárquico de nuestra prueba.
Para ello, calculamos el valor del coeficiente aglomerativo

```{r}
# Clustering jerárquico usando enlace completo
hc2 <- agnes(clusterprueba1500, method = "complete" )

hc2$ac
```

El coeficiente aglomerativo tiene un valor cercano al 1, con lo que sugiere una fuerte estructura de agrupamiento.
Vamos ahora a evaluar qué metodo nos da un coeficiente mayor y emplearemos esa estructura de agrupacion con el objetivo de conseguir una estructura de agrupación más fuerte.

```{r}
# Métodos evaluados
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# Función para calcular el coeficiente de agrupamiento
ac <- function(x) {
  agnes(clusterprueba1500, method = x)$ac
}

map_dbl(m, ac)
```

Como vemos, lo conseguimos con el método ward.
Por tanto, utilizamos ese método para realizar el dendrograma

```{r}
# Matriz de disimilaridades
d <- dist(clusterprueba1500, method = "euclidean")

# Clustering jerárquico usando enlace completo
hc1 <- hclust(d, method = "ward" )

# Dendrograma
plot(hc1, cex = 0.6, hang = -1)
```

Interpretando el dendrograma, vemos como los primeros pasos de agrupamiento son entre distintas muy pequeñas.
Por tanto, no tiene sentido cortar en esas etapas iniciales.
El gráfico parece sugerir la aglomeración en 3 grupos.

##Cluster divisivo.
DIANA.

Calculamos ahora el coeficiente de división.

```{r}
# Clustering jerárquico divisivo
hc4 <- diana(clusterprueba1500)

# Coeficiente de división; cantidad de estructura de agrupación encontrada
hc4$dc
```

Como podemos ver, tenemos un coeficiente de división cercano al 1.
Con lo cual, podemos proceder a realizar el dendograma.

```{r}

# Drendrograma
pltree(hc4, cex = 0.6, hang = -1, main = "Dendrogram de DIANA")
```

Utilizamos ahora la función "cutree" para dividir nuestro dendrograma en los clústers que consideremos.
En este caso, utilizamos k=4

```{r}
# Método de Ward
hc5 <- hclust(d, method = "ward.D2" )

# Cortamos en 4 clusters
sub_grp <- cutree(hc5, k = 4)

# Visualizamos el corte en el dendrograma
plot(hc5, cex = 0.6)
rect.hclust(hc5, k = 4, border = 2:5)
```

Veamos si coincide con los clusters que hemos considerado en el apartado previo

```{r}
# Visualización
#Cluster realizado con el método de división
fviz_cluster(list(data=clusterprueba1500,cluster=sub_grp))

#Cluster realizado con kmeans
fviz_cluster(k4, data = clusterprueba1500)
```

Como vemos, las divisiones son similares, pero no son iguales.
Esto se debe al método de agregación que difiere en ambos casos.

A su vez, comparamos si los dendrogramas utilizados para agregar o dividir son isomorfos.

```{r}

# Matriz de distancias
res.dist <- dist(clusterprueba1500, method = "euclidean")

# Calcuamos los dos clustering jerárquicos
hc1 <- hclust(res.dist, method = "ward")
hc2 <- hclust(res.dist, method = "ward.D2")

# Dendrogramas
dend1 <- as.dendrogram (hc1)
dend2 <- as.dendrogram (hc2)

# los enfrentamos
tanglegram(dend1, dend2)
```

Como podemos observar, no nos dan dendrogramas isomorfos puesto que los dos métodos manejan de manera diferente las distancias entre grupos durante el proceso de fusión.

```{r, warning=FALSE}
rm(clusterprueba1500, clusterprueba200, datos1500Masc, dend1, dend2, hc1, hc2, hc200, hc4, hc5, hc5_200, k2, k200, k3, k4, k5_200, pca_1500masculino, prueba1500, prueba200MariposaMasc, pruebita, d, d200, distance, distancias, ac, sub_grp, res.dist, m)
```

```{r, warning=FALSE}
rm(centroides, centroideslong, cluster800libres, componentess, finalistas, free800WomensNormalizado, free800WomensPre, gap_stat, media_swimtime_por_cluster, auto, conteo, p, prueba200MariposaMasc2, prueba800libresPreliminar, prueba800long, R, i, Cor_CompVar, Cor_CompVar_retenidos)
```



# Objetivo del análisis y partición de los datos. 

En esta sección y tras haber hecho un EDA genérico sobre los datos que tenemos, vamos a proseguir analizando de manera más específica los datos que tenemos. Nuestro objetivo en este trabajo es PREDECIR de alguna manera si los nadadores que llegan a la final, van a bajar su tiempo en esa prueba (tomarán el valor 1), o si en cambio, no lo harán (tomarán el valor 0). Bien, para ello, vamos a proceder a continuación a crear la tabla que nos ayudará a poder hacerlo. 

A partir de este momento, vamos a estudiar acerca de un target.
En este caso, nuestro target, ver si los finalistas van a mejorar su tiempo respecto a la ronda anteriormente nadada.
Por lo que, vamos a quedarnos con el conjunto de nadadores que están clasificados a la final de cada prueba, y su tiempo en la ronda anterior.
Para ello, voy a ir dividiendo los datos por cada distancia.
Elegiré los nadadores que nadaron la final y la semifinal.
Pero filtrando los semifinalistas

```{r}
#Me quedo con los finalistas de las pruebas de 50, 100 y 200:
finalistas1<-datos2015[datos2015$round=="FIN" & datos2015$distance %in% c(50,100,200),]

condicionFiltro<-unique(finalistas1[,c("athleteid", "distance", "stroke")])

#Me quedo con los semifinalistas de las pruebas de 50, 100 y 200: 
semifinalistas1<-datos2015[datos2015$round=="SEM" & datos2015$distance %in% c(50,100,200),]

#Ahora, los filtro para que cumplan esa condición de Filtro.
semifinalistasFiltrados <- merge(semifinalistas1, condicionFiltro, by = c("athleteid", "distance", "stroke"))

#Ahora, hago la unión.

dataframe1 <- rbind(finalistas1, semifinalistasFiltrados)


#Ahora, hago el mismo proceso para las pruebas de 400, 800 y 1500 pero con las finales y preliminares: 

finalistas2<-datos2015[datos2015$round=="FIN" & datos2015$distance %in% c(400,800,1500),]
condicionFiltro<-unique(finalistas2[,c("athleteid", "distance", "stroke")])

semifinalistas2<-datos2015[datos2015$round=="PRE" & datos2015$distance %in% c(400,800,1500),]

#Ahora, los filtro para que cumplan esa condición de Filtro.
semifinalistasFiltrados2 <- merge(semifinalistas2, condicionFiltro, by = c("athleteid", "distance", "stroke"))

#Ahora, hago la unión.

dataframe2 <- rbind(finalistas2, semifinalistasFiltrados2)


#Ahora, hago la unión de mis datos: 

datos2015Target<-rbind(dataframe1, dataframe2)


#Los voy a ordenar por prueba y nombre. 

datos2015Target<-datos2015Target[order(datos2015Target$stroke, datos2015Target$athleteid, datos2015Target$distance), ]


rownames(datos2015Target)<-NULL

```

```{r}
rm(condicionFiltro, dataframe1, dataframe2, finalistas1, finalistas2, semifinalistas1, semifinalistas2, semifinalistasFiltrados, semifinalistasFiltrados2)
```

Vamos a calcular la media, desviación típica, mínimo y máximo de cada parcial:

```{r}
#hacemos un long to wide.

datos2015Target$split<-NULL
datos2015Target$cumswimtime<-NULL

datos2015TargetLong <- datos2015Target %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas

#Una vez hecho, vamos a calcular la media, desviación típica, mínimo y máximo de cada parcial.


datos2015TargetLong$mediaParciales<- rowMeans(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], na.rm=TRUE)

datos2015TargetLong$minimoParciales<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, min, na.rm=TRUE)

datos2015TargetLong$maximoParciales<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, max, na.rm=TRUE)


datos2015TargetLong$sdParcial<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, sd, na.rm=TRUE)

datos2015TargetLong$medianaParciales<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, median, na.rm=TRUE)

datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")]<-NULL



rm(datos2015Target)
```

Ahora, busco que, para cada nadador que nada la final en una prueba de una distancia determinada, en sus columnas aparezcan las variables de las finales y las semifinales a la vez.
Para ello: Voy a dividir el dataframe datos2015TargetLong en 2, uno con los finalistas y otro con los semifinalistas.

```{r}
dataframe1<-datos2015TargetLong[datos2015TargetLong$round=="FIN", ]
dataframe2<-datos2015TargetLong[datos2015TargetLong$round == "PRE" | datos2015TargetLong$round== "SEM", ]

#Voy a cambiar los nombres de las variables para que, al hacer el merge, se puedan ver las variables de manera intuitiva.

dataframe1 <- dataframe1 %>%
  rename(
    eventidF= eventid,
    heatF= heat,
    laneF= lane,
    pointF= points,
    reactiontimeF= reactiontime,
    swimtimeF = swimtime,
    daytimeF= daytime,
    mediaParcialesF= mediaParciales,
    minimoParcialesF= minimoParciales,
    maximoParcialesF= maximoParciales,
    sdParcialF= sdParcial,
    medianaParcialesF= medianaParciales
  )

dataframe2<- dataframe2%>%
  rename(
    eventidP= eventid,
    heatP= heat,
    laneP= lane,
    pointP= points,
    reactiontimeP= reactiontime,
    swimtimeP = swimtime,
    daytimeP= daytime,
    mediaParcialesP= mediaParciales,
    minimoParcialesP= minimoParciales,
    maximoParcialesP= maximoParciales,
    sdParcialP= sdParcial,
    medianaParcialesP= medianaParciales
  )
#Ahora, quiero hacer un join por athleteid, distance, stroke: 

datos2015Target <- merge(dataframe1, dataframe2, by = c("athleteid", "distance", "stroke"), all = FALSE)

# Eliminar una o varias columnas
datos2015Target <- datos2015Target %>% select(-round.x, -lastname.y, -firstname.y, -gender.y, -name.y, -code.y, -round.y, -edad.y)

#Renombro aquellas que tienen el .x o .y:

datos2015Target<- datos2015Target%>%
  rename(
    lastname= lastname.x,
    firstname= firstname.x,
    gender= gender.x,
    name= name.x,
    code= code.x,
    edad= edad.x
  )



```

```{r}
rm(dataframe1, dataframe2, datos2015TargetLong )
```

Bien, me falta ahora, añadir el target:

```{r}

# Crear la nueva variable target según la condición
datos2015Target$target <- ifelse(datos2015Target$swimtimeF - datos2015Target$swimtimeP < 0, 1, 0)

```

Si visualizo al primer nadador:


```{r}
head(datos2015Target,1)
```

Observo que Joseph Schooling, nadó la final más rapido que la final, por lo que tienen de target un 1.

## Partición de los datos.

La repartición de nuestros datos, será sobre las finales.
En total, tengo 8 nadadores por cada final, 2 sexos.
En las pruebas de 50 y 100 tengo 4 estilos, lo que suma 128 nadadores.
También, tengo en las pruebas de 200, 8 nadadores, 2 sexos y 5 estilos, lo que suma 80.
En el 400 tengo 8 nadadores, 2 sexos y 2 estilos, lo que suma 32 nadadores.
En el 800 y 1500 tengo 8 nadadores por cada sexo, lo que hace un total de 32 nadadores.

La suma total es de 272 nadadores, aunque debemos tener en cuenta que hubo una baja en la final del 1500 masculino, luego será de 271 nadadores.

Vamos a ver si estas cuentas son ciertas de la siguiente manera:

```{r}
nadadoresFinalistas<-nadadoresPruebas[nadadoresPruebas$round=="FIN", ]
rownames(nadadoresFinalistas) <- 1:nrow(nadadoresFinalistas)

```

```{r}
dim(nadadoresFinalistas)
```

Luego, observamos que sí, estamos en lo cierto.
Ahora, voy a hacer la repartición de mis datos sobre el dataframe creado anteriormente:

```{r}
n=nrow(datos2015Target)
set.seed(1312)
indices_validation= sample(1:n, n*0.1)
indices_entrenamiento= c(1:n)[-indices_validation]

#he dividido los datos, ahora, cojo los de entreno y divido otra vez. 
n_entrenamiento=length(indices_entrenamiento)
set.seed(2910)
indices_train=sample(indices_entrenamiento, 0.8*n_entrenamiento)
indices_test=c(1:n)[-c(indices_validation, indices_train)]
#reinicio las filas por si acaso:
rownames(datos2015Target) <- NULL
#hago la repartición:
datos2015Target_train=datos2015Target[indices_train,]
datos2015Target_test= datos2015Target[indices_test, ]
datos2015Target_validation=datos2015Target[indices_validation, ]

```


```{r}
# Elimino las tablas que no voy a usar: 

rm(datos2015, nadadoresParticipantes, nadadoresPruebas, nadadoresParticipantesCopia, nadadoresPruebasCopia, nadadoresFinalistas )
```

# Análisis previo de los datos.

Antes de comenzar nuestro estudio, vamos a evaluar el total de nadadores que sí bajan de tiempo y el total que NO lo hacen. Lo hacemos: 

```{r}
datos2015Target_train$target <- as.factor(datos2015Target_train$target)
summary(datos2015Target_train$target)

112/(112+83)
```
Luego, un 0.57% baja de marca. Luego, tiene sentido intentar buscar mediante medidas de rendimiento, esas predicciones sobre nuevas observaciones. Vamos a evaluar todos los modelos de rendimiento vistos en teoría, y elegiremos el (los) que nos aporten un mayor rendimiento en las medidas (DECIDIRLAS).


## Posibles variables que influyan en la respuesta.

A continuación, voy a evaluar en mi conjunto de datos, si existe algún patrón que nos pueda decir si las nadadoras bajan o no de tiempo, es decir, si alguna variable dictamina más que otras. Para ello, voy a empezar analizando la edad. Voy a evaluar si existe algún tipo de relación entre la edad y si bajan o no tiempo. Para ello:

```{r}
# Agrupar edades en intervalos (por ejemplo, cada 5 años)
df<-datos2015Target_train
df <- df %>%
  mutate(grupo_edad = cut(edad, breaks = seq(10, 45, by = 5), right = FALSE))

## Calcular el porcentaje de nadadores que bajan (1) y que no bajan (0) por grupo de edad
porcentajes <- df %>%
  group_by(grupo_edad, target) %>%
  summarise(total = n(), .groups = "drop") %>%
  group_by(grupo_edad) %>%
  mutate(porcentaje = total / sum(total) * 100)

# Graficar: Gráfico de barras de porcentaje
ggplot(porcentajes, aes(x = grupo_edad, y = porcentaje, fill = factor(target))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Porcentaje de Nadadores que Bajan y No Bajan por Grupo de Edad",
    x = "Grupo de Edad",
    y = "Porcentaje",
    fill = "¿Bajan?"
  ) +
  theme_minimal()
```

Parece que, a partir de los 30 años, hay más porcentaje de nadadores que no consiguen bajar la marca. Parece haber relación, luego lo tendremos en cuenta. 

```{r, echo=FALSE}
rm(conteo, df, porcentajes)
```

Continuamos nuestro estudio haciendo algo muy similar con los estilos. Es decir, ¿alguno de los 5 estilos tiene relación con que se baje la marca? Lo vemos en el siguiente gráfico: 

```{r}
datos<- datos2015Target_train
# Calcular el porcentaje de nadadores que bajan (1) y que no bajan (0) por Stroke
porcentajes <- datos %>%
  group_by(stroke, target) %>%
  summarise(total = n(), .groups = "drop") %>%
  group_by(stroke) %>%
  mutate(porcentaje = total / sum(total) * 100)

# Graficar: Gráfico de barras de porcentaje
ggplot(porcentajes, aes(x = stroke, y = porcentaje, fill = factor(target))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Porcentaje de Nadadores que Bajan y No Bajan por Stroke",
    x = "Tipo de Stroke",
    y = "Porcentaje",
    fill = "¿Bajan?"
  ) +
  theme_minimal()
```

Bueno, parece que, hay algunos estilos mucho más influyentes que otros. Medley y Free, son estilos que parece que tienen un porcentaje alto de bajar. También el estilo braza no parece un estilo en el que se baje en las finales.

Prosigo el estudio haciendo lo mismo con las distancias: 

```{r}
datos<-datos2015Target_train
datos$distance<- as.factor(datos$distance)
# Calcular el porcentaje de nadadores que bajan (1) y que no bajan (0) por Stroke
porcentajes <- datos %>%
  group_by(distance, target) %>%
  summarise(total = n(), .groups = "drop") %>%
  group_by(distance) %>%
  mutate(porcentaje = total / sum(total) * 100)

# Graficar: Gráfico de barras de porcentaje
ggplot(porcentajes, aes(x = distance, y = porcentaje, fill = factor(target))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Porcentaje de Nadadores que Bajan y No Bajan por distancia",
    x = "Tipo de Stroke",
    y = "Porcentaje",
    fill = "¿Bajan?"
  ) +
  theme_minimal()
```

Aquí observamos que a partir de los 200 metros, suelen dejarse "algo" de energía para las finales, y allí si que bajan de tiempo. Luego parece que esto lo debemos ponderar. 

```{r, echo=FALSE}
rm(datos, porcentajes)
```



 

# Medidas de rendimiento.

En los modelos que vamos a calcular a continuación, nuestro objetivo va a ser que, cada vez que digamos que un nadador baja de tiempo, sea cierto, es decir, voy a intentar minimizar el error que se produce cuando predigo que un nadador SÍ baja de tiempo, pero en realidad no lo hace. Me interesa minimizar los falsos positivos. Por tanto, utilizaremos distintos modelos y evaluaremos su calidad mediante medidas de rendimiento que parten de la matriz de confusión, ya que nuestra variable objetivo es binaria (0,1). Comentaremos las principales métricas de rendimiento, haciendo mayor hincapié en las siguientes:

- Accuracy o Exactitud  $= \frac{TP + TN}{N}$. mide la proporción de predicciones correctas hechas por un modelo de clasificación. Es uno de los indicadores más utilizados para evaluar el desempeño de un modelo de clasificación. Intentaremos maximizar este valor.
- FPR (tasa de falsos positivos) $= \frac{FP}{FP+TN}$ Intentaremos minimizar este valor ya que mide la proporción de negativos reales que el modelo clasifica incorrectamente como positivos.
- Precisión $= \frac{FP}{FP+TN}$. Mide la proporción de casos correctamente clasificados como positivos entre todos los casos que el modelo ha clasificado como positivos. Intentaremos maximizar este valor.
Otras medidas se comentarán más adelante.

## K-vecinos.

El método de los k vecinos más cercanos (abreviatura de “k nearest neighbors” en inglés), se cuenta entre los enfoques más simples y ampliamente utilizados en el campo del ML. Este método se basa en la noción de similitud (o distancia) entre observaciones.

En un problema de clasificación, el algoritmo devolverá la clase que predomina entre los 
vecinos, es decir, la moda de la variable objetivo.

Para elegir el número k, seleccionamos aquel valor que minimice la tasa de errores, al mismo tiempo que preserva la capacidad del algoritmo para realizar predicciones precisas en datos no vistos previamente.

### Modelo 1.

Primeramente, vamos a probar introduciendo variables que razonablemente podrían determinar los mejores vecinos. Es importante que las variables seleccionadas sean informativas y relevantes para predecir el comportamiento objetivo.
Las variables introducidas, son las siguientes: 
- Athelteid: Esta variable podría ser útil si hay patrones repetitivos en el rendimiento de un mismo nadador a lo largo de las pruebas. 

- eventidF: es el id de evento de la final. Al introducir esta variable no es necesario introducir otras como son: el sexo, estilo y distancia, al agrupar a los nadadores por la misma competencia.

- reactionTimeF: Supondremos que vamos a predecir si los nadadores bajan justo en el momento en el que saltan. Esta variable es relevante para predecir si un nadador bajará su tiempo, si su tiempo de reacción en la final es pésimo, podría influir en la decisión de nuestro modelo.

- edad: También puede ser importante, ya que la edad puede influir en el rendimiento.

- eventidP: similar al EventidF, el evento preliminar puede agrupar a los nadadores que compiten en las mismas condiciones.  

- pointP: los puntos de las preliminares. 

- reactionTimeP: el tiempo de reacción de la prueba previa. 

- swimtimeP: el tiempo final de la prueba previa.

- daytimeP: la hora de la preliminar.

- mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP: son bastante útiles, ya que proporcionan información más detallada sobre el rendimiento del nadador a lo largo de la prueba. El promedio de los parciales puede indicar la consistencia del nadador. El máximo, el mínimo, la media, la mediana, pueden ayudar a identificar vecinos con características parecidas sobre cómo plantean la prueba.

A continuación, voy a entrenar un primer modelo fijándome en los 5 vecinos más proximos con todas las variables y usando la distancia euclídea entre observaciones y sin escalar los datos: 

```{r}
# Selecciono las variables. 

df <- datos2015Target_train %>% select(athleteid, eventidF, reactiontimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)

modelo1knn = knn3(df[,-14], as.factor(df$target), k=5, prob=TRUE)


```

Bien, voy a ver cómo de bien rinde mi modelo en el conjunto en el que se ha entrenado: 

```{r}
# Obtener las predicciones de clase y la matriz de confusión
set.seed(2945)
predicciones <- predict(modelo1knn, newdata = df[,-14], type = "class")
matrizconfusion1 <- confusionMatrix(predicciones, as.factor(df$target), positive = "1")
print(matrizconfusion1)
```

Tenemos en el conjunto de entrenamiento ya un accuracy bastante bajo, vamos a comprobar en los datos de tests, pero no parece ser un buen modelo: 

```{r}
df_test <-  datos2015Target_test %>% select(athleteid, eventidF, reactiontimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)

# Realizar predicciones en el conjunto de test
predicciones_test <- predict(modelo1knn, newdata = df_test[,-14], type = "class")
matrizconfusion2 <- confusionMatrix(predicciones_test, as.factor(df_test$target), positive = "1")
print(matrizconfusion2)

```


Es como lanzar una moneda al aire. No es un buen modelo. Vamos a probar a escalar, meter otras variables... También, Vamos a probar a bajar el número de vecinos próximos entre otras cosas. 


```{r, echo=FALSE}
rm(df, df_test, matrizconfusion1, matrizconfusion2)
```

### Modelo 2.

Dado que KNN depende de la distancia entre las observaciones, las variables con rangos más amplios podrían influir desproporcionadamente en los resultados. Por lo tanto, escalaremos antes de aplicar KNN y así todas las variables contribuirán equitativamente.

Para ello, cargo primeramente mis datos con las mismas variables que el modelo 1: 

```{r}
df <- datos2015Target_train %>% select(athleteid, eventidF, reactiontimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)

df_test <-  datos2015Target_test %>% select(athleteid, eventidF, reactiontimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)
```

A continuación, las escalo: 

```{r}
preProcValues <- preProcess(df[,-14], method = c("center", "scale"))
df_scaled <- predict(preProcValues, df[,-14])


#incluimos la columna target
df_scaled <- cbind(df_scaled, target = df$target)
df_scaled
```

Ahora, voy a usar validación cruzada para tratar de encontrar el mejor k. Es decir, el mejor número de obsevaciones más próximas (vecinos) en los que me dejo fijar. 

```{r}
# Crear un rango de valores de k
tuneGrid <- expand.grid(k = seq(1, 20, by = 1))  

# Configuración para validación cruzada
control <- trainControl(method = "cv", number = 10)  
# Entrenar el modelo KNN con validación cruzada
set.seed(123)
knnFit <- train(target ~ ., 
                data = df_scaled, 
                method = "knn", 
                trControl = control, 
                tuneGrid = tuneGrid, 
                preProcess = c("center", "scale")) 
# Mejor valor de k
best_k <- knnFit$bestTune$k
print(paste("El mejor valor de k es:", best_k))

# Visualizar los resultados de cada k
plot(knnFit)

```

Bien, visto que el mejor es k=3, vamos a continuación a evaluar mi modelo con k=3 y escalando: 

```{r}
set.seed(1466)
#Entrenar el modelo KNN con el mejor k encontrado, que es 3
modelo2knn <- knn3(df_scaled[,-14], as.factor(df_scaled$target), k = 3, prob = TRUE)

# Predicciones para el conjunto de entrenamiento
predicciones_train_best <- predict(modelo2knn, newdata = df_scaled[,-14], type = "class")

# Tabla de confusión
table(Predicted = predicciones_train_best, Actual = df_scaled$target)


# Ahora las obtenemos para los datos de test para ver si se pierde o se gana: 
# Escalar el conjunto de prueba
df_test_scaled <- predict(preProcValues, df_test %>% select(-target))  # Escalar todas menos el target

# Predicciones para el conjunto de prueba escalado
predicciones_test_best <- predict(modelo2knn, newdata = df_test_scaled[,-14], type = "class")

# Tabla de confusión
table(Predicted = predicciones_test_best, Actual = df_test$target)


# Tabla de confusión
conf_matrix_train <- confusionMatrix(predicciones_train_best, as.factor(df_scaled$target),positive= "1")

# Mostrar la matriz de confusión y las métricas asociadas
print(conf_matrix_train)


# Tabla de confusión
conf_matrix_test <- confusionMatrix(predicciones_test_best, as.factor(df_test$target),positive= "1")

# Mostrar la matriz de confusión y las métricas asociadas
print(conf_matrix_test)


```
El modelo tiene un buen rendimiento en el conjunto de entrenamiento con una precisión alta (78.9%) y un equilibrio razonable entre sensibilidad y especificidad. Esto indica que el modelo está capturando patrones en los datos de entrenamiento.

(JURARÍA QUE NO TIENE ESA PRECISIÓN)
Luego,tiene mejor precisión general en el conjunto de entrenamiento (78.9% frente a 72.5% antes). Clasifica mejor la clase 1 tanto en entrenamiento como en prueba.

```{r}
rm(conf_matrix_test, conf_matrix_train, control, df, df_scaled, df_test, df_test_scaled, knnFit, preProcValues, tuneGrid)
```


### Modelo 3.

A continuación, vamos a probar a usar ese k=3, pero ahora SIN escalar. Veamos qué resultado obtenemos: 

```{r}
# Creo las tablas: 
df <- datos2015Target_train %>% select(athleteid, eventidF, reactiontimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)

df_test<- datos2015Target_test%>% select(athleteid, eventidF, reactiontimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)

```


```{r}
set.seed(125)
#Entrenar el modelo KNN con el mejor k encontrado
modelo3knn <- knn3(df[,-14], as.factor(df$target), k = 3, prob = TRUE)

# Predicciones para el conjunto de entrenamiento
predicciones_train_best2 <- predict(modelo3knn, newdata = df[,-14], type = "class")

# Tabla de confusión
tabla_train2<- table(Predicted = predicciones_train_best2, Actual = df$target)


predicciones_test_best2 <- predict(modelo3knn, newdata = df_test[,-14], type = "class")

# Tabla de confusión
tabla_test2<- table(Predicted = predicciones_test_best2, Actual = df_test$target)



# Tabla de confusión calculada para que aparezcan los parámetros asociados
conf_matrix_train <- confusionMatrix(predicciones_train_best2, as.factor(df$target),positive= "1")

# Mostrar la matriz de confusión y las métricas asociadas
print(conf_matrix_train)



# Tabla de confusión calculada para que aparezcan los parámetros asociados
conf_matrix_test <- confusionMatrix(predicciones_test_best2, as.factor(df_test$target),positive= "1")

# Mostrar la matriz de confusión y las métricas asociadas
print(conf_matrix_test)

```

El modelo tiene un buen desempeño en el conjunto de entrenamiento, con una precisión razonable (79.4%) y un balance entre sensibilidad y especificidad.

El modelo generaliza mejor en este caso (precisión del 73.3%), lo que sugiere una mejora significativa respecto a versiones previas.
La sensibilidad para la clase 0 es aceptable (62.5%), aunque podría mejorarse.


```{r, echo=FALSE, warning=FALSE}
# Elimino lo que no sirve más: 

rm(df, df_test,conf_matrix_test, conf_matrix_train, best_k, predicciones, predicciones_test, predicciones_test_best, predicciones_test_best2, predicciones_train_best, predicciones_train_best2, tabla_test2, tabla_train2)
```

### Modelo 4.

Otra forma de variar nuestro método es mediante la variación en las variables introducidas. Variables anteriormente introducidas como athleteid, eventid pueden no estar influyendo. Además, estas variables son de tipo factor. Por lo tanto, al no distribuirse de manera lineal, calcular las distancias euclídeas podría no ser la forma correcta para clasificar a nuestros atletas. 
En este apartado, analizaremos el método Knn sin estas variables.

```{r}
# Selección de variables y normalización
kn3 <- datos2015Target_train %>%
  select(reactiontimeF, edad, pointP, reactiontimeP, swimtimeP, 
         mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)

kn3_test <- datos2015Target_test %>%
  select(reactiontimeF, edad, pointP, reactiontimeP, swimtimeP, 
         mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)

# Normalización de las variables predictoras 
kn3[, 1:9] <- scale(kn3[, 1:9])  # Normaliza todas las columnas predictoras (no la variable target)
kn3_test[, 1:9] <- scale(kn3_test[, 1:9])  

# Entrenamiento del modelo k-NN
trainControl <- trainControl(method="repeatedcv", number=10, repeats=3)  # Usar validación cruzada

set.seed(128)  # Para asegurar reproducibilidad
fit.knn3 <- train(as.factor(target) ~ ., data = kn3, method = "knn", metric = "Accuracy", trControl = trainControl)

# Obtener el mejor valor de k
knn.k3 <- fit.knn3$bestTune 
plot(knn.k3)
print(fit.knn3)  # Imprimir el resultado

```

Como podemos observar, el modelo con mejor valor en accuracy es el k=7. Tenemos muy cerca también el de k=5. 

```{r}
# Entrenar el modelo k-NN con el mejor k
set.seed(125)
modelo4knn <- train(target ~ ., data = kn3, method = "knn", 
                   trControl = trainControl, tuneGrid = data.frame(k = 7))

# Predicciones para el conjunto de entrenamiento
predicciones_train_best3 <- predict(modelo4knn, newdata = kn3)

# Tabla de confusión para el conjunto de entrenamiento
table(Predicted = predicciones_train_best3, Actual = kn3$target)

# Predicciones para el conjunto de prueba
predicciones_test_best3 <- predict(modelo4knn, newdata = kn3_test)

# Tabla de confusión para el conjunto de prueba
table(Predicted = predicciones_test_best3, Actual = kn3_test$target)



# Tabla de confusión
conf_matrix_train <- confusionMatrix(predicciones_train_best3, as.factor(kn3$target),positive= "1")

# Mostrar la matriz de confusión y las métricas asociadas
print(conf_matrix_train)


# Tabla de confusión
conf_matrix_test <- confusionMatrix(predicciones_test_best3, as.factor(kn3_test$target),positive= "1")

# Mostrar la matriz de confusión y las métricas asociadas
print(conf_matrix_test)


```

Como vemos, el accuracy en un primer lugar estaría en un 68%. Sin embargo, al ajustar los datos a test, nos resulta en un 46%. Por lo que nuestro modelo es bastante deficiente. 
Observación: hallamos las mismas matrices con k=5. Con lo que volvemos a obtener un 46%. Debemos abandonar este modelo.

```{r, echo=FALSE, warning=FALSE}
#elimino cosas: 
rm(conf_matrix_test, conf_matrix_train, fit.knn3, kn3, kn3_test, knn.k3, trainControl, predicciones_test_best3, predicciones_train_best3)
```



### Modelo 5. 

En este último modelo, vamos a probar a usar una función que proporciona la librería Caret, la cual va a tratar de darnos la mejor selección de variables. Para ello, seleccionamos primero todas las variables posibles que podríamos considerar meter: 

```{r}
df <- datos2015Target_train %>% select(target, athleteid, distance, eventidF, reactiontimeF, daytimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)

df_test <-  datos2015Target_test %>% select(target, athleteid, distance, eventidF, reactiontimeF, daytimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)

```


A continuación, uso la librería caret: 

```{r, warning=FALSE, echo=FALSE}
rownames(df)<- NULL
set.seed(33321)
control <- rfeControl(functions = caretFuncs, method = "cv", number = 8)
variablesSeleccionadas <- rfe(
  df[,-1],              # Variables predictoras
  df$target,  # Variable objetivo
  metric= "Accuracy",
  sizes = c(1:15),           # Cantidad de variables a probar
  rfeControl = control,
  method = "knn"
)

# Ver las variables seleccionadas
print(variablesSeleccionadas)
```

Observo el modelo con 3 variables a ver cómo funciona: 

```{r}
df <- datos2015Target_train %>% select(target, swimtimeP, mediaParcialesP, medianaParcialesP)
df_test <-  datos2015Target_test %>% select(target, swimtimeP, mediaParcialesP, medianaParcialesP )

```

Una vez hechas las mulitplicaciones correspondientes, vamos a calcular nuestro modelo K-vecinos: 

```{r}
modelo5knn = knn3(df[,-1], as.factor(df$target), k=3, prob=TRUE)
set.seed(3838)
predicciones <- predict(modelo5knn, newdata = df[,-1], type = "class")
matrizconfusion1 <- confusionMatrix(predicciones, as.factor(df$target), positive = "1")
print(matrizconfusion1)

# Ahora en test: 
# Realizar predicciones en el conjunto de test
predicciones_test <- predict(modelo5knn, newdata = df_test[,-1], type = "class")
matrizconfusion2 <- confusionMatrix(predicciones_test, as.factor(df_test$target), positive = "1")
print(matrizconfusion2)

```

Observo que tiene un accuracy de 0.774 en Train y 0.61 en test. No es el mejor modelo pero nos ha sacado uno de los mejores que nos puede proveer k-vecinos para los datos que manejamos. 

```{r, echo=FALSE}
rm(control, variablesSeleccionadas, df, df_test, matrizconfusion1, matrizconfusion2, predicciones, predicciones_test)
```


### knn (S)(resumen y decision)

1. Evaluación del Primer Modelo KNN(sin escalar y k = 5). Incluye todas las variables, incluidas las categóricas como athleteidy eventidF. En el entrenamiento, Accuracy, 0,797 (79,7%),tasa de falsos positivos ( FPR): 0,434 (43,4%). En prueba,Accuracy, 0,733 (73,3%),tasa de falsos positivos ( FPR): 0,5 (50%).

Este modelo muestra un desempeño aceptable, pero tiene un problema notable de generalización, ya que la precisión en el conjunto de prueba es significativamente menor que en el conjunto de entrenamiento.

2. Modelo KNN Escalado. Las variables se escalaron para garantizar que todas tengan una contribución equitativa. Se utilizó validación cruzada para encontrar el mejor k. Mejor valor de k encontrado: 3 .
En entrenamiento, la precisión ( Accuracy): 0,78. Y en prueba, 0,5.

3. Modelo k=3 sin escalar. Entrenamiento,0,7641 (76,41%). Esto significa que el modelo clasifica correctamente el 76,41% de los datos en el conjunto de entrenamiento.En prueba 0,6735 (67,35%).
El modelo clasifica correctamente el 67,35% de los datos en el conjunto de prueba.

4. Modelo KNN Simplificado (Sin Variables Categóricas).Variables categóricas como athleteidy eventidFse eliminaron. Solo se incluyen variables numéricas relevantes. Se probaron diferentes valores de k y se encontró que k = 7 es el mejor.En entrenamiento, la precisión ( Accuracy): 0.680 (68%).En prueba, la precisión ( Accuracy): 0,460 (46%).
Conclusión: El modelo sin variables categóricas y con solo variables numéricas tiene un rendimiento notablemente inferior. La eliminación de información clave (como identificadores o categorías relevantes) ha afectado la capacidad del modelo para predecir correctamente.


Basándome en los resultados que se presentaron, el modelo KNN con k=3 sin escalar y usando todas las variables predictoras muestra el mejor desempeño tanto en el conjunto de entrenamiento como en el de prueba.

```{r}
# Obtener probabilidades para cada modelo

# 1. KNN sin escalar con todas las variables
pred_probs_knn_no_scale <- predict(prob1, newdata = df_test[,-14], type = "prob")[, 2]

# 2. KNN escalado
pred_probs_knn_scaled <- predict(knn_best, newdata = df_test_scaled[,-14], type = "prob")[, 2]

# 3. KNN sin escalar k=3
pred_probs_knn_es_3 <- predict(knn_best2, newdata = df_test[,-14], type = "prob")[, 2]

# 4. KNN con variables seleccionadas
pred_probs_knn_selected <- predict(knn_best3, newdata = kn3_test, type = "prob")[, 2]

# Generar las curvas ROC para cada modelo
roc_knn_no_scale <- roc(df_test$target, pred_probs_knn_no_scale)
roc_knn_scaled <- roc(df_test$target, pred_probs_knn_scaled)
roc_knn_es_3 <- roc(df_test$target, pred_probs_knn_es_3)
roc_knn_selected <- roc(kn3_test$target, pred_probs_knn_selected)

# Calcular el AUC para cada modelo
auc_knn_no_scale <- auc(roc_knn_no_scale)
auc_knn_scaled <- auc(roc_knn_scaled)
auc_knn_es_3 <- auc(roc_knn_es_3)
auc_knn_selected <- auc(roc_knn_selected)

# Imprimir los valores de AUC
cat("AUC KNN sin escalar con todas las variables:", auc_knn_no_scale, "\n")
cat("AUC KNN escalado:", auc_knn_scaled, "\n")
cat("AUC KNN sin escalar k=3:", auc_knn_es_3, "\n")
cat("AUC KNN con variables seleccionadas:", auc_knn_selected, "\n")

# Graficar las curvas ROC
plot(roc_knn_no_scale, col = "blue", lwd = 2, main = "Comparación de Curvas ROC para Modelos KNN")
lines(roc_knn_scaled, col = "red", lwd = 2)
lines(roc_knn_es_3, col = "green", lwd = 2)
lines(roc_knn_selected, col = "purple", lwd = 2)

# Añadir una línea diagonal (clasificador aleatorio)
abline(a = 0, b = 1, col = "gray", lty = 2)


# Añadir una leyenda con tamaño reducido
legend("bottomright", legend = c("KNN sin escalar", "KNN escalado", 
                                 "KNN sin escalar k=3", "KNN variables seleccionadas"),
       col = c("blue", "red", "green", "purple"), lwd = 2, cex = 0.5)  # Ajuste del tamaño de la leyenda

```
KNN sin escalar con k=3, Área bajo la curva: 0,6375. Es el mejor modelo.



```{r}
rm
```

# Árboles de decisión

Los árboles de decisión son un modelo de aprendizaje supervisado ampliamente utilizado por su capacidad de manejar datos categóricos y numéricos, ser interpretables y funcionar bien sin necesidad de escalar. En este análisis, implementamos un árbol de decisión para predecir la variable objetivo target.

```{r}
df_arbol <- datos2015Target_train %>% select(eventidF, reactiontimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)
df_test_arbol <- datos2015Target_test %>% select(eventidF, reactiontimeF, edad, eventidP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP, target)

# Ajustamos las opciones del árbol con control
control_tree <- rpart.control(minsplit = 4,
                         minbucket = 2,
                         maxdepth = 5,
                         cp = 0)

# Entrenar el árbol de decisión
arbol <- rpart(target ~ ., data = df_arbol, method = "class", control = control_tree)

# Visualizar el árbol
rpart.plot(arbol, type = 3, extra = 104, under = TRUE, cex = 0.8)

```
La variable swimtimeP es el predictor más importante. Si swimtimeP < 106, se clasifica en ramas basadas en otros factores como medianaParcialesP y pointP. Si swimtimeP >= 106, se usan variables adicionales como medianaParcialesP para la clasificación.

Cada hoja indica una predicción (0 o 1), con precisión y porcentaje de datos representados.

```{r}
# Predicciones en el conjunto de entrenamiento
pred_train <- predict(arbol, newdata = df_arbol, type = "class")
confusionMatrix(pred_train, as.factor(df$target))

# Predicciones en el conjunto de prueba
pred_test <- predict(arbol, newdata = df_test_arbol, type = "class")
confusionMatrix(pred_test, as.factor(df_test$target), positive= "1")

```
El modelo tiene un buen desempeño en el conjunto de entrenamiento, lo que indica que aprende los patrones en los datos.

El modelo tiene un bajo desempeño en datos no vistos, lo que sugiere sobreajuste.


## posible mejora

Usamos la validación cruzada para encontrar el mejor valor de cp que maximice la generalización del árbol.

```{r}

set.seed(123)
control <- trainControl(method = "cv", number = 10)  # 10-fold 
arbol_cv <- train(target ~ ., 
                  data = df_arbol, 
                  method = "rpart", 
                  trControl = control, 
                  tuneLength = 10)  

print(arbol_cv$bestTune)

```

De hecho poniendo este cp, deberia mejorar un poco

## posible mejora 2

Si el árbol tiene muchas variables predictoras, algunas podrían no ser útiles y estar introduciendo ruido. 

```{r}
importancia <- varImp(arbol_cv, scale = TRUE)
print(importancia)

```
Puedes simplificar el modelo eliminando variables con baja importancia (por ejemplo, reactiontimeF y eventidP), lo que podría reducir el ruido y mejorar la generalización.

```{r}
arbol_reducido <- rpart(target ~ ., data = df_arbol %>% select(-eventidP, -reactiontimeF,-reactiontimeP), method = "class", control = control_tree)
rpart.plot(arbol_reducido, type = 3, extra = 104, under = TRUE, cex = 0.8)

# Evaluar el rendimiento
df_test_arbol_reducido=df_test_arbol %>% select(-eventidP, -reactiontimeF,-reactiontimeP)
pred_test_reducido <- predict(arbol_reducido, newdata = df_test_arbol %>% select(-eventidP, -reactiontimeF,-reactiontimeP), type = "class")
confusionMatrix(pred_test_reducido, as.factor(df_test_arbol_reducido$target), positive= "1")

```






# Random Forest

```{r}
#install.packages("randomForest")
library(randomForest)

# Entrenar el modelo Random Forest
rf <- randomForest(
  target ~ ., 
  data = df, 
  importance = TRUE, 
  proximity = TRUE,
  ntree = 150, 
  mtry = 6
)


# Graficar el error
plot(rf)
legend("right", colnames(rf$err.rate), lty = 1:5, col = 1:6)

# Importancia de las variables
var_importance <- importance(rf)
print(var_importance)
varImpPlot(rf)

# Predicción en el conjunto de entrenamiento
pred_rf_train <- predict(rf, df, type = "prob")[, 2]  
clase_pred_rf_train <- ifelse(pred_rf_train > 0.5, 1, 0)    # Umbral 0.5
cf_rf_train <- confusionMatrix(as.factor(clase_pred_rf_train), df$target, positive = "1")
print(cf_rf_train)

# Predicción en el conjunto de prueba
pred_rf_test <- predict(rf, df_test, type = "prob")[, 2] 
clase_pred_rf_test <- ifelse(pred_rf_test > 0.5, 1, 0)   

cf_rf_test <- confusionMatrix(as.factor(clase_pred_rf_test), df_test_arbol$target, positive = "1")
print(cf_rf_test)


```

swimtimeP es la variable más importante.

# xgboost

```{r}
library(purrr)
library(dplyr)
library(xgboost)

# Convertimos los datos a formato numérico
kn3_numeric <- map_df(kn3, function(columna) {
  columna %>% 
    as.factor() %>% 
    as.numeric %>% 
    { . - 1 }
})
kn3_test_numeric <- map_df(kn3_test, function(columna) {
  columna %>% 
    as.factor() %>% 
    as.numeric %>% 
    { . - 1 }
})

# Crear matrices DMatrix
train_mat <- kn3_numeric %>% 
  select(-target) %>% 
  as.matrix() %>% 
  xgb.DMatrix(data = ., label = kn3_numeric$target)

test_mat <- kn3_test_numeric %>% 
  select(-target) %>% 
  as.matrix() %>% 
  xgb.DMatrix(data = ., label = kn3_test_numeric$target)

# Entrenamiento del modelo
xgb_model <- xgboost(data = train_mat,  
                     objective = "binary:logistic", 
                     nround = 50, 
                     max_depth = 3, 
                     eta = 0.1, 
                     nthread = 2)

# Predicciones en el conjunto de prueba
predicciones <- predict(xgb_model, test_mat)
clases <- ifelse(predicciones > 0.5, 1, 0)

# Evaluar rendimiento
conf_matrix <- confusionMatrix(as.factor(clases), as.factor(kn3_test_numeric$target))
print(conf_matrix)

```

```{r}
xgb_model
```



```{r}
library(DiagrammeR)

xgb.plot.multi.trees(model = xgb_model)
```

Ahora con la función de abajo meter los valores de las hojas y comentar vale 

```{r}
# convertimos log odds a probabilidades
odds_to_probs <- function(odds){
    return(exp(odds)/ (1 + exp(odds)))
}
```
```{r}
# importancia sobre cada característica
importance_matrix <- xgb.importance(model = xgb_model)

xgb.plot.importance(importance_matrix)
```
Aqui hay algo abajo que esta mal, el que? no lo se
```{r}
# Realizar las predicciones en la muestra de prueba
prediccion <- predict(xgb_model, datos2015Target_test$target)

# Crear una tabla de confusión comparando las predicciones con los valores reales
library(caret)  # Asegúrate de tener cargada la librería 'caret' para la matriz de confusión
confusion_matrix <- cbind(prediccion > 0.5, datos2015Target_test$target) %>% 
  data.frame() %>% 
  table()

# Mostrar la matriz de confusión con los resultados positivos como "1"
confusionMatrix(confusion_matrix, positive = "1")

```

# Curva ROC (Pruebo por ahora como van los modelos, actualizar)

Genero las probabilidades para el conjunto de prueba
.
```{r}
# Probabilidades del árbol de decisión
pred_probs_arbol <- predict(arbol, newdata = df_test_arbol, type = "prob")[, 2]  # Probabilidad de clase 1

# Probabilidades del modelo KNN
pred_probs_knn <- predict(knn_best, newdata = df_test_scaled, type = "prob")[, 2]


library(pROC)


# ROC para cada modelo

roc_arbol <- roc(df_test_arbol$target, pred_probs_arbol)
roc_knn <- roc(df_test$target, pred_probs_knn)
roc_randomforest <- roc(df_test$target, pred_rf_test)

#AUC de cada modelo
auc_arbol <- auc(roc_arbol)
auc_knn <- auc(roc_knn)

# Gráfico comparativo de curvas ROC
plot(roc_arbol, col = "blue", lwd = 2, main = "Comparación de Curvas ROC")
lines(roc_knn, col = "red", lwd = 2)
lines(roc_randomforest, col = "green", lwd = 2)
# Añadir una leyenda
legend("bottomright", legend = c("Árbol de Decisión", "KNN","RandomForest"),
       col = c("blue", "red", "green", "purple"), lwd = 2)


```
El AUC es 0.618, lo cual indica que el modelo tiene un rendimiento moderado, pero no particularmente bueno para distinguir entre las clases.

El AUC es 0.582, lo cual sugiere que el modelo KNN tiene un rendimiento ligeramente inferior al del Árbol de Decisión.

Las curvas muestran que ambos modelos tienen un desempeño similar, pero el Árbol de Decisión parece ser marginalmente mejor en ciertos puntos

Ambos valores de AUC son menores a 0.7, lo cual indica que los modelos necesitan mejoras. Un AUC > 0.7 se considera aceptable, y > 0.8 es bueno.

