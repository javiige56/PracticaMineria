---
title: "Mundial de natación de Kazán 2015"
author: "Inés Molinero, Javier Villanueva, Salma Ghailan, Alonso González"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    toc: yes
    toc_float:
      collapsed: true
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Cargamos las librerias que vamos necesitando a lo largo del codigo
library(pastecs)
library(factoextra)
library(dplyr)
library(MASS)
library(rstatix)
library(ggplot2)
library(tidyr)
library(ggimage)
library(countrycode)
library(ggExtra)
library(cluster)
library(purrr)
library(dendextend)
library(RColorBrewer)
library(knitr)
library(FSA)
library(tidyverse)
library(viridis) # Para una paleta amigable para daltónicos
```

# Introducción(Javier).

En este proyecto, se analizarán los resultados del **mundial de natación de 2015** con el objetivo de identificar patrones en el desempeño de los nadadores por país y eventos.
Se realizará un análisis exploratorio de datos y se utilizarán técnicas de reducción de dimensionalidad, aprendizaje no supervisado, aprendizaje supervisado, medidas de rendimiento, comparación de modelos y técnicas de Aprendizaje Máquina Explicable. 

En primer lugar, vemos con qué datos vamos a tratar.
El conjunto de datos consiste en los resultados del Campeonato Mundial de Natación Kazán del año 2015, con los correspondientes datos de cada nadador y prueba.
Los datos han sido extraídos de [Omega](http://www.omegatiming.com/File/Download?id=00010F0200FFFFFFFFFFFFFFFFFFFF08), la plataforma oficial de tiempos de la World Aquatics.
El conjunto de datos contiene información sobre los nadadores (fecha de nacimiento, país, id), y sobre la prueba nadada (tiempo de reacción, parciales, tiempo total, estilo, serie).

Las variables o atributos que conforman el conjunto de datos son:

-   athleteid: id del nadador
-   lastname: Apellidos del nadador
-   firstname: El nombre del nadador
-   birthdate: Fecha de nacimiento del nadador
-   gender: Género del nadador/a
-   name: Nombre del país
-   code: abreviatura del país.
-   eventid: id de la prueba nadada (único)
-   heat: Serie en la que nadaron
-   lane: Calle en la que nadaron (0 a 9)
-   points: puntos FINA que realizaron. (es una "estimación" entre el mejor tiempo o récord del mundo, y el tiempo realizado. )
-   reactiontime: Tiempo de reacción en la salida.
-   swimtime: tiempo tardado
-   split: Parcial
-   cumswimtime: Tiempo acumulado en el parcial
-   splitdistance: Distancia del parcial
-   daytime: hora a la que se nadó
-   round: ronda (preliminar, semifinal, final)
-   distance: distancia de la prueba
-   relaycount: Número de relevista.
-   stroke: Estilo de nado en el que se realizó la prueba.
-   splitswimtime: Tiempo del parcial (50m)

# Entender los datos (Javi).

Primeramente, vamos a leer los datos:

```{r}
datos2015<-read.csv("datos/2015_FINA.csv", header=TRUE, sep = ',')
```

Una vez nuestro programa los ha leído, vamos a averiguar el tamaño de los datos con los que vamos a tratar:

```{r}
dim(datos2015)
```

Las dimensiones del dataframe son 11423 filas y 22 variables o columnas.

Veamos la primera ocurrencia:

```{r}
head(datos2015,1)
```

Observamos Noel Borshi, nadadora albanesa nacida un 13 de febrero de 1996, que tiene como id el número (100784).
Noel Borshi nadó la prueba 1 en la serie 1 y carril 4.
Nadó el 100m Mariposa en la ronda preliminar con un tiempo final de 63.65 segundos y pasó por el primer parcial (50m) en 29.63 segundos.

# Análisis exploratorio de datos.

## Resumen de los datos(Javi).

A continuación, vamos a ver un resumen de los datos:

```{r}
summary(datos2015)
```

De aquí, podemos observar que tenemos algunos valores nulos (NA's), durante toda la competición, que como máximo hubo 12 series y como mínimo 1 y que la piscina disponía de 10 carriles numerados del 0 al 9.
También observamos que se nadaron pruebas de 50 y hasta 1500 metros.

Tenemos variables categóricas las cuales se han tratado como continuas de partida.
Por lo cual, usando la librería "dyplr", vamos a convertirlas a variables categóricas en R para tener una mejor visualización de ellas.

```{r}
datos2015<- datos2015 %>% convert_as_factor(gender,name,code,round,heat,lane,stroke, relaycount)

```

Visualicemos ahora de nuevo el resumen:

```{r}
summary(datos2015)
```

Viendo este resumen de los datos podemos comenzar a entender algunas de las variables.

Observamos que las variables name y code toman absolutamente los mismos valores, luego seguramente podamos reducir en una variable el conjunto de datos. Se trata del país de procedencia de cada nadador.

Vemos que hay 5 ***tipos de nado***: braza, mariposa, crol, espalda y estilos individual.

No hemos guardado la distancia como una variable categórica, pero más adelante veremos que hay 6 distancias (50, 100, 200, 400, 800, 1500) Hay 5 tipos de ronda distintos.

El menor tiempo de reacción fue de 0.42 y el mayor de 0.97.

Viendo los datos, observamos que cada nadador tiene en una prueba concreta, tantas filas como parciales tenía en esa prueba, luego es obvio que para conocer mejor algunas variables, vamos a necesitar limpiar los datos para que los elementos repetidos no causen interferencia en nuestros datos.

A continuación, vamos a ir realizando estudios para tratar de comprender más a fondo algunas variables.

## Variable Relaycount. ¿Nos sirve de algo?(Javi)

Si observamos el resumen de la variable relaycount:

```{r}
summary(datos2015$relaycount)
```

Observamos que sólo toma un único valor, 1.
Esto se debe principalmente a que nuestro conjunto de datos consta de las pruebas individuales del mundial de Kazán 2015, luego como no hay relevos, todos los nadadores son el primer "relevista" en su prueba.

Luego, la eliminamos:

```{r}
datos2015$relaycount <- NULL
```

Luego ahora, tenemos 21 variables en vez de 22.

## Valores NA. Datos faltantes. [Expone Alonso todo.]

Si volvemos a mirar nuestro resumen, observamos que hay valores faltantes.
Vamos a tratar de identificarlos, intentar entender el por qué de esos datos faltantes, y razonar cuándo será conveniente eliminarlos o no de nuestro estudio.

Para ello, vamos a obtener primeramente un resumen de cuántos datos faltantes hay:

```{r}
print(sum(is.na(datos2015)))
```

Observamos que hay 309 valores faltantes.

Vamos a crear una dataframe donde se nos muestren dónde se encuentran los valores faltantes:

```{r}
datosNA <- datos2015[rowSums(is.na(datos2015)) > 0, ]
dim(datosNA)

```

Observamos que, de 11429 observaciones de mi dataframe original, en 73 de ellas, existe algún valor nulo.
Es decir, un 0.63 % por ciento.
Un valor muy bajo.

En principio y sin estudiar nada más, podríamos considerar eliminar las filas que contengan datos faltantes ya que toman un valor muy pequeño con respecto al total.
Aún así, vamos a ver dónde se suelen tomar más valores nulos e intentar explicar el por qué.
Hacemos una dataframe adicional con los valores nulos de cada variable en porcentaje:

```{r}
percent_na <- colSums(is.na(datosNA)) / nrow(datosNA) * 100
percent_na

```

Observamos de manera bastante clara que los datos nulos tienen mucho que ver con el tiempo acumulado, los puntos finales, el tiempo de reacción, el tiempo final y el tiempo al paso por el parcial.

A continuación, vamos a intentar clasificar los nulos dependiendo qué falta:

### Valores nulos en los que faltan todas las variables.

Visualicemos los datos donde faltan todas las variables dichas anteriormente:

```{r}
todosNA<-datosNA[is.na(datosNA$points) & is.na(datosNA$reactiontime) & is.na(datosNA$swimtime) & is.na(datosNA$cumswimtime) & is.na(datosNA$splitswimtime), ]

dim(todosNA)
```

Bien, en 59 de las 73 observaciones, faltan, tanto el tiempo de reacción, los puntos finales, el tiempo final, los parciales acumulados... Es decir, nadadores que posiblemente se dieron de baja en la prueba.

```{r}
summary(todosNA)
```

```{r}
todosNA[todosNA$round=="FIN",]
```

La mayoría de nadadores causaron baja en la ronda preliminar, pero hay uno, el nadador chino Sun Yang, que causó baja en la final del 1500m libres masculino.

Haciendo una pequeña búsqueda en los resultados de la World Aquatics de los mundiales de 2015, observamos que Sun Yang produjo DNS (Did not Start).

```{r}
todosNA[todosNA$firstname=="CESAR",]
```

También, buscando a César Cielo en el 50 libres de las preliminares, observamos que causó baja DNS. Para poneros en contexto, Cesar Cielo es actualmente el poseedor del récord mundial del 50 libres, luego también resultaba raro que causase baja. 

Luego todo parece indicar que estos nadadores fueron baja en esa prueba y por ello no sale ningún dato en esas variables.
Vamos a optar por eliminarlos.


```{r}
#Primero datosNA: 
datosNA <- datosNA %>%
  filter(!(is.na(datosNA$points) & is.na(datosNA$reactiontime) & is.na(datosNA$swimtime) & is.na(datosNA$cumswimtime) & is.na(datosNA$splitswimtime)))

#Ahora, los eliminamos de datos2015: 
datos2015<-datos2015 %>%
  filter(!(is.na(datos2015$points) & is.na(datos2015$reactiontime) & is.na(datos2015$swimtime) & is.na(datos2015$cumswimtime) & is.na(datos2015$splitswimtime)))

```

Bien, ahora, tenemos solamente datos en los que falta alguna de las variables.
Analizamos nuevamente para poder reclasificarlos:

```{r}
datosNA
```

Nos quedan solamente 14 filas en los que hay datos nulos.

Si seguimos con nuestra limpieza:

### Valores nulos donde faltan los puntos:

Veamos qué sucede si sólo faltan los puntos:

```{r}
naReactionTime<-datosNA[is.na(datosNA$points),]
naReactionTime
```

Vamos a buscar los resultados de World Aquatics de alguno de ellos, para estimar qué esta sucediendo.
¿Fueron descalificados?.

Nuestro nadador de la primera fila, Ben Treffers, fue descalificado.
Buscamos también a Vladimir Morozov, y también fue descalificado.
Luego, son participantes que nadaron pero quedaron descalificados.
Por tanto, sus datos nos servirán para hacer estudios sobre participación, pero no para cualquier estudio que involucre los resultados.
Luego estos, no los eliminamos del dataframe inicial.

```{r}
datosNA <- datosNA %>%
  filter(!(is.na(datosNA$points)))
```

Me quedan las dos ultimas observaciones por ver:

```{r}
datosNA
```

Tenemos dos observaciones en las cuales no existe el tiempo de reacción.
Seguramente se deba a algún fallo en el sistema electrónico o algún fallo al pasar los datos.
Por lo tanto, al igual que con los anteriores, no lo eliminaremos de nuestro dataframe inicial, pero sí lo tendremos en cuenta cuando tengamos que analizar estudios que tengan que ver con el tiempo de reacción.

```{r}
print(sum(is.na(datos2015)))
```

Luego, de 309 iniciales, vamos a tratar ahora con 14 datos nulos ya controlados.

```{r, echo=FALSE}
#Elimino las cosas creadas para no sobrecargar. Ya que no las vamos a volver a usar.
rm(datosNA, naReactionTime, todosNA, percent_na)
```

## Variable birthdate. Creacion de nueva variable edad.(Ines)

A continuación, vamos a crear una variable llamada *edad*, ya que será más representativo que trabajar con la variable birthdate.
La variable tendrá el valor numérico de la edad de cada participante en el momento del mundial.
Es decir, el 24 de Julio de 2015.

```{r}
datos2015$birthdate <- as.Date(datos2015$birthdate)
#Calculamos la edad
fechaKazan<- as.Date("2015-07-24")
datos2015$edad <- as.numeric(difftime(fechaKazan, datos2015$birthdate, units = "weeks")) %/% 52  # Convertir de semanas a años
```

Además, borramos la variable birthdate:

```{r}
datos2015$birthdate=NULL
```

## Dataframes. [Inés]

Si visualizamos el dataframe datos2015, observamos por cada prueba de cada nadador, salen n filas que equivalen a los n parciales (de 50m ) en los que constaba la prueba.
Luego, para algunos estudios, usar este dataframe va a suponer duplicar, triplicar e incluso multiplicar por 15 un mismo valor (en el caso de las carreras de 1500m).
Además, no estaríamos haciendo un análisis correcto, puesto que los resultados estarían claramente sesgados hacia los de las distancias más largas.
Por ejemplo, en el caso del tiempo de reacción, los tiempos de los nadadores de 1500 metros se contabilizarían 15 veces.
Mientras que en los nadadores de 50 metros sólo una vez.

A continuación, procedemos a presentar los dataframes que vamos a utilizar dependiendo lo que queramos estudiar:

### Dataframe nadadoresParticipantes.
Utilizaremos este dataframe para realizar análisis sobre el número de nadadores, proporción entre hombres y mujeres, la edad de los participantes, etc.
Es decir, análisis sobre datos que no requieren el conocimiento de la progresión en sus splits.
Para ello, nos bastará con tener la primera fila de cada participante.

Creamos, por tanto, un nuevo dataframe, llamado *nadadoresParticipantes*, el cual constará de todos los participantes sin repetir.
Nos basaremos en la unicidad de la variable athleteid para crearla. 

```{r}
nadadoresParticipantes <- datos2015 %>%
  distinct(athleteid, .keep_all = TRUE)

#guardamos una copia de seguridad por si se modifica el dataframe más adelante. 

nadadoresParticipantesCopia<-nadadoresParticipantes
```

```{r}
summary(nadadoresParticipantes)
```

### Dataframe nadadoresPruebas. 

Para poder elaborar un estudio de algunas variables como *events*, *reactiontime*, *lane*, *heats* y *daytime*,entre otras cosas, vamos a necesitar un dataframe que refleje a cada nadador y sus pruebas nadadas por filas.

Para poder realizar el dataframe, primero hay que saber si cada prueba, dentro de cada tipo de prueba (preliminar, final, semifinal), tiene un id distinto.

Lo evaluamos seleccionando algún nadador que haya nadado en varias rondas:

```{r}
ejemplo<-datos2015[datos2015$distance == 100 & datos2015$stroke=="BACK" & datos2015$code=="AUS", ]
head(ejemplo,6)
```

Bien, vemos que el australiano nadó tanto las preliminares, como las semifinales como la final y el eventid era distinto entre rondas pero es el mismo en la misma prueba.

```{r, echo=FALSE}
rm(ejemplo)
```

Creamos el siguiente dataframe:

```{r}
nadadoresPruebas <- datos2015 %>%
  distinct(eventid, athleteid, .keep_all = TRUE)

head(nadadoresPruebas,6)

#Copia de seguridad: 
nadadoresPruebasCopia<-nadadoresPruebas
```

Los datos creados, reflejan nadadores y pruebas nadadas por cada uno.

## Estudio sobre el número de nadadores, su género, país y edad. [Alonso]

Usaremos el dataframe nadadoresParticipantes.
Ahora, comenzamos nuestro estudio:

### Edad [Alonso]

Veamos primeramente un resumen de la edad:

```{r}
summary(nadadoresParticipantes$edad)
```

Observamos que la edad máxima fue de 38 años, la media fue de 21.32 años, y el participante con menos edad fue de 10 años.
Además, el 50% de los participantes estaban entre 19 y 24 años de edad.

Una pregunta razonable sería: ¿El dato relativo al participante de 10 años es un error?

Procedemos a contrastar la información.
De esta forma, podemos ver si de verdad existe este atleta o es un dato mal tomado de nuestra base de datos.
Confirmamos la información, entre otras fuentes, con esta noticia, de la cual añadimos el enlace sobre la joven nadadora de 10 años.
[noticia](https://www.rtve.es/deportes/20150807/nina-10-anos-alzain-tareq-asombra-a-natacion-mundial/1195782.shtml#:~:text=Se%20llama%20Alzain%20Tareq%2C%20tiene,estrella%20medi%C3%A1tica%20de%20la%20jornada.)

Confirmamos mediante su nombre, apellidos y edad, que la noticia se refiere a los datos que tenemos.

```{r}
datos2015[datos2015$edad == 10, ]
```

Se trata de una nadadora de Bahrain que nadó el 50 mariposa y el 50 libres.
Luego podemos concluir que es un dato atípico pero no es erróneo.

De acuerdo con esta nueva variable, vemos cómo se distribuyen las edades.

```{r}
ggplot(nadadoresParticipantes, aes(x = edad)) +
  geom_density(fill = "#0072B2", color = "#0072B2") + # Azul accesible para daltónicos
  ggtitle("Distribución. Edades.")
```

La mayoría de los nadadores parecen tener entre 15 y 25 años, con un pico alrededor de los 20 años.

Esto sugiere que los participantes en la competición están en su mayoría en la etapa juvenil o temprana adultez.

Podríamos preguntarnos si la edad sigue una distribución normal en estos datos, para ello, hacemos uso del test shapiro:

```{r}
shapiro.test(nadadoresParticipantes$edad)
```

Rechazamos la hipótesis nula, es decir, la edad NO sigue una distribución normal en estos datos.

Vamos a realizar 3 evaluaciones para ver si podemos suponer que nuestros datos son normales: 


#### Probabilidad de que un nadador tenga más de 29 años: 

Para calcular la probabilidad de que un nadador tenga más de 29 años, cuento todos los nadadores que tienen más de 30, y divido sobre el número total de participantes. 


```{r}
valor1<- sum(nadadoresParticipantes$edad >=29)/1099
```


#### Calcular media y varianza y calcular la probabilidad Normal. 

```{r}
media<-mean(nadadoresParticipantes$edad)
desviacion<-sd(nadadoresParticipantes$edad)

valor2<-1 - pnorm(29, media, sd=desviacion)
```


#### Simular datos de una normal sabiendo media y varianza. 

Ahora, simulo datos: 

```{r}
datos_simulados <- rnorm(1100, mean = media, sd = desviacion)
## Calculo la probabilidad de 29 o más: 

conteo_mayores_que_29 <- sum(datos_simulados >= 29)

valor3<- conteo_mayores_que_29/1100
```


A continuación, comparo los tres valores obtenidos: 

```{r}
valor1
valor2
valor3
```



```{r}
rm(conteo_mayores_que_29, datos_simulados, desviacion, media, valor1, valor2, valor3)
```

Observo que hay una variación de 0.014 entre las probabilidades, al ser una probabilidad tan baja, podríamos asumir normalidad en nuestros datos. 
### Análisis de géneros participantes [Salma].

Veamos el número exacto de mujeres y hombres en la competición:

```{r}
summary(nadadoresParticipantes$gender)
```

Luego, hay 608 hombres y 491 mujeres que participaron en los mundiales de Kazán 2015.

Veamos ahora cómo se distribuyen los hombres y las mujeres y sus respectivas edades:

```{r}
ggplot(nadadoresParticipantes, aes(x = edad, colour = gender)) +
# Añadir la capa de la densidad de probabilidad.
    geom_density()
```

Según observamos, la distribución está ligeramente desplazada a la derecha para los hombres, esto indica que los hombres tienden a ser mayores en promedio que las mujeres.
Esta diferencia en la distribución de edades entre los géneros nos conduce a realizar distintos test estadísticos para confirmar si la diferencia realmente es significativa.

#### Hipótesis:

Hipótesis nula: Las medias de los dos grupos son iguales.
Hipótesis alternativas: Las medias de los dos grupos son diferentes.

```{r}
t.test(edad~gender,data=nadadoresParticipantes)

```

Hemos comparado las medias de edad entre mujeres (grupo F) y hombres (grupo M), tomando como hipótesis nula que las medias de edad entre mujeres y hombres son iguales, y cómo hipótesis alternativa que las medias de edad entre mujeres y hombres son diferentes.
Aunque el resultado del t-test muestra que hay una diferencia estadísticamente significativa (el p-valor es muy pequeño) entre las edades medias de hombres y mujeres (aproximadamente 1.16 años), en términos prácticos, esta diferencia es relativamente pequeña.
En este caso, puede no ser relevante en términos de la experiencia o desempeño de los nadadores.

No obstante, proseguimos en nuestro análisis exploratorio.

```{r}
tabla1<-table(nadadoresParticipantes$edad>30,nadadoresParticipantes$gender)
chisq.test(tabla1)
```

Por el resultado del siguiente test aplicado, podemos concluir con que **no hay asociación significativa**: Dado que el p-valor es 0.47, entre ser mayor de 30 años y el género de los nadadores en nuestros datos.
En términos sencillos,la edad no parece estar relacionada con el género de los nadadores en cuanto a si son mayores de 30 años.

```{r}
tabla2<-table(nadadoresParticipantes$edad<20,nadadoresParticipantes$gender)
chisq.test(tabla2)
```

Hay una diferencia considerable entre las frecuencias observadas (cuántos hombres y mujeres son menores de 20 años) y las frecuencias esperadas bajo la hipótesis nula (que no hay asociación entre edad y género para menores de 20 años).
Esto sugiere ir un paso más allá, **¿Hay más mujeres menores de edad que hombres menores de edad?**

```{r}
tabla3<-table(nadadoresParticipantes$edad<18,nadadoresParticipantes$gender)
chisq.test(tabla3)
```

Los resultados sugieren que el género y la minoría de edad si que están significativamente relacionados en nuestro conjunto de datos de nadadores.
Esto podría tener implicaciones para el análisis del rendimiento y la participación en competiciones.

Veamos números,

```{r}
tabla3

#Calcular los totales
totales <- colSums(tabla3)

#Calcular el porcentaje de nadadores menores de 18 años por género
porcentajes <- (tabla3[2, ] / totales) * 100  
# fila 2 son los menores de 18

porcentajes
```

De esta forma, ya habiendo confirmado una diferencia significativa.
Podemos ver, de manera más representativa, como existe el doble de proporción de mujeres menores de edad en comparación con los hombres.
Dicho en otras palabras, *2 de cada 10 mujeres son menores de 18 años, mientras que esto sólo ocurre en 1 de cada 10 hombres*:

```{r}

porcentajes <- c(10.88, 21.66)  # 10% para hombres y 20% para mujeres
generos <- c("Hombres", "Mujeres")

# Crear un dataframe con los porcentajes
datos_porcentajes <- data.frame(Genero = generos, Porcentaje = porcentajes)

# Crear el gráfico de barras
ggplot(datos_porcentajes, aes(x = Genero, y = Porcentaje, fill = Genero)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(Porcentaje, "%")), vjust = -0.5) +  # Agregar los porcentajes sobre las barras
  labs(title = "Porcentaje de Nadadores Menores de 18 Años por Género",
       x = "Género",
       y = "Porcentaje") +
  scale_fill_manual(values = c("violet", "red")) +  # Colores para los géneros
  theme_minimal() +
  ylim(0, max(porcentajes) + 10)  # Ajustar el límite del eje Y

```

```{r, echo=FALSE}

#elimino las cosas creadas para no interferir luego. 

rm(tabla1,tabla2, tabla3, generos, porcentajes, totales, datos_porcentajes)

```

### Análisis de nacionalidades [Salma].

Vamos a ver la cantidad de nadadores por país.

```{r, warning=FALSE}

nadadoresParticipantes$iso2 <- countrycode(nadadoresParticipantes$name, "country.name", "iso2c")

nombres<- unique(nadadoresParticipantes$name) #Para no repetir
#print(nombres)
manual <- data.frame(
  nombre = c("Fina", "Kosovo", "Micronesia", "Virgin Islands"),
  iso2 = c("FI", "XK", "FM", "VI")  
)

# Agregamos la variable continente 
nadadoresParticipantes$continent <- countrycode(nadadoresParticipantes$iso2, "iso2c", "continent")



nadadoresParticipantes <- nadadoresParticipantes %>%
  mutate(continent = ifelse(iso2 == "XK", "Europe", continent))  


#nadadores por país
resumen_paises <- nadadoresParticipantes %>%
  group_by(name, iso2, continent) %>%
  summarise(num_nadadores = n(), .groups = "drop") %>%
  arrange(desc(num_nadadores))  # Ordenar por número de nadadores

head(resumen_paises,6)

#Creamos un gráfico con colores
paleta <- c("Americas" = "#0084ff", "Asia" = "#44bec7", 
            "Europe" = "#ffc300", "Oceania" = "#fa3c4c", "Africa"= "#ff6347")

oda_bar <- resumen_paises %>% 
  ggplot(aes(x = reorder(name, num_nadadores), y = num_nadadores, fill = continent)) + 
  geom_flag(y = -10, aes(image = iso2), size = 0.05) +  
  geom_bar(stat = "identity") + 
  labs(title = "Participación de Nadadores por País",
       subtitle = "Datos de nadadores en competiciones",
       x = "País",
       y = "Número de Nadadores") +
  scale_fill_manual(values = paleta) +  # colores personalizados
  expand_limits(y = c(0, max(resumen_paises$num_nadadores) + 10)) +  # Aumentar el límite superior
  coord_flip() +  # Para hacer el gráfico horizontal
  theme_minimal()

# Imprimir el gráfico
print(oda_bar)
```

Vemos también este mismo gráfico, pero separando los países por continentes.

```{r, warning=FALSE}
paleta <- c("Americas" = "#0084ff", 
            "Asia" = "#44bec7", 
            "Europe" = "#ffc300", 
            "Oceania" = "#fa3c4c", "Africa"= "#ff6347")

oda_bar1 <- resumen_paises %>% 
  ggplot(aes(x = reorder(name, num_nadadores), 
             y = num_nadadores, 
             fill = continent)) + 
  geom_flag(y = -10, aes(image = iso2), size = 0.05) +  
  geom_bar(stat = "identity") + 
  labs(title = "Participación de Nadadores por País",
       subtitle = "Datos de nadadores en competiciones",
       x = "País",
       y = "Número de Nadadores") +
  scale_fill_manual(values = paleta) +  # Colores personalizados
  expand_limits(y = c(0, max(resumen_paises$num_nadadores) + 10)) +  # Ajustar el límite superior
  coord_flip() +  # Gráfico horizontal
  theme_minimal() +
  facet_wrap(~ continent, scales = "free_y")  # Separar por continentes

# Imprimir el gráfico
print(oda_bar1)

```

Como vemos, estos gráficos son poco interpretables debido a la gran cantidad de países.
Por ello, intentaremos analizar los resultados en función de proporciones relativas a continentes.

```{r}
paleta <- c("Americas" = "#0084ff", 
            "Asia" = "#44bec7", 
            "Europe" = "#ffc300", 
            "Oceania" = "#fa3c4c", "Africa"="#ff6347")

# Crear el histograma de cantidad de nadadores por continente
histograma_nadadores <- resumen_paises %>% 
  ggplot(aes(x = continent, y = num_nadadores, fill = continent)) + 
  geom_bar(stat = "identity") +  # Sumar cantidad de nadadores por continente
  labs(title = "Cantidad de Nadadores por Continente",
       x = "Continente",
       y = "Número de Nadadores") +
  scale_fill_manual(values = paleta) +  # Colores personalizados por continente
  theme_minimal()

# Imprimir el histograma
print(histograma_nadadores)

```

Como podemos observar en los gráficos, la mayor cantidad de nadadores son de procedencia europea, continuando con Asia y Américas, y teniendo baja proporción los nadadores de África y Oceanía.

Nos preguntamos en esta situación, si los Europeos tendrán los puestos más altos en el ranking.
Es decir, si existe mayor proporción de ganadores en los países con más densidad de participantes.

Para ello, analizaremos los puntos según las nacionalidades de los nadadores.

```{r}
puntos_por_pais <- nadadoresPruebas %>%
  group_by(name) %>%  
  summarise(total_puntos = sum(points, na.rm = TRUE))  

# Ver el resultado
head(puntos_por_pais,20)

```

```{r}
#Graficar los puntos por país
ggplot(puntos_por_pais, aes(x = reorder(name, total_puntos), y = total_puntos)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Total de Puntos por País", x = "País", y = "Total de Puntos") +
  coord_flip() +  # Voltear el gráfico para una mejor visualización
  theme_minimal()

```

De la misma manera que nos ocurría antes, este gráfico es poco interpretativo.
Lo vemos por continentes:

```{r, warning=FALSE}
# Utilizamos la dataframe nadadoresPruebas
# Agregar el código ISO de dos dígitos. No es posible con la variable CODE, hay que convertir.
nadadoresPruebas$iso2 <- countrycode(nadadoresPruebas$name, "country.name", "iso2c")

nombres<- unique(nadadoresPruebas$name) #Para no repetir

#print(nombres)

#Nombres problemáticos
manual <- data.frame(
  nombre = c("Fina", "Kosovo", "Micronesia", "Virgin Islands"),
  iso2 = c("FI", "XK", "FM", "VI")  
)

# Agregamos la variable continente 
nadadoresPruebas$continent <- countrycode(nadadoresPruebas$iso2, "iso2c", "continent")

#solo es XK(KOSOVO, que está en Europa)
#manualmente el continente para Kosovo (XK)
nadadoresPruebas <- nadadoresPruebas %>%
  mutate(continent = ifelse(iso2 == "XK", "Europe", continent))  


puntos_por_continente <- nadadoresPruebas %>%
  group_by(continent) %>%  #agrupar por continente
  summarise(total_puntos = sum(points, na.rm = TRUE))  #Sumar puntos por continente

print(puntos_por_continente)
```

```{r}
#Graficar los puntos por continente
ggplot(puntos_por_continente, aes(x = reorder(continent, total_puntos), y = total_puntos, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Total de Puntos por Continente", x = "Continente", y = "Total de Puntos") +
  coord_flip() + 
  theme_minimal()
```

```{r}
ggplot(na.omit(nadadoresPruebas), aes(x = points, colour = continent)) +
# Añadir la capa de la densidad de probabilidad.
    geom_density()

ggplot(na.omit(nadadoresPruebas), aes(x=continent, y=points, color=continent)) +
  geom_boxplot()
```

Como podemos observar, parece ser que los Europeos son mejores en el desempeño de las pruebas de natación.
Además, presentan una distribución más centrada a la media y sus valores más altos están bastante alejados del resto de los del resto de participantes de otros continentes.
Podríamos interpretar que América tiene la segunda distribución más centrada en comparación con el resto de continentes.
La esperanza está cercana a Oceanía por debajo pero con menor dispersión.
Oceanía también presenta una media bastante alta y cercana a la de Europa.
sin embargo, se puede ver como su dispersión es bastante elevada por lo que presenta nadadores de diversa cualificación.
La peor esperanza la tiene África, muy por debajo este valor del resto de los continentes.
Además presenta una gran dispersión, ya que abarca el rango desde valores cercanos al 0 hasta 1000, sin ser estos visualizados como outliers.
Esta información nos podría ser de gran ayuda para dar un posible enfoque a la hora de establecer tendencias en los grupos y a qué se puede deber (clima, tipo de entrenamiento, condiciones sociales en diversos países) la cantidad de puntos en promedio y la variabilidad de estas observaciones.

Anteriormente hemos hallado para cada contiente todos los puntos conseguidos por los nadadores de dicho continente.
Lo que vamos a hacer a continuación es normalizar los puntos por continente, es decir, para cada continente tomamos todos los puntos de dicho continente y lo dividimos por todos participantes de ese continente y comparamos.

```{r}
# Agrupar por continente, sumar puntos y contar participantes
resumenContinente <- nadadoresPruebas %>%
  group_by(continent) %>%
  summarise(
    puntos_totales_continente = sum(points, na.rm = TRUE),
    numero_Participantes_continente = n()  # Contar los participantes
  ) %>%
  mutate(
    relacion_puntos_por_participante = puntos_totales_continente / numero_Participantes_continente
  )

# Imprimir el resultado
print(resumenContinente %>% select(continent, relacion_puntos_por_participante))
```

Vemos que Europa tiene el mejor promedio con una cierta diferencia, le siguen América y Oceanía (puntuaciones similares), despúes Asia y por último Africa.

Para terminar con esta sección, vamos a ver los 20 primeros en el ranking, y a hacer un gráfico que nos indique de que pais es cada uno de los 20.

```{r}
# Filtrar solo las filas de la prueba de 100 metros y ordenar por puntos
datos_100m_top <- nadadoresPruebas[nadadoresPruebas$distance==100,] %>% # Filtra para la prueba de 100 metros
  arrange(desc(points)) %>%           # Ordena por puntos de mayor a menor
  dplyr::slice(1:20)                        # Selecciona las primeras 20 

datos_100m_top
```

Vemos los 20 primeros y de que continente son:

```{r}

# Contar la cantidad de nadadores por continente
conteo_por_continente <- datos_100m_top %>%
  group_by(continent) %>%                                       # Agrupa por continente
  summarise(cantidad_nadadores = n()) %>%                      # Cuenta los nadadores por continente
  mutate(percent = (cantidad_nadadores / sum(cantidad_nadadores)) * 100)  # Calcula el porcentaje

# Crear el gráfico de distribución porcentual
grafico_distribucion_continente <- ggplot(conteo_por_continente, aes(x = continent, y = percent, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Distribución Porcentual de Nadadores por Continente en los Top 20 - 100 Metros",
       x = "Continente",
       y = "Porcentaje de Nadadores") +
  scale_fill_manual(values = paleta) +                          # Usa la paleta de colores personalizada
  theme_minimal()

# Imprimir el gráfico
print(grafico_distribucion_continente)
grafico_circular <- ggplot(conteo_por_continente, aes(x = "", y = percent, fill = continent)) +
  geom_bar(stat = "identity", width = 1) +                      # Crea las barras
  coord_polar("y") +                                            # Convierte el gráfico en circular
  labs(title = "Distribución Porcentual de Nadadores por Continente en los Top 20 - 100 Metros",
       fill = "Continente") +                                   # Etiqueta para la leyenda
  scale_fill_manual(values = paleta) +                          # Usa la paleta de colores personalizada
  theme_void()                                                  # Elimina el fondo y ejes

# Imprimir el gráfico
print(grafico_circular)
```

La alta cantidad de nadadores europeos en el podio de 100 metros(más específico que lo anterior, ya que esto nos mete directamente en los primeros 20) sugiere que hay un fuerte nivel de competencia y entrenamiento en las naciones de este continente.
Esto podría estar relacionado con la inversión en programas de natación.
Le sigue oceanía,ya que Oceanía, aunque es una región más pequeña en términos de población comparada con Europa, ha producido nadadores destacados que compiten a niveles muy altos.
La presencia de nadadores de élite, especialmente de Australia, resalta la calidad del talento en la región.

Los datos indican que África tiene solo un 15% de ganadores en la natación en comparación con otros continentes como Europa y Oceanía, esto puede abrir un amplio espacio para el análisis, ya que muchos países africanos enfrentan desafíos significativos en cuanto a la inversión en infraestructura deportiva.
La falta de instalaciones de calidad para la natación, como piscinas adecuadas, puede limitar el desarrollo de talentos.

Realizando un chequeo rápido a la tabla de los 20 mejores, vemos que tenemos South Africa en el top 4 en 100 metros(hemos elegido 100 metros al haber una gran cantidad de nadadores, lo que refleja bien lo que buscamos).
Podríamos ver que a pesar de que en África no se llegue mucho al podio, cuando se llega es en los tres primeros puestos.
¿Hemos concluido bien?
Veámoslo.
Esto es el podio de los 4 primeros en 100 metros

```{r}
# Filtrar solo las filas de la prueba de 100 metros y ordenar por puntos
datos_100m_top_4 <- nadadoresPruebas[nadadoresPruebas$distance==100,] %>% # Filtra para la prueba de 100 metros
  arrange(desc(points)) %>%           # Ordena por puntos de mayor a menor
  dplyr::slice(1:4)                        # Selecciona las primeras 20 

datos_100m_top_4
```

La presencia de Sudáfrica en el cuarto lugar es un indicador de que, a pesar de la baja representación general, el continente tiene al menos algunos atletas de élite que pueden competir con los mejores del mundo.Aunque la cantidad de nadadores africanos en el podio es baja, su éxito en alcanzar los primeros puestos es notable.
Esto podría implicar que los nadadores africanos son altamente competitivos cuando tienen la oportunidad de competir en el más alto nivel.
Además,al centrarse en la prueba de 100 metros, que tiene una gran cantidad de participantes, se obtiene una visión clara del rendimiento de los nadadores en este evento específico.
Esto ayuda a eliminar sesgos que podrían surgir al mirar pruebas con menos competidores.

```{r}
# Crear un gráfico para visualizar el podio de los 3 primeros
grafico_podio_100m <- ggplot(datos_100m_top_4, aes(x = reorder(lastname, points), y = points, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Podio de los 4 Primeros en 100 Metros",
       x = "Nadador",
       y = "Puntos",
       fill = "Continente") +
  scale_fill_manual(values = paleta) +  # Usa la paleta de colores que ya definiste
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Mejorar legibilidad

# Imprimir el gráfico
print(grafico_podio_100m)

grafico_podio_100mrepresentacion <- ggplot(datos_100m_top_4, aes(x = reorder(continent, points), y = points, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Representación podium de África VS Europa  (en Puntos)",
       x = "Nadador",
       y = "Puntos",
       fill = "Continente") +
  scale_fill_manual(values = paleta) +  # Usa la paleta de colores que ya definiste
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Mejorar legibilidad

# Imprimir el gráfico
print(grafico_podio_100mrepresentacion)

```

```{r, echo=FALSE}

rm(conteo_por_continente, datos_100m_top, datos_100m_top_4, grafico_circular, grafico_distribucion_continente, grafico_podio_100m, grafico_podio_100mrepresentacion, histograma_nadadores, manual, oda_bar, oda_bar1, puntos_por_continente, puntos_por_pais, resumen_paises, resumenContinente, nombres, paleta)
nadadoresParticipantes<-nadadoresParticipantesCopia
nadadoresPruebas<-nadadoresPruebasCopia
```

## Estudio sobre los eventos, reactiontime, lane, heats, daytime:

### Reactiontime. Hombres vs Mujeres(Ines)

Veamos cómo se distribuyen los datos de tiempo de reacción de todos los nadadores.
Para ello, no tenemos en cuenta las dos filas con datos nulos.

```{r}
ggplot(na.omit(nadadoresPruebas), aes(x = reactiontime)) +
geom_density() +
ggtitle("Distribución. reactiontime")

```

Parece que los datos siguen una distribución normal a priori.
Igual que antes, vamos a hacer el test de shapiro:

```{r}
shapiro.test(na.omit(nadadoresPruebas$reactiontime))
```

Al tener un p-valor tan bajo, no parece que siga una distribución normal.

Comparamos las funciones de densidad de mujeres y hombres en general:

```{r message=FALSE, warning=FALSE}
nadadoresPruebas <- nadadoresPruebas %>% filter(!is.na(nadadoresPruebas$reactiontime))
ggplot(nadadoresPruebas, aes(x=reactiontime, colour=gender))+
geom_density()+
  ggtitle("Distribución. Hombres vs Mujeres")
```

De esta gráfica nos podemos plantear realizar un contraste de hipótesis, en el cual analizaremos sobre la posible diferencia significativa del tiempo de reacción en ambos géneros.
Por tanto, realizamos el siguiente test:

-   H0: El tiempo de reacción es igual en mujeres y hombres.
-   H1: El tiempo de reacción es menor en hombres que en mujeres.

```{r}
t.test(reactiontime~gender,data=nadadoresParticipantes)
```

Si observamos los resultados, el p- valor nos indica que hay una evidencia significativa para rechazar la hipótesis nula, y por ende concluir con que hay una diferencia estadística en el tiempo de reacción dependiendo del género.
Ahora que hemos determinado que la diferencia es estadísticamente significativa, es importante considerar si la diferencia es también significativa en la práctica o si tiene relevancia a la hora de los resultados finales.
Calculamos la diferencia relativa, ya que los tiempos de reacción son muy pequeños y de esta forma nos podemos hacer una idea de lo representativa que es la diferencia de medias.

```{r}
mediaTiempoReaccion <- mean(nadadoresPruebas$reactiontime)
mediaTiempoReaccion
(0.7166871-0.6922862)/mediaTiempoReaccion*100
```

Obtenemos que las mujeres tardan un 3.5% más de tiempo que los hombres.
Debemos seguir analizando esta variable con otras para poder concluir cualquier resultado.

En este punto, podríamos preguntarnos si las mujeres/hombres que tienen un tiempo de reacción más bajo le corresponderán puestos mas altos, y viceversa.
Es decir, si existe una correlación negativa entre ambas variables.

No podemos precipitarnos a decir que la diferencia es muy pequeña ya que habría que hacer un análisis adicional para medir la magnitud la diferencia (como el de Cohen).
Esto nos diría cómo es de grande la diferencia en términos de desviaciones estándar.

### Reactiontime. Distancias largas vs distancias cortas(Ines).

Vamos a comparar ahora las funciones de densidad de las chicas en la prueba de 800m libres y 50m libres:

Primeramente calculamos el conjunto de datos:

```{r}
nadadorasComparacionReactionTime<-nadadoresPruebas[(nadadoresPruebas$distance==50 | nadadoresPruebas$distance==800) & nadadoresPruebas$gender=="F" , ]

```

```{r}

ggplot(nadadorasComparacionReactionTime, aes(x = factor(distance), y = reactiontime, fill = factor(distance))) +
  geom_boxplot() +
  labs(title = "Boxplot de Reaction Time: 50m vs 800m",
       x = "Distancia (m)",
       y = "Tiempo de Reacción") +
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  
  theme_minimal()

```

El gráfico muestra los boxplots del tiempo de reacción para la prueba de 50 metros y otra para 800 metros.

```{r}
# Crear el gráfico de densidad con colores por distancia
ggplot(nadadorasComparacionReactionTime, aes(x = reactiontime, fill = factor(distance), group = distance)) +
  geom_density(alpha = 0.6) +  #curvas semi-transparentes
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  
  ggtitle("Distribución del Tiempo de Reacción: 800m libre vs 50m libre") +
  labs(fill = "Distancia (m)") +  
  theme_minimal() +  
  xlab("Tiempo de Reacción (s)") +  
  ylab("Densidad")
```

Las curvas se encuentran en un rango de aproximadamente 0.5 a 1 segundos, que representa los tiempos de reacción.
Para los 50 metros, la densidad es más alta en el rango de tiempos de reacción más cortos, lo que indica que las nadadoras tienden a tener tiempos de reacción más rápidos en esta distancia.
Esto es esperado, ya que la carrera de 50 metros es más corta y requiere reacciones más rápidas y explosivas.
En cuanto a la de 800 metros, la curva muestra una mayor dispersión en los tiempos de reacción, con una densidad más amplia.
Esto sugiere que los tiempos de reacción son más variados en esta distancia, probablemente debido a la naturaleza más larga y estratégica de la carrera, donde el triunfo de las nadadoras puede estar influenciado por otras variables más determinantes.

Aquí también podemos hacer un test de hipótesis.

```{r}
t.test(reactiontime~distance,data=nadadorasComparacionReactionTime)
```

Veamos nuestros resultados del test.
Por un lado tenemos el valor del estadístico t calculado, como es un valor negativo indica que la media del primer grupo (50 metros) es menor que la del segundo grupo (800 metros).El valor del p-valor (que es extremadamente bajo) indica que hay una diferencia estadísticamente significativa entre las medias de los dos grupos.
Las nadadoras que participan en distancias más cortas (50 metros) tienen un tiempo de reacción más rápido en comparación con aquellas que nadan distancias más largas (800 metros).Luego, habíamos identificado correctamente la tendencia del gráfico, en términos estadísticos.

A continuación, realizamos el mismo estudio pero con hombres y vemos si la situación es similar.

```{r}
nadadoresComparacionReactionTime<-nadadoresPruebas[(nadadoresPruebas$distance==50 | nadadoresPruebas$distance==800) & nadadoresPruebas$gender=="M", ]
```

```{r}
ggplot(nadadoresComparacionReactionTime, aes(x = factor(distance), y = reactiontime, fill = factor(distance))) +
  geom_boxplot() +
  labs(title = "Boxplot de Reaction Time: 50m vs 800m en hombres",
       x = "Distancia (m)",
       y = "Tiempo de Reacción") +
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  
  theme_minimal()

# Crear el gráfico de densidad con colores por distancia
ggplot(nadadoresComparacionReactionTime, aes(x = reactiontime, fill = factor(distance), group = distance)) +
  geom_density(alpha = 0.6) +  #curvas 
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  
  ggtitle("Distribución del Tiempo de Reacción: 800m libre vs 50m en hombres") +
  labs(fill = "Distancia (m)") +  
  theme_minimal() +  
  xlab("Tiempo de Reacción (s)") +  
  ylab("Densidad")

```

```{r}
t.test(reactiontime~distance,data=nadadoresComparacionReactionTime)
```

Al realizar el t-test para este grupo, vemos también como la diferencia es significativa entre el tiempo de reacción para la prueba de 50 metros y la de 800.

La diferencia entre estos dos extremos en las pruebas es muy significativa.
Dados estos resultados, queremos ver las tendencias en las carreras de distancia intermedia, dada nuestra intuición de que el tiempo de reacción aumente de manera gradual.
Es decir, cuál es la diferencia entre las pruebas de 50 metros, las de 100, 200, etc.

Para ello, realizaremos un gráfico de densidad conjunto.

```{r}
ggplot(nadadoresPruebas, aes(x = reactiontime, color = as.factor(distance), fill = as.factor(distance))) +
  geom_density(alpha = 0.5) +  # Ajustar la transparencia
  ggtitle("Distribución comparada de Reaction time") +
  labs(x = "Tiempo de Reacción", y = "Densidad", color = "Distancia", fill = "Distancia") +
  theme_minimal()
```

Como podemos observar, nuestras suposiciones parecen ser ciertas acerca de que las medias de los tiempos de reacción aumentan según la carrera es más larga.
Si bien es cierto, para distancias largas, como son 800 y 1500 metros, no se observan diferencias en torno a su valor central.
Del mismo modo, para carreras de 100 y 200 tampoco se observa una diferencia signifiticativa.

Contrastamos esto de forma más precisa realizando el test ANOVA de diferencia de medias.

```{r}
anova_tiempoReaccion_distancia <- aov(reactiontime ~ as.factor(distance), data = na.omit(nadadoresPruebas))
summary(anova_tiempoReaccion_distancia)
```

Interpretando estos resultados, tenemos que el p-valor es de orden e\^-16.
Por ello, podemos concluir que hay diferencias significativas en los tiempos de reacción entre al menos uno de los grupos de distancia.
Esto indica que, al menos una distancia tiene un tiempo de reacción diferente en comparación con las otras distancias.
El valor de F es alto (56.98), sugiere que la variación entre los grupos es mucho mayor que la variación dentro de los grupos.
Esto refuerza la idea de que las medias de los tiempos de reacción son significativamente diferentes entre las carreras de diferente distancia.

```{r, echo=FALSE}
rm(anova_tiempoReaccion_distancia, nadadorasComparacionReactionTime, nadadoresComparacionReactionTime, mediaTiempoReaccion)

#restauro nadadoresPruebas para el siguiente estudio: 
nadadoresPruebas<-nadadoresPruebasCopia

```

### Calles usadas(Ines).

Veamos cómo se distribuyen las calles usadas:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(nadadoresPruebas$lane)) + geom_bar(fill = "orange") +
theme_bw()

```

Se observa que las calles menos usadas son tanto la 0 como la 9.
Esto es un dato que puede resultar curioso al visualizar los datos.

Informándonos acerca de ello, las calles 0 y 9 sólo se usan en la ronda preliminar, en las semifinales y finales se usan de la 1 a la 8, luego tiene sentido que sean las menos frecuentadas por los nadadores.
Podríamos intentar visualizar si hay alguna relación entre alguna variable de nuestro dataframe y la calle usada, aunque podemos adelantar que, en cada serie, los nadadores se van colocando de más rapido a más lento de la siguiente forma: 4-5-3-6-2-7-1-8.
Luego hay que tener esto en cuenta para no sacar conclusiones equivodadas.

¿Habrá alguna relación entre la calle usada y el tiempo de reacción?

```{r, warning=FALSE}
#Creo una paleta con 10 colores: 
colores <- c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", 
             "#A65628", "#F781BF", "#999999", "#D95F02", 
             "#7570B3", "#66A61E")


ggplot(nadadoresPruebas, aes(x = reactiontime, fill = lane)) +
  geom_histogram(binwidth = 0.01, alpha = 0.7, position = "identity") +
  facet_wrap(~ lane) +  # Crear facetas por calle
  theme_bw() +
  labs(title = "Distribución de Tiempos de Reacción por Calle",
       x = "Tiempo de Reacción",
       y = "Frecuencia") +
  scale_fill_manual(values = colores)
```

Como podemos ver, no parece haber diferencias significativas según el tipo de calle en los tiempos de reacción.
De nuevo, podemos realizar un test anova sobre la diferencia de medias.

```{r}
anova_tiempoReaccion_Calles <- aov(reactiontime ~ as.factor(lane), data = na.omit(nadadoresPruebas))
summary(anova_tiempoReaccion_Calles)
```

El p-valor de nuestro análisis es menor de 0.005, por lo que podríamos sugerir que sí tiene cierta influencia según el número de calle empleada.
Sin embargo, existen muchas variables en nuestro conjunto de datos que podrían influir. 

### Daytime(Ines)

Nos genera curiosidad, por su formato, cómo se distribuye daytime, luego veamos:

```{r}
ggplot(nadadoresPruebas, aes(daytime)) + geom_bar(width=0.7, colour="red", fill="skyblue") + ggtitle("Daytime en los que se producen las pruebas")
```

Vemos que, aunque podríamos sacar alguna conclusión ya, el valor de la variable daytime debería tener el formato hora/minutos.
Por ello, lo realizamos:

```{r}
# Función para convertir
convertir_a_hhmm <- function(tiempo_numerico) {
  # Convertir el número a un string y separar horas y minutos
  horas <- tiempo_numerico %/% 100
  minutos <- tiempo_numerico %% 100
  
  # Crear un objeto de tiempo en formato hh:mm
  tiempo_formateado <- sprintf("%02d:%02d", horas, minutos)
  return(tiempo_formateado)
}

# Aplicar la función a todos los tiempos
tiempos_hhmm <- sapply(nadadoresPruebas$daytime, convertir_a_hhmm)
head(tiempos_hhmm)

```

Ahora representamos estos tiempos en una gráfica.
De esta manera, el lector puede visualizarlo sin tener que imaginar su conversión, como en el gráfico de antes.

```{r}
# Crear la columna 'tiempo_hhmm'
nadadoresPruebas$tiempo_hhmm <- sapply(nadadoresPruebas$daytime, convertir_a_hhmm)

# Convertir la nueva columna 'tiempo_hhmm' a formato POSIXct
nadadoresPruebas$tiempo_hhmm <- as.POSIXct(nadadoresPruebas$tiempo_hhmm, format = "%H:%M")

# Ahora puedes hacer el histograma
ggplot(nadadoresPruebas, aes(x = tiempo_hhmm)) +
  geom_histogram(binwidth = 3600, color = "black", fill = "blue") +  # binwidth en segundos (3600 segundos = 1 hora)
  scale_x_datetime(date_labels = "%H:%M", breaks = "1 hour") +  # Etiquetas de tiempo
  labs(
       x = "Tiempo (hh:mm)",
       y = "Frecuencia de nadadores") +
  theme_minimal()

```

Luego, podemos observar de manera clara que, cada día de competición constaba de 2 sesiones, una matinal y otra vespertina, y que las franjas horarias van, por la mañana de 9:30 a 12:30, y por la tarde de 17:30 a 19:30.

#### Pruebas matinales y vespertinas. [Alonso]

Observamos que el número de nadadores que nadan por la mañana es mucho mayor al de por la tarde.

Vamos a ver un resumen de qué pruebas se nadan por la mañana y cuáles por la tarde:

```{r}
nadadoresPruebas$tiempo_hhmm<- as.POSIXct(nadadoresPruebas$tiempo_hhmm, format = "%H:%M")
#intervalo para las matinales
limite_inferior1 <- as.POSIXct("09:30", format = "%H:%M")
limite_superior1 <- as.POSIXct("13:00", format = "%H:%M")
#intervalo para las vespertinas
limite_inferior <- as.POSIXct("17:00", format = "%H:%M")
limite_superior <- as.POSIXct("20:00", format = "%H:%M")
#Creamos los dataframes.
pruebasMatinales<-subset(nadadoresPruebas, nadadoresPruebas$tiempo_hhmm >= limite_inferior1 & nadadoresPruebas$tiempo_hhmm <= limite_superior1)

pruebasVespertinas<-subset(nadadoresPruebas, nadadoresPruebas$tiempo_hhmm >= limite_inferior & nadadoresPruebas$tiempo_hhmm <= limite_superior)
```

Bien, dividida ya nuestras pruebas en la sesion matinal y la vespertina, veamos un resumen de los datos:

```{r}
dim(pruebasMatinales)
dim(pruebasVespertinas)
```

De aquí observamos que, mientras que por las mañanas se nada un 75% de las pruebas del mundial, por las tardes sólo se nada un 25%.
Veamos si hay alguna variable que nos pueda ayudar:

```{r}
print("Resumen de rondas nadadas en sesiones matinales.")
summary(pruebasMatinales$round)
print("Resumen de rondas nadadas en sesiones vespertinas.")
summary(pruebasVespertinas$round)
```

Luego podemos concluir que, el formato que sigue el mundial de Kazán 2015 es, nadar por las mañanas las series preliminares de cada prueba, mientras que por las tardes sólo nadan los nadadores clasificados a semifinales y finales.

```{r, echo=FALSE}
rm(limite_inferior, limite_inferior1, limite_superior, limite_superior1, tiempos_hhmm, convertir_a_hhmm,pruebasMatinales, pruebasVespertinas, colores)

nadadoresPruebas<-nadadoresPruebasCopia
```

## Estudio sobre la variable distancia y su asociación con los tipos de nado. (SALMA)

Una variable que aún no hemos tratado de comprender es el tipo de nado, es decir, la variable 'stroke'.
Una pregunta que nos puede surgir es, ¿dependiendo de la distancia se nada con un estilo u otro?
Veamos sobre 'nadadoresPruebas' el estilo de nado en el que se usar en distintas distancias.

```{r}
distancia_stroke <- table(nadadoresPruebas$distance, nadadoresPruebas$stroke)
print(distancia_stroke)

```

Para analizar la relación entre las distancias y los estilos de nado en este conjunto de datos, examinaremos cómo se distribuyen los distintos estilos (BACK, BREAST, FLY, FREE, MEDLEY) en función de la distancia recorrida en metros (50, 100, 200, 400, 800, 1500).

A partir de la tabla proporcionada, se observa lo siguiente:

-En distancias cortas (50 m y 100 m) los estilos BACK, BREAST, FLY, y FREE tienen una alta frecuencia.
MEDLEY no está presente en estas distancias, lo que sugiere que este estilo no se usa en distancias cortas.
El término "medley" se refiere a una prueba en la que el nadador (o el equipo en el caso de un relevo) utiliza una combinación de los cuatro estilos principales de nado en un solo evento, en un orden específico.
Cada estilo debe nadarse en una sección de la carrera.
-En distancias intermedias (200 m), los estilos BACK, BREAST, FLY, y FREE siguen estando presentes.
Sin embargo, hay un número significativo de pruebas en el estilo MEDLEY (136), sugiriendo que este estilo comienza a ser popular en esta distancia.
-En largas distancias (400 m, 800 m, y 1500 m), tenemos por una parte que para las distancias que comienzan a ser largas (400 m), el estilo FREE es el más utilizado, seguido de MEDLEY, con 92 pruebas.Cabe destacar, que los estilos BACK, BREAST, y FLY no se encuentran en esta distancia.
Por otro lado, en los 800 m y 1500 m, sólo el estilo FREE tiene registros, lo cual es característico, ya que estas distancias se suelen nadar en estilo libre para reducir la fatiga, donde se busca mantener la velocidad y resistencia sin variaciones de estilo que pueden desgastar al nadador.

Podemos verlo con porcentajes:

```{r}
# proporciones
prop.table(distancia_stroke, margin = 1)  #proporciones por distancia

```

```{r}
ggplot(nadadoresPruebas, aes(x = factor(distance), y = stroke)) +
  geom_count() +
  labs(x = "Distancia", y = "Estilo de Nado", size = "Frecuencia") +
  ggtitle("Frecuencia de Estilos de Nado según la Distancia") +
  theme_minimal()

```

Podemos replantearnos ahora si esto se mantiene indistintamente del género del nadador.Es decir,¿Hay las mismas pruebas para mujeres y hombres?

Primero, crearemos subconjuntos de datos para cada género.

```{r}
# Filtrar los datos por género
nadadoresFemeninas <- subset(nadadoresPruebas, gender == "F")
nadadoresMasculinos <- subset(nadadoresPruebas, gender == "M")
```

```{r}
#género femenino
tabla_femenino <- table(nadadoresFemeninas$distance, nadadoresFemeninas$stroke)
print("Tabla de estilo de nado por distancia (Femenino):")
print(tabla_femenino)

# género masculino
tabla_masculino <- table(nadadoresMasculinos$distance, nadadoresMasculinos$stroke)
print("Tabla de estilo de nado por distancia (Masculino):")
print(tabla_masculino)

```

Parece que todo está funcionando como esperábamos, tanto en el análisis conjunto como en los análisis individuales.
Esto confirma que los resultados son consistentes y los datos están bien estructurados para las pruebas.

```{r, echo=FALSE}
rm(distancia_stroke, tabla_femenino, tabla_masculino, nadadoresFemeninas, nadadoresMasculinos, anova_tiempoReaccion_Calles)

```

## Estudio sobre la relación entre la edad de los nadadores y las distancias que nadan.(Salma)

```{r}
#Crear una nueva columna para clasificar por edad
nadadoresPruebas <- nadadoresPruebas %>%
  mutate(grupo_edad = ifelse(edad < 18, "Menores de 18", "18 y más"))

#Resumir el número de participantes en cada prueba por grupo de edad
resumen_pruebas <- nadadoresPruebas %>%
  group_by(grupo_edad , distance) %>%  # Agrupar por grupo de edad y prueba(LO MIRO POR DISTANCIAS)
  summarise(num_participantes = n(),.groups = "drop") %>%  #Contar el número de participantes
  ungroup() %>%  # Quitar agrupación
  arrange(grupo_edad, desc(num_participantes))  #Ordenar los resultados

# Mostrar el resumen
resumen_pruebas

```

Para poder analizar correctamente la tendencia de los nadadores según su grupo de edad, no podemos quedarnos en las frecuencias absolutas.

Debemos analizar los resultados según sus frecuencias relativas.

```{r}
# Crear una nueva columna para clasificar por edad
nadadoresPruebas <- nadadoresPruebas %>%
  mutate(grupo_edad = ifelse(edad < 18, "Menores de 18", "18 y más"))

# Contar el número total de nadadores
total_nadadores <- nrow(nadadoresPruebas)

# Resumir el número de participantes en cada prueba por grupo de edad
resumen_pruebas <- nadadoresPruebas %>%
  group_by(grupo_edad, distance) %>%  # Agrupar por grupo de edad y prueba
  summarise(num_participantes = n(), .groups = "drop") %>%  # Contar el número de participantes
  mutate(porcentaje = (num_participantes / total_nadadores) * 100) %>%  # Calcular el porcentaje
  ungroup() %>%  # Quitar agrupación
  arrange(grupo_edad, desc(num_participantes))  # Ordenar los resultados

# Mostrar el resumen
print(resumen_pruebas)


```

Lo veo gráficamente:

```{r}
# Gráfico de barras para el número de participantes por grupo de edad y distancia
ggplot(resumen_pruebas, aes(x = factor(distance), y = num_participantes, fill = grupo_edad)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Número de Participantes por Distancia y Grupo de Edad",
       x = "Distancia (m)",
       y = "Número de Participantes",
       fill = "Grupo de Edad") +
  theme_minimal()

```

La distancia de 100 y 50 metros es la distancia más popular entre los nadadores mayores de 18 años.
Le sigue la distancia de 200 metros.
La participación disminuye considerablemente en distancias más largas, como 1500 metros.
Para los menores de 18 años tenemos carreras de 100 y 50 metros como las más frecuentadas, aunque menos que el grupo de 18 años o más(hay menos menores).
La participación en distancias más largas, como 400 metros, es aún más baja en menores.

Los nadadores mayores de 18 años tienen una participación significativamente mayor en todas las distancias en comparación con los menores de 18 años.
La participación en distancias más largas tiende a ser baja en ambos grupos, pero la caída es más pronunciada en los menores de 18.

Tratando de analizar los datos obtenidos podemos concluir con que la distancia de 50 metros es la más popular entre los nadadores.
Sin embargo, la diferencia en el número de participantes entre ambos grupos de edad es significativa.
Este es un dato que es evidente con nuestras observaciones anteriores, ya que vimos que la media de los participantes está en torno a 21 años.
Por tanto, hay más de la mitad de los participantes en el segundo grupo.
Lo que si podemos apreciar es que se observa una tendencia de disminución en la participación a medida que las distancias aumentan.

```{r, warning=FALSE}
# Gráfico de líneas para mostrar la tendencia
resumen_pruebas
ggplot(resumen_pruebas, aes(x = distance, y = num_participantes, color = grupo_edad, group = grupo_edad)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  labs(title = "Tendencia de Participación en Distancias de Natación por Grupo de Edad",
       x = "Distancia (m)",
       y = "Número de Participantes") +
  scale_x_continuous(breaks = unique(resumen_pruebas$distance)) +
  scale_color_manual(values = c("blue", "orange")) +
  theme_minimal()

```

La distancia de 50 metros es la más popular, tanto para mayores como para menores de 18 años.
La participación de los mayores de 18 años es considerablemente más alta en todas las distancias.
La caída en la participación es más pronunciada en el grupo de menores de 18 años, especialmente en distancias más largas.

Nos vamos a centrar, en una de las conclusiones que hemos mencionado varias veces.
En los menores de edad,¿realmanete hay una diferencia significativa entre el número de nadadores en las pruebas más explosivas, que en las pruebas más largas?
Para ello, creamos una nueva columna, que nos indique que prueba es explosiva, y cual de más resistencia.
A continuación, procedo a quedarme con lo que me interesa(menores de edad agrupados en explosivo y resistencia)

```{r}
resumen_pruebas
# Clasificar las distancias
resumen_pruebas <- resumen_pruebas %>%
  mutate(tipo_prueba = case_when(
    distance %in% c(50, 100) ~ "Explosiva",
    distance %in% c(200, 400, 800, 1500) ~ "Resistencia",
    TRUE ~ "Otra"
  ))

# Filtrar solo los menores de 18 años y contar las participaciones
participaciones_menores <- resumen_pruebas  %>%
  filter(grupo_edad == "Menores de 18") %>%
  group_by(tipo_prueba) %>%
  summarise(total_participantes = sum(num_participantes),porcentajes_acumulativos=sum(porcentaje))

print(participaciones_menores)

```

Evidentemente, como ya nos podíamos esperar, la participación de nadadores menores de edad en pruebas explosivas es notablemente mayor que en pruebas de resistencia.
Esto se puede atribuir a la naturaleza de las pruebas, donde las pruebas explosivas, como los 50 y 100 metros, requieren menos tiempo de entrenamiento prolongado en comparación con las pruebas de resistencia, que implican una mayor dedicación y condición física a largo plazo.

```{r, echo=FALSE}
rm(participaciones_menores,resumen_pruebas, total_nadadores)

nadadoresPruebas<-nadadoresPruebasCopia

```

## Estudio sobre la variable round. [Alonso]

A continuación, vamos a intentar entender más sobre la variable ronda.
Para ello, primero vemos un resumen:

```{r}
summary(datos2015$round)
```

Observamos que toma 5 posibles valores, tenemos controlados tanto FIN (final), como PRE (preliminar) y SEM (semifinal).
Pero SOP y SOS no parece tan claro saber qué es.
Vamos a comenzar dejando de lado SOP y SOS, nos vamos a centrar en controlar los otros 3 valores.

### ¿Cuántos nadadores nadan cada ronda? [Alonso]

Una pregunta natural podría ser, ¿cuántos nadadores pasan de ronda?
¿Todos?
Está claro que al ver que por la mañana en preliminares nadan el 75% y por las tardes son semifinales y finales y son un 25%.
Veamoslo con distintas pruebas:

#### 50 libre femenino: [Alonso]

Seleccionamos las nadadoras que nadaron preliminares en el 50 libre femenino:

```{r}
free50PrelimWomens<- nadadoresPruebas[nadadoresPruebas$round=="PRE" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]

head(free50PrelimWomens,10)
```

Ahora, vamos a hacer el ranking de resultados de esta prueba, para ello:

```{r}
free50PrelimWomens<-free50PrelimWomens[order(free50PrelimWomens$swimtime), ]

dim(free50PrelimWomens)
```

Observamos que hubo 119 nadadoras que nadaron las preliminares del 50 libres.
Veamos ahora cuántas nadaron las semifinales:

```{r}
free50SemisWomens<-nadadoresPruebas[nadadoresPruebas$round=="SEM" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]
```

Antes de ordenarlas, veamos cuántas filas tengo en mi nuevo data frame:

```{r}
dim(free50SemisWomens)
```

Es decir, de 119, sólo se clasificaron 16.
Veamos si fueron las 16 primeras.
Para ello, voy a coger las 16 primeras de las prelims, voy ahora a ordenarlas por athleteid, y hacer lo mismo con las de las semifinales, a ver si coincide:

```{r}
free50PrelimWomens<-head(free50PrelimWomens, 16)

#Ordeno: 

free50PrelimWomens<-free50PrelimWomens[order(free50PrelimWomens$athleteid), ]
free50SemisWomens<-free50SemisWomens[order(free50SemisWomens$athleteid), ]

free50PrelimWomens
free50SemisWomens

```

Luego, podemos observar claramente que, las 16 primeras de las preliminares, consiguieron clasificarse a las semifinales.
Hagamos el mismo trabajo con el dataframe *free50SemisWomens* para ver cuántas nadadoras se clasificaron en la final:

```{r}
free50SemisWomens<-free50SemisWomens[order(free50SemisWomens$swimtime), ]

```

Al igual que antes, confeccionamos el dataframe de la final:

```{r}
free50FinalWomens<-nadadoresPruebas[nadadoresPruebas$round=="FIN" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]

dim(free50FinalWomens)
```

Observamos que hay 8, luego las 8 primeras se clasificaron a la final.

### ¿Se nadan las 3 rondas en cada prueba?(ALONSO)

Esta cuestión nos surge ya que, algunas pruebas requieren más esfuerzo y el tiempo de descanso para la recuperación total es más largo, por ello alomejor hay pruebas en las que sólo hay 1 ronda, o 2, o esta suposición es falsa y en cada prueba se nadan 3 rondas.
Para ello, echemos un cálculo inicial.
Hay 2 géneros, pruebas de 50, 100, 200, 400, 800 y 1500 metros.
Veamos qué valores toman las rondas en cada una de estas pruebas.
Para ello:

```{r}
print("Rondas que se nadan en las pruebas de 50 metros: ")
summary(nadadoresPruebas[nadadoresPruebas$distance==50, ]$round)
print("Rondas que se nadan en las pruebas de 100 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==100, ]$round)
print("Rondas que se nadan en las pruebas de 200 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==200, ]$round)
print("Rondas que se nadan en las pruebas de 400 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==400, ]$round)
print("Rondas que se nadan en las pruebas de 800 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==800, ]$round)
print("Rondas que se nadan en las pruebas de 1500 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==1500, ]$round)
```

Luego, observamos que en las pruebas de 400, 800 y 1500 metros no hay semifinales, tan sólo una ronda preliminar y una ronda final.

También podemos sacar conclusiones gracias al estudio hecho en el apartado anterior.
En los 50 por ejemplo, hay 128 nadadores que nadan semifinales, hay dos géneros, luego 64 nadadores por género nadaron semifinales, además, hay 4 estilos, luego 16 nadadores nadaron las semifinales de cada prueba, lo cual concuerda con lo visto anteriormente.

Destaca a la vista que, en las pruebas de 200 metros, hay más nadadores.
¿Por qué sucede esto?.
Veamos:

```{r}
print("Estilos que se nadan en pruebas de 50 metros: ")
summary(nadadoresPruebas[nadadoresPruebas$distance==50, ]$stroke)
print("Estilos que se nadan en pruebas de 200 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==200, ]$stroke)
```

Hay más nadadores que nadan semifinales puesto que hay 5 pruebas, no 4.
Si echamos los cálculos, 160/(2\*5)=16 nadadores, igual que en las demás.

Se puede ver de manera análoga que nadan 8 nadadores cada final.

Ahora, ya que hemos analizado a fondo qué sucede con las finales, semifinales y preliminares, vamos a ver qué significan los otros dos valores que toma la variable *round*.

### Rondas SOP [Alonso]

Bien, primeramente, vamos a observar las filas tales que toman ese valor.
Lo hacemos de la siguiente manera:

```{r}
datosSOP<-datos2015[datos2015$round=="SOP",]

datosSOP
```

Observamos 4 filas, que se trata, viendo que es el mismo *eventid*, de una prueba que nadan sólo 2 nadadoras, Osman y Kelly.
En este caso, un 100 mariposa.
Es curioso que estas dos nadadoras naden una sóla prueba.
Además, nadaron a las 11:56, por la mañana, donde sólo se nadan preliminares.
Vamos a ver si descubrimos algo viendo la clasificación de ese 100 mariposa en la ronda preliminar:

```{r}
fly100PREWomen<-nadadoresPruebas[nadadoresPruebas$distance==100 & nadadoresPruebas$stroke=="FLY" & nadadoresPruebas$round=="PRE" & nadadoresPruebas$gender=="F", ]

#Ahora ordenamos por tiempo
fly100PREWomen<-fly100PREWomen[order(fly100PREWomen$swimtime), ]
#Las ordeno
rownames(fly100PREWomen) <- 1:nrow(fly100PREWomen)
head(fly100PREWomen,20)

```

Si busco a Osman y Kelly en el anterior dataframe, observo que se encuentran en el puesto 16 y 17 respectivamente y que, hicieron el mismo tiempo.
Luego tiene sentido razonar que, las rondas SOP son rondas de desempate para ver quién pasa a la siguiente ronda.

### Rondas SOS [Alonso]

Viendo el razonamiento de las rondas SOP, intuimos que las rondas SOS deben ser rondas de desempate entre nadadores de las semifinales.
De todas maneras, vamos a verlo.
Para ello, si nos fijamos en una de los dataframes anteriores, en la prueba de 200 metros había 4 nadadores que nadan la ronda SOS.
Vamos a visualizarlo:

```{r}
datosSOS<-nadadoresPruebas[nadadoresPruebas$round=="SOS" & nadadoresPruebas$distance==200, ]
datosSOS
```

Vemos que se nadaron dos rondas SOS, una para la prueba de 200m braza femenino, y otra para la prueba de 200 estilos masculino.
Elijamos el 200 estilos masculino, visualicemos el ranking de las semifinales y veamos si están Roberto Pavoni y Conor Dwyer empatados en el 8vo y 9no puesto:

```{r}
medley200SEM<-nadadoresPruebas[nadadoresPruebas$round=="SEM" & nadadoresPruebas$distance==200 & nadadoresPruebas$gender=="M" & nadadoresPruebas$stroke=="MEDLEY", ]

#Ahora, ordeno igual que antes: 

medley200SEM<-medley200SEM[order(medley200SEM$swimtime), ]
#Las ordeno
rownames(medley200SEM) <- 1:nrow(medley200SEM)
medley200SEM
```

Y efectivamente, empataron con un tiempo de 118.54 segundos, luego SOS equivale a las rondas de desempate producidas en las rondas semifinales.
Además, observamos que se realizan por las tardes.

Luego, ya hemos resuelto las dudas acerca de Round.

```{r, echo=FALSE}
rm(datosSOP, datosSOS, fly100PREWomen, free50FinalWomens, free50PrelimWomens, free50SemisWomens, medley200SEM)

```

## Estudios relacionados con los puntos(Javi).

Veamos las posibles relaciones de puntos con las demás variables:

Antes de ello, vamos a tener que eliminar de este estudio a los nadadores descalificados (es decir, los que tienen NA points).

```{r}
nadadoresPruebas <- nadadoresPruebas %>% filter(!is.na(nadadoresPruebas$points))
```

### Mejor nadador por prueba nadada. MVP de los mundiales(Javi).

Veamos ahora cómo se distribuyen los puntos.

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = points)) +
geom_density() +
ggtitle("Distribución. points")
```

Observamos que la mayoría de puntos se encuentran a partir de los 750/800 puntos, y esto, tiene sentido si razonamos que para entrar a los mundiales de natación, se necesitan unas marcas mínimas (una cantidad de puntos preestablecida).
Luego es normal encontrar una gran cantidad de datos que tengan más de 750 puntos ya que había un "corte" para la inscripción en la competición.
Esto hace que la gráfica no esté más distribuida por todos los posibles valores de puntos.

Ahora nos surge la siguiente pregunta: *¿Quién rindió mejor en los campeonatos?*.

Podemos buscar el nadador que hizo más puntos:

```{r}
datos2015[which.max(datos2015$points), ]
```

Observamos que la nadadora que cosechó más puntos en una prueba fue Katie Ledecky en los 1500 metros.
Buscando, casualmente observamos que batió el récord[<https://www.rtve.es/deportes/20150803/ledecky-bate-record-del-mundo-1500-libres/1193160.shtml>] del mundo en dicha prueba.

Ahora, vamos a buscar al nadador que, en promedio, consiguió más puntos, podríamos denominarlo el *MVP* del Mundial Kazán 2015.
Para ello:

```{r}
#Usamos nadadoresPruebas, donde tenemos cada nadador y la prueba que realizó. 

media_puntos <- aggregate(nadadoresPruebas$points ~ nadadoresPruebas$athleteid, data = nadadoresPruebas, FUN = mean)
media_puntos <- media_puntos[order(media_puntos$`nadadoresPruebas$points`, decreasing = TRUE), ]
media_puntos<- rename(media_puntos, "athleteid"="nadadoresPruebas$athleteid")
media_puntos<-rename(media_puntos, "meanPoints"="nadadoresPruebas$points")

head(media_puntos,5)
```

El atleta con id 108588 es el que hizo más puntos, veamos quien es:

```{r}
nadadoresPruebas[nadadoresPruebas$athleteid==108588	, ]
```

Luego, el MVP fue el británico Adam Peaty, que nadó 50, 100 y 200 braza.
Veamos quiénes fueron los integrantes del podio:

```{r}
nadadoresParticipantes[nadadoresParticipantes$athleteid==102630 | nadadoresParticipantes$athleteid==105594, ]
```

Completaron el podio Cameron Van der Burgh, de Sudáfrica, y Katie Ledecky.

### Puntos. Hombres vs Mujeres(Ines)

A continuación, vamos a comparar los puntos realizados por hombres y mujeres, para ver si podemos sacar alguna conclusión.

Primeramente, vamos a ver la función de densidad:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = points, colour=gender)) +
geom_density() +
ggtitle("Distribución. Puntos por sexo")

```

A priori, parece haber dos distribuciones muy igualadas.

```{r}
modelo= lm(points ~ gender, data = nadadoresParticipantes)

summary(modelo)

# Realizar ANOVA
anova_puntos_genero <- aov(points ~ gender, data = nadadoresParticipantes)

# Ver el resumen del resultado
summary(anova_puntos_genero)

```

### Puntos. ¿La edad influye?(Salma)

Una buena manera de medir el rendimiento con respecto a la edad del nadador, es verlo a través de los puntos obtenidos.

```{r, warning=FALSE}
# Resumen de puntos por edad
resumen_puntos <- nadadoresPruebas %>%
  group_by(edad, points) %>%
  summarise(frecuencia = n(), .groups = 'drop')

# Crear el gráfico de calor
ggplot(resumen_puntos, aes(x = edad, y = points)) +
  geom_tile(aes(fill = frecuencia), color = "black") +
  # Usar una paleta de colores divergente
  scale_fill_gradientn(colors = brewer.pal(9, "Reds"), 
                       limits = c(min(resumen_puntos$frecuencia), max(resumen_puntos$frecuencia))) + 
  theme_bw() +
  labs(title = "Gráfico de Calor: Edades y Puntos Obtenidos",
       x = "Edad",
       y = "Puntos Obtenidos") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

```{r}
# Crear una nueva columna que clasifica a los nadadores en grupos de edad
nadadoresPruebas <- nadadoresPruebas %>%
  mutate(grupo_edad = case_when(
    edad < 18 ~ "Menores de 18",
    edad >= 18 & edad <= 30 ~ "Entre 18 y 30",
    edad > 30 ~ "Mayores de 30"
  ))

# Calcular el promedio de puntos por grupo de edad
promedio_puntos <- nadadoresPruebas %>%
  group_by(grupo_edad) %>%
  summarise(promedio = mean(points, na.rm = TRUE))

# Crear un gráfico de barras para visualizar el promedio de puntos
ggplot(promedio_puntos, aes(x = grupo_edad, y = promedio, fill = grupo_edad)) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_brewer(palette = "Reds") +  # Cambiar la paleta si es necesario
  theme_bw() +
  labs(title = "Promedio de Puntos por Grupo de Edad",
       x = "Grupo de Edad",
       y = "Promedio de Puntos") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none")
```

Vamos a comparar los puntos con la edad.
Para ello, vamos a dividir en 3 grupos por edades (menores de 18, entre 18 y 30 y mayores de 30) y a comparar el promedio de puntos cosechados por cada franja de edad.

```{r}
# Mostrar el promedio de puntos en una tabla
promedio_puntos %>%
  kable(caption = "Promedio de Puntos por Grupo de Edad", 
        col.names = c("Grupo de Edad", "Promedio de Puntos"))

```

En el grupo de edad entre 18 y 30, el promedio de Puntos es 817.76.Este grupo presenta el promedio más alto en comparación con los otros grupos.
Esto podría indicar que los nadadores en este rango de edad tienen un rendimiento superior en términos de puntos acumulados.
Esto puede ser atribuible a varios factores, como una mayor experiencia.
El grupo de Edad Mayores de 30 tiene un promedio de 806.32 puntos.
Los nadadores mayores de 30 años tienen un promedio de puntos ligeramente inferior al grupo de 18 a 30 años.
Sin embargo, el rendimiento sigue siendo fuerte, lo que sugiere que, aunque pueden enfrentar desafíos relacionados con la edad, muchos continúan siendo competitivos.
El grupo de Edad Menores de 18 tiene un promedio de 621.36 puntos.
Este grupo muestra el promedio más bajo en comparación con los otros dos.
Esto puede ser indicativo de que los nadadores jóvenes aún están en desarrollo y adquiriendo habilidades y experiencia.
Es natural que los nadadores más jóvenes, al estar en una etapa temprana de su carrera, acumulen menos puntos.

La diferencia significativa en el rendimiento entre los grupos puede sugerir que la edad tiene un impacto positivo en el rendimiento de los nadadores, al menos hasta cierto punto.
Esto también resalta la importancia del entrenamiento y la experiencia que se adquiere con la edad.
Es posible que los nadadores más jóvenes tengan que enfocarse en su desarrollo técnico y competitivo para alcanzar a sus contrapartes mayores.
Esto podría incluir mejorar sus técnicas de natación, preparación física, y estrategias de carrera.

Realizamos un test para ver si la diferencia es significativa

```{r}
# Realiza la prueba de Kruskal-Wallis
kruskal_result <- kruskal.test(points ~ grupo_edad, data = nadadoresPruebas)
print(kruskal_result)
```

El p-value \< 2.2e-16: Este valor p es extremadamente bajo, lo que indica que hay diferencias significativas en los puntos entre al menos uno de los grupos de edad.
Dado que el valor p es muy pequeño, puedes rechazar la hipótesis nula, que sostiene que no hay diferencias en las medianas de los puntos entre los grupos.

Aunque Kruskal-Wallis indica que hay diferencias, no te dice cuáles son esos grupos que difieren.
Por lo tanto, es recomendable realizar pruebas post-hoc para identificar qué grupos son significativamente diferentes entre sí.

```{r, warning=FALSE}
# Prueba de Dunn
dunn_test <- dunnTest(points ~ grupo_edad, data = nadadoresPruebas, method = "bonferroni")
print(dunn_test)
```

Entre 18 y 30 vs. Mayores de 30: No hay evidencia suficiente para afirmar que hay una diferencia significativa en los puntos entre estos dos grupos de edad.
Entre 18 y 30 vs. Menores de 18: Hay una diferencia altamente significativa en los puntos entre estos dos grupos.
Esto indica que los nadadores menores de 18 años obtienen significativamente menos puntos que los nadadores entre 18 y 30.
Mayores de 30 vs. Menores de 18: También hay una diferencia altamente significativa entre estos grupos, sugiriendo que los nadadores mayores de 30 años obtienen significativamente más puntos que los nadadores menores de 18.

La comparación muestra que, mientras que no hay diferencia significativa entre los grupos de 18-30 y mayores de 30, los menores de 18 años se desempeñan significativamente peor en términos de puntos en comparación con ambos grupos de mayores edad.

```{r}
ggplot(nadadoresPruebas, aes(x = grupo_edad, y = points, fill = grupo_edad)) +
  geom_boxplot() +
  labs(title = "Distribución de Puntos por Grupo de Edad", 
       x = "Grupo de Edad", 
       y = "Puntos") +
  theme_minimal()

```

```{r, echo=FALSE}
#vuelvo de nuevo a la original

rm(anova_puntos_genero, dunn_test, kruskal_result, media_puntos, modelo, promedio_puntos, resumen_puntos)
nadadoresPruebas<-nadadoresPruebasCopia
```

### Modelo de regresión lineal: reactiontime vs swimtime(Salma)

```{r, echo=FALSE}
# Esto no funciona porque las dos variables continuas tienen distinto tamaño
# Hay que gestionar los NAs previamente
# Además, como solo se está trabajando con dos variables continuas, no tiene sentido hacer pairs
# Realmente es un único plot
# pairs(nadadoresPruebas$points,splitswimtime)
```

Empezamos viendo la relación lineal (que ya sabemos que será alta) entre puntos y tiempo.
Es evidente que a mayor tiempo, hay menos puntos.
Veámoslo

```{r}
nadadoresPruebas50crol<- nadadoresPruebas[nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=='FREE', ]
t= nadadoresPruebas50crol$swimtime
p= nadadoresPruebas50crol$points
cor(nadadoresPruebas50crol$swimtime,nadadoresPruebas50crol$points)
head(nadadoresPruebas50crol,10)

```

Esto no es de mucho estudio, ya que es lo lógico.

Veamos los puntos respecto al tiempo de reacción:

```{r}
nadadoresPruebas<- na.omit(nadadoresPruebas)
x= nadadoresPruebas$points
y=nadadoresPruebas$reactiontime
```

```{r}
cor(x,y)
```

Parecen no estar correlacionadas el tiempo de reaccion y los puntos de manera lineal.
Pero a lo mejor, en pruebas específicas , como las pruebas de distancias cortas la correlación es mayor.

```{r}
nadadoresPruebas50<- nadadoresPruebas[nadadoresPruebas$distance==50, ]
X=nadadoresPruebas50$reactiontime
Y=nadadoresPruebas50$points
cor(X,Y)
```

Ya tenemos nuestro objetivo de estudio ya que para comenzar con la modelización estadística, debemos contextualizar el problema, definiendo objetivos y variables.

Queremos investigar si existe relación entre el tiempo de reacción y puntos.
Una pregunta que puede surgirnos es, ¿A mayores valores del tiempo de reacción, hay mayores valores de puntos?
Luego, nuestro objetivo será saber si hay algún tipo de relación lineal, y las variables, por ende, serán tiempo de reacción y puntos.
La variable tiempo de reacción, será nuestra variable independiente, y puntos será la variable dependiente.

A continuación, procedemos a realizar una inspección gráfica simple, para identificar tendencias.

```{r}
plot(X,Y,xlab="Tiempo de reacción",ylab="Puntos")
```

```{r}
cov(X,Y)
```

Esta covarianza, positiva y grande en valor absoluto, nos indica que hay relación negativa entre las variables(ya lo habíamos intuido pero gracias al signo lo hemos confirmado).

A pesar de la confirmación, en este momento nos surge un problema, pues, la covarianza toma valores en todos los números reales, dependiendo de las magnitudes del tiempo de reacción y puntos, y de sus unidades .
Por eso, calcularemos el coeficiente de correlación lineal, que se obtiene tipificando la covarianza, es decir, dividiendo la covarianza entre las desviaciones típicas muestrales (obteniendo un coeficiente entre -1 y 1)

```{r}
cor(X,Y)
```

De manera adicional, podemos incluir histogramas marginales en cada eje del gráfico, para ello usamos las librerías `ggplot2` y `ggExtra`.

```{r}
datos<-data.frame(x=X,y=Y)

p<-ggplot(datos, aes(x = X, y = Y)) +
  geom_point()
#vemos la nube de puntos 
print(p)
#Especificamos que se añadan histogramas en los márgenes
ggMarginal(p, type = "histogram")

```

Como hemos visto, si la relacion lineal es fuerte tiene sentido querer ajustar una recta a la nube de puntos.
Es decir, considerar un modelo de regresion lineal simple.

La función que ajusta el modelo de regresión lineal simple en R es `lm`(con parametros B_0,B_1 y sigma\^2), directamente hacemos un `summary` para que nos devuelva la información más importante, aunque realmente `lm` calcula muchas cosas: estimaciones, residuos, predicciones, etc.

```{r}
lm=lm(Y~X)
summary(lm)
```

Podemos añadir la recta de regresión al gráfico usando el comando `abline`, y el objeto donde hemos guardado el ajuste de la recta, en este caso `lm4`:

```{r}
#representamos
plot(X,Y)
#añadimos la recta de regresion
abline(lm)
```

Los coeficientes de la regresión estimados también están en el objeto donde hemos guardado el ajuste, en `lm`

```{r}
#generamos un vector con los coeficientes de la regresion
coeficientes=lm$coefficients
#comprobamos que es lo mismo que nos salía en el summary
coeficientes
```

Sabemos que el valor de los puntos cuando X=0, es decir, que el tiempo de reacción sea cero, es de 1809 aproximadamente.
Este parámetro no tendría sentido, pues el tiempo de reacción nunca va a ser cero.
Por otro lado la pendiente es -1562.315, lo que nos muestra que por cada valor que aumenta X, Y aumenta lo indicado.

```{r, echo=FALSE}

#Este código al final del estudio para no sobrecargar el entorno (Enviroment)
rm( datos, lm, coeficientes, t, x, X, y, Y, nadadoresPruebas50, nadadoresPruebas50crol, p)

nadadoresPruebas<- nadadoresPruebasCopia

```

## Prueba 800m Libre femenino. [Alonso]

Quiero evaluar la prueba 800m libres.

Veamos qué nadadores nadaron el 800 libre femenino:

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
nadadoras800free<-nadadoresPruebas[nadadoresPruebas$distance==800 & nadadoresPruebas$gender=="F", ]

dim(nadadoras800free)
```

Se observa que no hay descalificaciones en el 800 libres femenino.
Tenemos que 51 chicas nadaron el 800 libres, algunas de ellas dos veces ya que pasaron a la final.

Nos vamos a fijar en la final, para ello, filtramos otra vez los datos:

```{r}
nadadoras800free<-datos2015[datos2015$gender=="F" & datos2015$distance==800 & datos2015$round=="FIN", ]

```

#### Estudio sobre los parciales de la carrera.(ALONSO)

Vamos a evaluar cómo fueron los parciales de las nadadoras, para ello hacemos el siguiente gráfico:

```{r, warning=FALSE}
ggplot(nadadoras800free, aes(y=nadadoras800free$lastname, x=nadadoras800free$splitswimtime, fill=nadadoras800free$lastname))+
  geom_boxplot()+
  labs(x="Parciales", y="Nadadoras")
```

De aquí podemos observar la media y los cuantiles de los parciales de las nadadoras.
Observamos que casi todas tienen 1 o incluso 2 puntos atípicos, seguramente se deban al primer y último parcial de la prueba.
Además, podemos observar que algunas nadadoras como Kapas y Friis, tuvieron una desviación muy pequeñita en sus parciales, es decir, fueron a un ritmo constante durante toda la prueba clavando sus parciales.

Vamos a observar, para cada nadador, los parciales realizados para ver si podemos conseguir algún patrón de tipo de carrera:

```{r, warning=FALSE}
ggplot(nadadoras800free, aes(x=nadadoras800free$splitdistance, y=nadadoras800free$splitswimtime, group = lastname, colour =lastname )) + 
  geom_line()  + 
  geom_point( size=2, shape=21, fill="white") + 
  theme_minimal()+
  labs(x="Parciales", y="Tiempos por parcial.")
```

Observamos que todas nadan muy rápido tanto el primer parcial como el último.
Además, vemos de manera clara como Ledecky parece que alterna un largo un poco más rapido y luego otro más lento durante toda su prueba.
¿Puede ser una estrategia de carrera?
Lo veremos más adelante.
También vemos alguna otra nadadora más que hace algo similar como Van Rouwendaal.
Otras en cambio, intentan conservar el ritmo marcado desde el inicio y ser constantes.
Carlin mete un cambio de ritmo muy drástico al paso de los 650m de 31s altos a 31s bajos y sigue luego bajando.

#### Visualización de la carrera.(alonso)

Ahora, vamos a definir un dataframe en el que nos va a importar el nombre, la suma total de tiempo al paso de cada parcial:

```{r}
nadadoras800free <- nadadoras800free %>%
  dplyr::select(lastname,firstname,gender,reactiontime,splitdistance,cumswimtime, swimtime)

```

Visualizamos la carrera:

```{r}
# Ordenar los datos por tiempo
nadadoras800free <- nadadoras800free %>%
  arrange(splitdistance, cumswimtime)

# Crear un índice de posición
nadadoras800free <- nadadoras800free %>%
  group_by(splitdistance) %>%
  mutate(Posicion = rank(cumswimtime, ties.method = "first"))



ggplot(nadadoras800free, aes(x = splitdistance, y = Posicion, group = lastname)) +
  geom_line(aes(color = lastname, alpha = 1), size = 2) +
  geom_point(aes(color = lastname, alpha = 1), size = 4) +
  scale_y_reverse(breaks = 1:nrow(nadadoras800free))
```

Observamos como Ledecky lidera toda la carrera, Boyle alcanza al paso de los 100 metros la segunda posición y la mantiene.
La pelea por la última medalla en juego dura hasta los 700 metros, donde un adelantamiento de Carlin a Ashwood hace que la nadadora Jaz Carlin alcance el bronce olímpico.

```{r, echo=FALSE}
rm(nadadoras800free)
```

# PCA's

Realizaremos ahora el análisis de componentes principales del 800m libres femenino:

## Análisis de componentes principales. 200 mariposa masculino preliminares (Salma)

La idea de realizar el siguiente PCA es porque disponemos de gran cantidad de variables, algunas de las cuales están correlacionadas entre sí, lo que complica su análisis.
En estas situaciones es conveniente aplicar el método de componentes principales, que permita reducir el número de variables sin pérdida sustancial de información, y consiguiendo que estas nuevas variables sean incorreladas evitando así que haya información redundante.

Comenzamos,cargando los datos:

```{r}
prueba200MariposaMasc<- datos2015[datos2015$distance==200 & datos2015$gender=="M" & datos2015$stroke=="FLY"& datos2015$round=="PRE", ]

prueba200MariposaMasc <- prueba200MariposaMasc %>%
    dplyr::select(lastname, reactiontime, splitdistance, splitswimtime, edad)
```

Creamos un dataframe en la que nos quedamos con el nombre, apellidos y parciales

```{r, warning=FALSE}
pruebita <- prueba200MariposaMasc %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
head(pruebita,10)
#omito los valores nulos: 
pruebita<- na.omit(pruebita)
row.names(pruebita) <- pruebita$lastname # esto es para llamar a las filas con el nombre de los nadadores
head(pruebita,10)
```

Calculas estadísticas descriptivas utilizando 'pastecs::stat.desc' para entender mejor tus datos:

```{r}
pastecs::stat.desc(pruebita, basic = F)
```

Se puede observar que hay grandes diferencias entre las varianzas de las variables, lo que puede afectar a los resultados de un análisis de componentes principales (ACP), debido a que las variables con mayor varianza tendrán más influencia en la generación de un componente.

El ACP tiene sentido cuando hay correlación entre las variables pues permite eliminar información redundante.
Si se analiza la matriz de correlaciones se puede ver, a modo de ejemplo, que hay correlaciones fuertes.Luego, procedemos con el PCA

```{r}
prueba200MariposaMasc2<- datos2015[datos2015$distance==200 & datos2015$gender=="M" & datos2015$stroke=="FLY"& datos2015$round=="PRE", ]

prueba200MariposaMasc2 <- prueba200MariposaMasc2 %>%
    dplyr::select( reactiontime, splitdistance, splitswimtime, edad)

R <- cor(prueba200MariposaMasc2)
corrplot::corrplot(R, method = "number", 
                   number.cex = 0.75) # Matriz de correlaciones con números en letra pequeña
```

Para la obtención de los componentes principales utilizamos la función princomp.
Para evitar la influencia de la diferencia en magnitud de las varianzas se puede emplear los datos originales y el argumento cor = TRUE o los datos originales estandarizados y el argumento cor = FALSE.Utilizaremos el primer caso,ya que conseguimos que la suma de las varianzas de las variables originales y la de los componentes coincida con el número de variables de la matriz de datos original.

```{r, warning=FALSE}
componentess=prcomp(pruebita[,-1], cor = TRUE)
summary(componentess)
```

Los componentes están ordenados en función de la varianza que explican y el porcentaje acumulado permite decidir con cuántos componentes trabajar.
En este caso con solo dos se explica el 96%, con tres el 98%, con uno el 68%...

Generalmente, hay un número pequeño de componentes, los primeros, que contienen casi toda la información y el resto suele contribuir relativamente poco.
Ya lo hemos visto en nuestro estudio.
Podemos directamente coger 2, trabajar sobre el plano y tener una alta varianza explicada, pero vamos a demostrarlo de una manera un poco más empírica.
Utilizamos el criterio del autovalor superior a la unidad (regla de Kaiser) y el gráfico de sedimentación (scree test).

Para el primero, tenemos que saber que este criterio retiene aquellos componentes cuyos valores propios son superiores a la unidad y funciona bastante bien salvo con un gran número de variables, que no es nuestro caso.Luego, será muy preciso.
Las raices de los autovalores asociados a la matriz de correlaciones son las desviaciones típicas de los componentes y se encuentran en '\$sdev' del objeto componentes creado con la función princomp.

```{r}
auto<-componentess$sdev^2
auto
```

El número de componentes a retener según este criterio sería 2, ya que únicamente hay 2 autovalores mayores que uno.
Como ya se ha visto, esta decisión implicaría quedarnos con un 96% de la varianza total de los datos, que es bastante.

Otra manera de ver el número de componentes que escojamos, más gráfica, es un gráfico de sedimentación (scree test).
Este gráfico muestra en el eje de ordenadas los autovalores y en el eje de abscisas los componentes.
Los cambios en la pendiente nos permiten observar cuánta capacidad explicativa va aportando cada componente.

Se escoge el número de componentes a partir del cual los autovalores restantes son relativamente más pequeños en comparación con él.

```{r}
plot(componentess, type="lines", main = "Gráfico de sedimentación")
abline(h=1, lty=3, col="red")
```

El gráfico de codo nos aconseja también quedarnos con 2 componentes.
Ambos criterios ofrecen la misma conclusión, que el número de componentes a retener es 2.

Una vez pasamos a la interpretación de las componentes debemos estudiar sus relaciones con cada una de las variables originales.
Para ello se obtienen e interpretan las correlaciones entre los componentes (componentes\$scores) y las variables.
Una forma de calcularla es con la función cor:

```{r}

Cor_CompVar <- round(cor(pruebita[,-1], componentess$scores), 4) # con round se redondea, en este caso concreto, a 4 decimales 
Cor_CompVar
```

Estos coeficientes que se acaban de calcular son los que se utilizan para interpretar los componentes.
Como se ha decidido retener solo dos componentes, es conveniente crear un objeto que contenga solo las correlaciones con esos tres componentes, que será el objeto a analizar:

```{r}
Cor_CompVar_retenidos <- Cor_CompVar[, 1:2]
Cor_CompVar_retenidos
```

Antes de seguir con la interpretación de los componentes, es conveniente analizar si con el número de componentes elegido (dos) están todas las variables bien representadas.
Para ello se utiliza el coeficiente de correlación al cuadrado.El valor de la correlación al cuadrado se utiliza para estimar la calidad de la representación.
Cuanto más cercano esté a la unidad, mejor será esta.

```{r}
round(Cor_CompVar[,1:2]^2, 4) # con round se redondea, en este caso concreto, a 4 decimales
```

Estos resultados se pueden visualizar con corrplot:

```{r}
corrplot::corrplot(factoextra::get_pca_var(componentess)$cos2[, 1:2], is.corr = F)
```

La variable correspondiente a 200m se explica principalmente por la componente 1, lo que sugiere que el rendimiento en esta distancia está fuertemente asociado a la variabilidad que captura este componente.
La visualización indica que esta relación tiene un porcentaje de varianza explicada de aproximadamente 37% lo cual es significativo.La variable 150m también tiene una correlación notable con el componente 1, aunque en menor medida que la variable de 200m.
Esto indica que el rendimiento en 150m también está influenciado por las mismas características que se reflejan en el componente 1.

La variable edad tiene un fuerte impacto en el componente 1, con un porcentaje de varianza explicada alrededor del 74%.
Esto sugiere que este componente refleja características que son particularmente relevantes para la edad de los nadadores, implicando que, a medida que los nadadores envejecen, sus tiempos y capacidades en el agua podrían verse influidos por la edad.
Este hallazgo es importante porque indica que la edad no solo es un factor en el rendimiento, sino que también está profundamente integrada en los componentes que explican la variabilidad del rendimiento en natación.

```{r}


factoextra::fviz_cos2(componentess, choice = "var", 
                      axes = 1:2, # axes recoge los componentes a utilizar
                         title = "Cos2 de las variables para los componentes 1 a 2") 
```

En este caso, se representa la suma de cos2 para los 2 componentes.La proporción de variabilidad explicada por los dos componentes retenidos es bastante baja.

Procedemos, con la función fviz_pca_var del paquete factoextra, donde sobre un círculo de radio unidad, se sitúan las variables, utilizando como coordenadas sus correlaciones con cada uno de los componentes en el plano.
Además, las variables se pueden colorear en función de distintas características, entre las que destacan su contribución y el valor del cos2 (por ejemplo, verde, naranja o rojo dependiendo de que sean valores bajos, medios o altos, respectivamente).

En edad,la recta formada por la primera componente solo explica el 0,28% de la varianza de edad, lo que significa que está pobremente representado por esta dimensión.

```{r}

factoextra::fviz_pca_var(componentess, col.var = "cos2", 
                         gradient.cols = c("green", "orange", "red"),
                         repel = TRUE,
                         title = "Cos2 de las variables en el plano 1")
```

Cuanto más cercana esté una variable al borde, mejor será la calidad de la representación en el conjunto de las dos componentes.

La variable reactiontime también se observa en una posición cercana al centro del círculo, lo que sugiere que su variabilidad no está suficientemente capturada por los dos componentes principales.
Esto refuerza la idea de que el tiempo de reacción podría requerir un análisis más profundo o considerar otros componentes adicionales para una representación más adecuada.
Por el contrario, otras variables relacionadas con las distancias (como las variables de 50m, 100m, 150m, y 200m) están más alejadas del centro, lo que indica que están bien representadas por los dos primeros componentes.
Esto sugiere que estos componentes capturan la mayor parte de la variabilidad del rendimiento en natación en estas distancias.
Este PCA, dadas las conclusiones que hemos obtenido, y las variables que hay, simplemente se utilizará para entender la manera de proceder


## Análisis de componentes principales del 800 libres femenino. Ronda preliminar [Alonso]

Lo primero que debemos hacer es cargar los datos:

```{r}
prueba800libresPreliminar<- datos2015[datos2015$distance==800 & datos2015$gender=="F" & datos2015$stroke=="FREE" & datos2015$round=="PRE", ]

prueba800libresPreliminar <- prueba800libresPreliminar %>%
    dplyr::select(lastname, reactiontime, splitdistance, splitswimtime, edad)
```

Bien, ahora, debemos encontrar la manera de crear un dataframe en la que nos quedemos con el nombre, apellido y parciales.

```{r, warning=FALSE}
pruebawide <- prueba800libresPreliminar %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
#omito los valores nulos: 
pruebawide<- na.omit(pruebawide)
pruebawide<- as.data.frame(pruebawide)
rownames(pruebawide) <- pruebawide$lastname

```

Ahora que ya tenemos nuestro dataframe hecho, vamos a hacer el PCA:

```{r}
pca800libres<-prcomp(pruebawide[,-1], scale=T)

plot(pca800libres)

```

Vemos la importancia de cadad componente.

Observemos además, un resumen numérico:

```{r}
summary(pca800libres)
```

Viendo el pca, observamos que con la primera componente, tenemos un 84% de la varianza.
Con pc2 un 6%, luego con esas dos logramos explicar un 90% de los datos.

Hagamos una interpretación previa a la graficación de los datos:

```{r}
pca800libres
```

La PCA1 corresponde a una media ponderada en la cual, lo que más ponderan son los parciales de la prueba, siendo los más significativos del 200 al 650.
También toma algo de importancia la edad pero no se verá reflejada.
Luego, nos esperaremos más a la izquierda los nadadores cuyo tiempo medio sea menor (es decir, las más rapidas de las preliminares), y a la derecha las nadadoras más lentas en promedio.

La PCA2, cobra muchísima importancia el tiempo de reacción y la edad.
Luego, esperaremos, contra más arriba se encuentren, nadadoras con un buen tiempo de reacción o pocos años, y abajo nadadoras con mal tiempo de reacción o muchos años.

Ahora, veamos cómo se ven los datos:

```{r}
plot(pca800libres$x[,1:2], type="n")
text(pca800libres$x[,1:2],rownames(pruebawide), cex = 0.4)

```

Luego, podríamos decir que, el grupo de Ledecky, Carlin... fueron las más rapidas de las preliminares.
Chentson, Holowchak y Rannvaardottir las más lentas.

También, podríamos decir que, nadadoras como Jo, corresponden a un tiempo de reacción muy bajo junto con una edad baja.
Nadadoras como Kobrich y Elhenicka, serán nadadoras con más años y que además tienen un mal tiempo de reacción en comparación con todas las demás.

Veámos la ponderación de las variables con el siguiente gráfico:

```{r}
fviz_pca_var(pca800libres, col.var = "red")
```

Viendo esta interpretación, podemos observar de una mejor manera, cuando un nadador va a estar más "arriba" o "abajo", si es causa de la edad o del tiempo de reacción.
Luego, si nos fijamos en las nadadoras del gráfico anterior, podremos asegurar que, Gill, tiene un tiempo de reacción pésimo, ledecky es rápida y joven y buen tiempo de reacción.
Hassler es una nadadora con más edad pero de las más rapidas pero con mal tiempo de reacción.

```{r}
#biplot(pca800libres)

fviz_pca_biplot(pca800libres, repel = TRUE)
```

```{r, echo=FALSE}
rm(pca800libres, prueba800libresPreliminar, pruebawide)
```


## Análisis de componentes principales del 100m mariposa femenino. [JAVIER]

En primer lugar, vamos a crear un nuevo dataframe llamado prueba100MariposaFem en la cuál nos quedamos con todas las pruebas de atletas femeninos, de distancia igual a 100 metros y de estilo de nado mariposa.
A continuación, nos quedamos con las columnas de lastname, reactiontime, splitdistance, splitswimtime y swimtime del dataframe prueba100MariposaFem.

```{r}
# Filtro de pruebas de 100m mariposa femenino
prueba100MariposaFem <- datos2015[datos2015$distance==100 & datos2015$gender=="F" & datos2015$stroke=="FLY" & datos2015$round =="PRE",]

# Selección de columnas relevantes
prueba100MariposaFem <- prueba100MariposaFem %>% dplyr::select(lastname, reactiontime, splitdistance, splitswimtime)
head(prueba100MariposaFem, 10)
```

A continuación, vamos a organizar los datos del dataframe *prueba100MariposaFem*.
de modo que cada nadador tiene una fila única con columnas para cada distancia.

```{r}
prueba <- prueba100MariposaFem %>%
  pivot_wider(names_from = splitdistance,       # Las diferenetes distancias se convierten en los nombres de las columnas
              values_from =splitswimtime)     #los valores de las celdas serán los tiempos de nado

#Eliminamos duplicados y NA de la columna 'lastname'
prueba <- prueba[!duplicated(prueba$lastname) & !is.na(prueba$lastname), ]

#Convertimos a data frame
prueba <- as.data.frame(prueba)

# Asignar los nombres de fila como el apellido del nadador
row.names(prueba) <- prueba$lastname

#Eliminamos filas con NA restantes
prueba <- na.omit(prueba)
head(prueba,10)
```

Con todo esto, estamos preparados para realizar el PCA.

```{r}
#Realizamos el PCA (estandarizamos los datos)
pca_100mariposafemenino <- prcomp(prueba[,-1], scale=T)
pca_100mariposafemenino

```

Observamos que la primera y segunda componente son las que tienen mayor valor de standard deviations, luego serán las más relevantes a efectos de la visualización.
Veamos la importancia relativa de cada componente

```{r}
plot(pca_100mariposafemenino)
summary(pca_100mariposafemenino)
```

El resultado del análisis de componentes principales (PCA) muestra tres componentes principales (PC1, PC2, PC3).
Veamos cada aspecto de la salida: Los datos de la fila de desivación estándar (Standard deviation), cuanto mayores sean, mas variabilidad de los datos se captura.
En este caso, la componente principal PC1 es la que tiene mayor desviación estándar, lo que sugiere que capta la mayor parte de la varianza.

En segundo lugar, la proporción de la varianza (proportion of variance) indica qué porcentaje de la varianza total de los datos está capturado por cada componente.
Aquí, PC1 captura el 74.23% de la varianza, mientras que PC2 captura el 23.28%, y PC3 solo el 2.493%.
Esto significa que PC1 es el componente más relevante para representar la estructura de los datos, mientras que PC3 aporta muy poco.
(como habiámos adelantado anteriormente)

Por último, para la variable de proporción acumulada (cumulative proportion) indica la varianza total capturada al considera las componentes en conjunto.
PC1 junto con PC2 explican el 97,51% de la variabilidad de los datos (bastante alto).
Esto sugiere que podemos reducir la dimensionalidad a estas dos primeros componentes sin perder mucha información.

El análisis PCA muestra que los datos prueba pueden ser bien representados con solo dos componentes principales (PC1 y PC2).
Este resultado implica que la mayor parte de la variabilidad de los tiempos de nado de los participantes se puede resumir en estas dos dimensiones.

Por último, dibujamos los datos proyectados sobre las dos primeras componentes

```{r}
plot(pca_100mariposafemenino$x[,1:2])
text(pca_100mariposafemenino$x[,1:2], rownames(prueba[,-1]))
biplot(pca_100mariposafemenino) 
```


```{r, echo=FALSE}
rm(pca_100mariposafemenino, prueba100MariposaFem)
```

## Análisis de componentes principales en la carrera preliminar de 1500 metros (INES)

Vamos a ver en qué estilo predominan los nadadores de 1500 metros.

```{r}
summary(nadadoresPruebas$stroke[nadadoresPruebas$distance == 1500])
summary(nadadoresPruebas$round[nadadoresPruebas$distance == 1500])
```

Como podemos observar, todos los nadadores nadan en estilo libre.
Por tanto, no seleccionaremos según esa imposición, ya que nos viene de los propios datos.
Gracias a ello, tenemos un enfoque más global de la carrera de 1500 metros.

Además, tenemos 70 participantes en rondas preliminares y 15 finales.
Por tanto, tomaremos la ronda preliminar para hacer nuestro análisis de componentes principales.

```{r}
# Filtro de pruebas de 1500m masculino
datos1500Masc <- datos2015[datos2015$distance==1500 & datos2015$gender=="M" & datos2015$round =="PRE",]

# Selección de columnas relevantes
datos1500Masc <- datos1500Masc %>% dplyr::select(lastname, reactiontime, splitdistance, splitswimtime)
head(datos1500Masc,15)
```

```{r}
prueba1500 <- datos1500Masc %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas

#Eliminamos duplicados y NA de la columna 'lastname'
prueba1500 <- prueba1500[!duplicated(prueba1500$lastname) & !is.na(prueba1500$lastname), ]

prueba1500 <- as.data.frame(prueba1500)

# Asignar los nombres de fila como el apellido del nadador
row.names(prueba1500) <- prueba1500$lastname

#Eliminamos filas con NA restantes
prueba1500 <- na.omit(prueba1500)
head(prueba1500,15)
```

Con todo esto, estamos preparados para realizar el PCA:

```{r}
#Realizamos el PCA
pca_1500masculino <- prcomp(prueba1500[,-1], scale=T)

# Resultados del PCA
summary(pca_1500masculino)

```

Por tanto, vemos el Análisis de Componentes Principales (PCA) en los datos de nadadores masculinos en la carrera de 1500 metros, excluyendo la primera variable, que es el nombre.

Observamos que el primer componente principal (PC1) tiene una desviación estándar de 5.0272 y explica el 81.52% de la varianza total.
Este componente captura la mayor parte de la variabilidad en los datos, lo que sugiere que una sola dirección en el espacio de los datos contiene gran parte de la información relevante.
Los siguientes componentes, como PC2 y PC3, explican 7.75% y 3.47% de la varianza respectivamente.
Estos valores disminuyen progresivamente, lo que indica que los componentes adicionales explican cada vez menos de la variabilidad total.
Así pues, los primeros dos componentes principales explican el 89,27% de la varianza.
Si añadimos el tercer componente, logran explicar el 92.73% de la varianza, lo que puede ser suficiente para una interpretación efectiva de los datos.

Visualizamos ahora cómo se distribuyen los datos en las dos primeras componentes principales y observamos la influencia de las variables en estas componentes.

```{r}
fviz_pca_biplot(pca_1500masculino, repel = TRUE)

```

Viendo el gráfico, podemos interpretar la primera componente como la rapidez en cada split de los participantes.
Cuantos mayores tiempos tienen en cada split, mas desplazados estarán hacia la izquierda.
Por tanto, los nadadores mas a la derecha serán aquellos con mejores resultados.
Vemos como el 81,5% de la varianza de los resultados está explicado por estos tiempos, como podría imaginarse en un principio.
Si nos enfocamos en lo que explica la componente 2, vemos que mayores tiempos de los primeros splits condicionan su desplazamiento hacia abajo, y los tiempos mayores en los ultimos splits desplazan los puntos hacia arriba.
Esto parece indicar que la componente 2 captura las diferencias entre el rendimiento en las etapas iniciales y finales de la prueba, posiblemente destacando la resistencia o la fatiga en los nadadores.
Además, es claramente visible como el tiempo del último split (cuando se completan los 1500m) es muy influyente en la posición de estos nadadores.
Es decir, los tiempos en esta última parte parecen ser muy decisivos en cuanto a su resultado final.

Si observamos la influencia del tiempo de reacción, los tiempos de reacción altos ejercen influencia a favor del eje x e y, en sus sentidos positivos.
Con lo cual, el tiempo de reacción alto parece estar asociado con un rendimiento positivo en los splits y posiblemente en la resistencia hacia el final de la prueba.

Para ver si estas cuestiones se cumplen, vamos a observar si los primeros puestos del ranking de puntos de esta categoría coincide con lo visto en el gráfico.

```{r}
# Filtro de pruebas de 1500m masculino
resumen1500 <- datos2015[datos2015$distance==1500 & datos2015$gender=="M" & datos2015$round =="PRE",]

# Selección de columnas relevantes
resumen1500 <- resumen1500 %>% dplyr::select(lastname,points) %>%
    distinct() %>%         
    arrange(desc(points))


resumen1500
```

Como podemos comprobar, Paltrinieri, Jaeger, Sun y Milne aparecen en los puntos más extremos del eje x.
Además, se localizan en la posición central, lo que parece indicar que sus tiempos son bastante estables durante todo el recorrido.
Si visualizamos los últimos nadadores, que son Arias Dourdet, Butler y Sim Wee Sheng, observamos que efectivamente están en los extremos izquierdos del eje x.
Además, Arias Dourdet y Butler están desplazados hacia el eje y, lo que parece indicar que obtuvieron tiempos más largos en sus splits finales, posiblemente debido a una falta de resistencia y mayor fatiga en estos tiempos, que es un factor crucial para el desarrollo de este tipo de pruebas.



```{r, echo=FALSE}
rm(datos1500Masc, pca_1500masculino, resumen1500)
```

# Clusters

## Cluster sobre el 800m libres femenino. Análisis de estrategias de las nadadoras. [Alonso]

Voy a crear a continuación un dataframe en el cual, contenga el nombre de las nadadoras del 800 libres femenino. Además, quiero los parciales al paso por cada 50 y el tiempo final. 

Vamos a intentar, normalizar de cierta manera los parciales respecto del tiempo final, para intentar ver estrategias de carrera en las nadadoras.
Obsérvese que, normalizamos los datos porque pueden existir dos nadadoras cuya estrategia de carrera sea la misma, pero que se encuentren muy alejadas en el cluster debido a que sus tiempos son lo suficientemente distintos.
Es por ello que normalizaremos los datos.

Empecemos creando los dataframes de manera análoga a como lo hicimos en el PCA: 

```{r, warning=FALSE}
prueba800libresPreliminar<- datos2015[datos2015$distance==800 & datos2015$gender=="F" & datos2015$stroke=="FREE" & datos2015$round=="PRE", ]

prueba800libresPreliminar <- prueba800libresPreliminar %>%
    dplyr::select(lastname, splitdistance, splitswimtime,swimtime)

free800WomensPre <- prueba800libresPreliminar %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
#omito los valores nulos: 
free800WomensPre<- na.omit(free800WomensPre)

free800WomensPre <- as.data.frame(free800WomensPre)

rownames(free800WomensPre) <- free800WomensPre$lastname
```

A continuación, vamos a echar un vistazo a lo creado:  

```{r}
head(free800WomensPre, 10)
```

Ahora, voy a normalizar los datos dividiendo cada pacial por el tiempo total, que dará una especie de "porcentaje" de cuánto tardan en cada parcial: 


```{r}
free800WomensNormalizado <- free800WomensPre %>%
  mutate(across(c(`50`, `100`, `150`, `200`, `250`, `300`, `350`, `400`, `450`, 
                  `500`, `550`, `600`, `650`, `700`, `750`, `800`), 
                ~ . / swimtime))

#free800WomensNormalizado$swimtime=NULL
free800WomensNormalizado <- as.data.frame(free800WomensNormalizado)
rownames(free800WomensNormalizado) <- free800WomensNormalizado$lastname


```


Bien, ahora, voy a tratar de hacer un cluster:

En primer lugar vamos a calcular la distancia Euclídea entre las observaciones de la base de datos.
```{r}
distance <- get_dist(free800WomensNormalizado[,-c(1,2)])

fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Esto empieza a ilustrar qué estados tienen grandes disimilitudes (rojo) frente a los que parecen ser bastante similares (verde azulado).

Veamos ahora, mediante el método de las siluetas, el número óptimo de clusters: 

```{r}
fviz_nbclust(free800WomensNormalizado[,-c(1,2)], kmeans, method = "silhouette")
```

A continuación, hacemos el cluster: 

```{r}
cluster800libres <- kmeans(free800WomensNormalizado[,-c(1,2)], centers = 3, nstart = 25)
cluster800libres
```


```{r}
fviz_cluster(cluster800libres, data = free800WomensNormalizado[,-c(1,2)])
```

Bien, ahora para poder sacar las conclusiones debidas, voy a querer graficar el dataframe, donde cada nadadora (fila), va a tener asociado un cluster. 

```{r}
free800WomensNormalizado$cluster<-cluster800libres$cluster

```

A continuación, vuelvo al formato long, para ello: 

```{r}
prueba800long <- free800WomensNormalizado %>%
  pivot_longer(cols = c("50", "100", "150", "200", "250", "300", "350", 
                         "400", "450", "500", "550", "600", "650", 
                         "700", "750", "800"), 
               names_to = "splitdistance", 
               values_to = "splitswimtime")



```

Gráfica: 

```{r}
ggplot(prueba800long, aes(x = as.numeric(splitdistance), 
                          y = splitswimtime, 
                          group = lastname, 
                          color = factor(cluster))) +
  geom_line(alpha = 0.6) +  # Agrega líneas para cada nadadora
  geom_point() +             # Agrega puntos en cada parcial
  labs(x = "Parcial (m)", 
       y = "Tiempo de Nado (segundos)", 
       color = "Cluster") +
  theme_minimal() +
  ggtitle("Tiempos de Nado por Parciales Agrupados por Cluster")
```

Parece que este gráfico no es lo suficientemente claro, voy a evaluar nadadoras por cluster de manera separada: 

```{r}
# Filtrar datos por cluster y graficar
for (i in unique(prueba800long$cluster)) {
  p <- ggplot(prueba800long[prueba800long$cluster == i, ], 
               aes(x = as.numeric(splitdistance), 
                   y = splitswimtime, 
                   group = lastname, 
                   color = factor(cluster))) +
    geom_line(alpha = 0.6) + 
    geom_point() +
    labs(x = "Parcial (m)", 
         y = "Tiempo de Nado (segundos)", 
         color = "Cluster") +
    theme_minimal() +
    ggtitle(paste("Tiempos de Nado del Cluster", i))

  print(p)  # Imprime la gráfica
}
```

Para analizar mejor las estrategias, intentamos no fijarnos en el primer y último largo, ya que corresponden para todas las nadadoras, a largos en los que van más rápido. Tras ver las tres gráficas, se ve que, las nadadoras pertenecientes al cluster 1, son nadadoras que empiezan relativamente rápido pero que con el paso de los metros, empiezan a subir de tiempos cada parcial. 

Las nadadoras del cluster 2, se aprecia que sus parciales tienen una forma de U invertida, empiezan rápido, sobre la mitad de la prueba, es donde más lento van, y luego vuelven a acelerar. 

Las nadadoras del último cluster, observamos que son nadadoras muy constantes en cuanto a los parciales. 

Vamos a evaluar estas 3 últimas gráficas graficando los centroides de cada cluster: 

```{r}
centroides <- as.data.frame(cluster800libres$centers)
centroides$cluster<- factor(rownames(centroides)) 
#Los vuelvo long: 
centroideslong <- centroides %>%
  pivot_longer(cols = c("50", "100", "150", "200", "250", "300", "350", 
                         "400", "450", "500", "550", "600", "650", 
                         "700", "750", "800"), 
               names_to = "splitdistance", 
               values_to = "splitswimtime")


# Gráfico
ggplot(centroideslong, aes(x = as.numeric(splitdistance), y = splitswimtime, color = cluster, group = cluster)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_viridis_d() +  # Colores amigables para daltónicos
  labs(x = "Split Distance (m)", y = "Split Swim Time (s)", color = "Centroide") +
  theme_minimal()

```

### Mejor cluster. 
A continuación, vamos a evaluar cuál cluster tiene las mejores nadadoras, es decir, las nadadoras que pasaron a la final: 

Vamos a ordenar el data frame *free800WomensNormalizado*: 

```{r}
free800WomensNormalizado <- free800WomensNormalizado[order(free800WomensNormalizado$swimtime), ]

finalistas<-head(free800WomensNormalizado, 8)

conteo <- table(finalistas$cluster)
conteo
```

Observamos que, hay nadadoras tanto del 3er cluster como del 1ro (5 y 3). Ahora, vamos a calcular la media de tiempos de cada cluster para ver "cuál" es el más rapido en media. 

```{r}
media_swimtime_por_cluster <- aggregate(free800WomensNormalizado$swimtime ~ free800WomensNormalizado$cluster, data = free800WomensNormalizado, FUN = mean, na.rm = TRUE)

media_swimtime_por_cluster
```


### IDEAS DE LOS PROFES
Graficar los centroides del kmeans para ver más claro cada tipo de estrategia. Además, intentar sacar conclusiones sobre los cluster, ¿cuál es el óptimo, es decir, en cuál están las mejores nadadoras?. 


Mirar las gráficas e intentar ponerlas todas en colores para personas con daltonismo. 

Poner en análisis de nacionalidades las paletas de los colores de los ¿juegos olímpicos? (son el mundial)


Sobre los test shapiro, cambiar e intentar hacer 3 cosas para ver si son normales: 

1. Probabilidad de que en mis datos, el reaction time sea mayor que 0.8?
2. Calcular la media y la desviación típica y calcular la probabilidad como una Normal. 
3. Calcular la media y la desviación típica y calcular la probabilidad simulando los datos. 




##Cluster 100 mariposa femenino [Javier]

Vamos a escalar los datos de *prueba[,-1]* (los relativos al PCA de 100 mariposa femenimo), es decir, restamos la media y dividimos por la desviación estándar, para que cada columna tenga media 0 y desviación estándar 1.

```{r}
cluster100mariposafem <- scale(prueba[,-1])
cluster100mariposafem
```

Ahora, calculamos y visualizamos la matriz de distancias entre las observaciones de *cluster100mariposafem* (REVISAR)

```{r}
#Calulamos la matriz de distancias
distancias <- get_dist(cluster100mariposafem)
#Vemos la matriz de distancias como un mapa de calor
fviz_dist(distancias, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Aquí: - low = "#00AFBB" (azul claro) representa las distancias pequeñas entre observaciones.
- mid = "white" representa las distancias medias.
- high = "#FC4E07" (rojo) representa las distancias grandes.

Aplicamos el algoritmo de las k-medias con k=2 con la función k-means, ejecutando el algoritmo 25 veces, por ejemplo

```{r}
k100Mariposafemenino <- kmeans(cluster100mariposafem, centers = 2, nstart = 25)
k100Mariposafemenino
```

La técnica aplicada genera 2 agrupaciones de 48 y 21 observaciones cada una.
Además se especifica a qué conglomerado pertenece cada asignación (por ejemplo, Borshi pertenece al la agrupación 2, Nobrega a la 2, Mckeon a la 1...)

Ahora, visualicemos los resultados con fviz_cluster

```{r}
fviz_cluster(k100Mariposafemenino, data =cluster100mariposafem)
```

Observamos gráficamente las dos agrupaciones mencionadas.

```{r}
rm(cluster100mariposafem, k100Mariposafemenino, prueba, prueba100MariposaFem, distancias)
```


## Cluster 200 mariposa masculina

```{r}
clusterprueba200 <- scale(pruebita[,-1])

summary(clusterprueba200)
```

```{r}
distancias <- get_dist(clusterprueba200)
fviz_dist(distancias, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k200 <- kmeans(clusterprueba200, centers = 2, nstart = 25)
str(k200)
```

```{r}
fviz_cluster(k200, data = clusterprueba200)
```

Como vemos, con 2 clusters nos divide a los participantes según el tiempo de reacción (vemos como el 5, que ya habiamos mencionado, aparece en los más rápidos).
Los medios, son más, y están en el rojo.

Realmente parece que dos grupos no son suficientes.
Vamos a verlo empíricamente.

```{r}
# Reproducible
set.seed(123)

fviz_nbclust(clusterprueba200, kmeans, method = "wss")
```

Parece que deberiamos aumentar el número de grupos, incluso 5 grupos.
A partir de 5 grupos, parece muy baja mejora.

Utilizamos otros métodos.
Para ello, como el de la silueta.

```{r}
fviz_nbclust(clusterprueba200, kmeans, method = "silhouette")
```

Parece que con dos grupos, podemos excluir a valores muy discriminados en nuestro estudio.
Luego, depende de si nuestro objetivo es encontrar valores peculiares.

Probamos con k=5

```{r}
k5_200 <- kmeans(clusterprueba200, centers = 5, nstart = 25)

fviz_cluster(k5_200, data = clusterprueba200)
```

El cluster 5 representa un grupo de nadadores que tienen un comportamiento peculiar en cuanto a los tiempos de reacción, y la edad no parece ser un factor determinante para ellos.

El grupo azul (cluster 4) tiene varias observaciones distribuidas más arriba a la derecha del gráfico, a lo largo de Dim1.
Estos nadadores parecen tener una mayor edad y mayor tiempo de reacción.
Esto tiene sentido, ya que el eje de Dim1 parece estar relacionado con el rendimiento en la prueba (donde mayor puntuación indicaría menor rendimiento).

Este cluster verde está ubicado hacia el centro del gráfico, alrededor del origen de los ejes de Dim1 y Dim2.
Esto sugiere que los nadadores en este grupo tienen un rendimiento promedio o neutral en las variables consideradas (edad y tiempo de reacción).

Los puntos 5 y 26 están en un cluster aislado, probablemente por tener características atípicas en cuanto a su tiempo de reacción, pero con una edad no influyente.
El cluster azul representa a nadadores mayores con tiempos de reacción más lentos, lo que afecta negativamente su rendimiento.
Los otros clusters agrupan a los nadadores con características más cercanas entre sí en cuanto a edad y tiempos de reacción.

## Cluster divisivo 200

```{r}
# Clustering jerárquico divisivo
hc200 <- diana(clusterprueba200)

# Coeficiente de división; cantidad de estructura de agrupación encontrada
hc200$dc
```

Podemos proceder a realizar el dendograma(cercano a 1).

```{r}
# Drendrograma
pltree(hc200, cex = 0.6, hang = -1, main = "Dendrogram de DIANA")
```

Utilizamos k=5

```{r}
# Método de Ward
# Matriz de disimilaridades
d200 <- dist(clusterprueba200, method = "euclidean")
hc5_200 <- hclust(d200, method = "ward.D2" )

# Cortamos en 4 clusters
sub_grp <- cutree(hc5_200, k = 5)

# Visualizamos el corte en el dendrograma
plot(hc5_200, cex = 0.6)
rect.hclust(hc5_200, k = 5, border = 2:5)
```

Veamos si coincide con los clusters anteriores

```{r}
# Visualización
#Cluster realizado con el método de división
fviz_cluster(list(data=clusterprueba200,cluster=sub_grp))

#Cluster realizado con kmeans
fviz_cluster(k5_200, data = clusterprueba200)
```

Vemos que coinciden.

## Cluster para la prueba de 1500 masculina

```{r}
# escalado de todas las variables
clusterprueba1500 <- scale(prueba1500[,-1])

summary(clusterprueba1500)
```

```{r}
distance <- get_dist(clusterprueba1500)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k2 <- kmeans(clusterprueba1500, centers = 2, nstart = 25)
str(k2)
```

```{r}
fviz_cluster(k2, data = clusterprueba1500)
```

Como vemos, con 2 clusters nos divide a los participantes según la velocidad.
Es decir, los que pertenecen al cluster rojo serían los de tiempos más altos, y los azules los que están en mejores posiciones de resultados.

Nos preguntamos, si el número óptimo de clústeres para dividir a nuestro grupo total es realmente 2, o podemos dividirlos en más grupos.
Para ello, utilizamos el método del codo.

```{r}
# Reproducible
set.seed(123)

fviz_nbclust(clusterprueba1500, kmeans, method = "wss")
```

Parece que sí que tenemos una mejoría si continuamos diviendo nuestro grupo en 3 o incluso 4.
Por encima de estos números, no obtenemos grandes mejoras en nuestro análisis.

Por tanto, probamos con k=3 y k=4 y observamos los resultados

```{r}
k3 <- kmeans(clusterprueba1500, centers = 3, nstart = 25)

fviz_cluster(k3, data = clusterprueba1500)
```

```{r}
k4 <- kmeans(clusterprueba1500, centers = 4, nstart = 25)

fviz_cluster(k4, data = clusterprueba1500)
```

Como podemos observar en ambos gráficos, la segregación de nadadores sigue estando bastante influida por su posición relativa al eje x.
Es decir, nos clasifica los grupos según sus velocidades.
Con 3 clústeres, tendríamos los nadadores lentos, los intermedios, y los muy rápidos.
En el segundo gráfico con 4 clusteres, podemos observar los grupos muy lentos (prácticamente valores outiers), los centrales divididos en mas y menos lentos y un último grupo, de competidores de alta calificación.
Observando ambos, los dos grupos de la derecha contienen prácticamente los mismos puntos.
Sin embargo,si que existe una división entre los puntos de la izquierda.
La elección de k=3 o k=4 vendrá por el interés del estudio que queramos realizar.
Si no nos interesan los nadadores de peor cualificación, no será necesario segregar a los nadadores en 4 grupos.
Sin embargo, si queremos analizar estos nadadores con peores marcas parece interesante ajustarnos a un nivel de k=4.

Utilizamos otros métodos para decidir si nuestro razonamiento es correcto.
Para ello, utilizamos el método de "silueta" y el método "GAP".

```{r}
fviz_nbclust(clusterprueba1500, kmeans, method = "silhouette")
```

```{r}
set.seed(123)
gap_stat <- clusGap(clusterprueba1500, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)

print(gap_stat, method = "firstmax")
fviz_gap_stat(gap_stat)
```

Utilizando estos dos últimos métodos, nos dan el resultado de que el número óptimo de clústers son dos en "silueta" y uno en "Gap".
Puesto que cada método nos determina un número distinto de k, utilizaremos la división en grupos según el objetivo a tratar, como hemos comentado recientemente.

##Cluster jerarquico prueba de 1500 metros masculina

### Cluster aglomerativo. AGNES.

Queremos hacer un cluster jerárquico de nuestra prueba.
Para ello, calculamos el valor del coeficiente aglomerativo

```{r}
# Clustering jerárquico usando enlace completo
hc2 <- agnes(clusterprueba1500, method = "complete" )

hc2$ac
```

El coeficiente aglomerativo tiene un valor cercano al 1, con lo que sugiere una fuerte estructura de agrupamiento.
Vamos ahora a evaluar qué metodo nos da un coeficiente mayor y emplearemos esa estructura de agrupacion con el objetivo de conseguir una estructura de agrupación más fuerte.

```{r}
# Métodos evaluados
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# Función para calcular el coeficiente de agrupamiento
ac <- function(x) {
  agnes(clusterprueba1500, method = x)$ac
}

map_dbl(m, ac)
```

Como vemos, lo conseguimos con el método ward.
Por tanto, utilizamos ese método para realizar el dendrograma

```{r}
# Matriz de disimilaridades
d <- dist(clusterprueba1500, method = "euclidean")

# Clustering jerárquico usando enlace completo
hc1 <- hclust(d, method = "ward" )

# Dendrograma
plot(hc1, cex = 0.6, hang = -1)
```

Interpretando el dendrograma, vemos como los primeros pasos de agrupamiento son entre distintas muy pequeñas.
Por tanto, no tiene sentido cortar en esas etapas iniciales.
El gráfico parece sugerir la aglomeración en 3 grupos.

##Cluster divisivo. DIANA.

Calculamos ahora el coeficiente de división.

```{r}
# Clustering jerárquico divisivo
hc4 <- diana(clusterprueba1500)

# Coeficiente de división; cantidad de estructura de agrupación encontrada
hc4$dc
```

Como podemos ver, tenemos un coeficiente de división cercano al 1.
Con lo cual, podemos proceder a realizar el dendograma.

```{r}

# Drendrograma
pltree(hc4, cex = 0.6, hang = -1, main = "Dendrogram de DIANA")
```

Utilizamos ahora la función "cutree" para dividir nuestro dendrograma en los clústers que consideremos.
En este caso, utilizamos k=4

```{r}
# Método de Ward
hc5 <- hclust(d, method = "ward.D2" )

# Cortamos en 4 clusters
sub_grp <- cutree(hc5, k = 4)

# Visualizamos el corte en el dendrograma
plot(hc5, cex = 0.6)
rect.hclust(hc5, k = 4, border = 2:5)
```

Veamos si coincide con los clusters que hemos considerado en el apartado previo

```{r}
# Visualización
#Cluster realizado con el método de división
fviz_cluster(list(data=clusterprueba1500,cluster=sub_grp))

#Cluster realizado con kmeans
fviz_cluster(k4, data = clusterprueba1500)
```

Como vemos, las divisiones son similares, pero no son iguales.
Esto se debe al método de agregación que difiere en ambos casos.

A su vez, comparamos si los dendrogramas utilizados para agregar o dividir son isomorfos.

```{r}

# Matriz de distancias
res.dist <- dist(clusterprueba1500, method = "euclidean")

# Calcuamos los dos clustering jerárquicos
hc1 <- hclust(res.dist, method = "ward")
hc2 <- hclust(res.dist, method = "ward.D2")

# Dendrogramas
dend1 <- as.dendrogram (hc1)
dend2 <- as.dendrogram (hc2)

# los enfrentamos
tanglegram(dend1, dend2)
```

Como podemos observar, no nos dan dendrogramas isomorfos puesto que los dos métodos manejan de manera diferente las distancias entre grupos durante el proceso de fusión.

```{r, warning=FALSE}
rm(clusterprueba1500, clusterprueba200, datos1500Masc, dend1, dend2, hc1, hc2, hc200, hc4, hc5, hc5_200, k2, k200, k3, k4, k5_200, pca_1500masculino, prueba1500, prueba200MariposaMasc, pruebita, d, d200, distance, distancias, ac, sub_grp, res.dist, m)
```


```{r, warning=FALSE}
rm(centroides, centroideslong, cluster800libres, componentess, finalistas, free800WomensNormalizado, free800WomensPre, gap_stat, media_swimtime_por_cluster, auto, conteo, p, prueba200MariposaMasc2, prueba800libresPreliminar, prueba800long, R, i, Cor_CompVar, Cor_CompVar_retenidos)
```




# Medidas de rendimiento.


```{r carga de los datos}
#Voy a cargar aquí los datos para no tener que ejecutar todos los chunks anteriores:

datos2015<-read.csv("datos/2015_FINA.csv", header=TRUE, sep = ',')

datos2015<- datos2015 %>% convert_as_factor(gender,name,code,round,heat,lane,stroke, relaycount)

datos2015$relaycount <- NULL

datos2015<-datos2015 %>%
  filter(!(is.na(datos2015$points) & is.na(datos2015$reactiontime) & is.na(datos2015$swimtime) & is.na(datos2015$cumswimtime) & is.na(datos2015$splitswimtime)))


datos2015$birthdate <- as.Date(datos2015$birthdate)
#Calculamos la edad
fechaKazan<- as.Date("2015-07-24")
datos2015$edad <- as.numeric(difftime(fechaKazan, datos2015$birthdate, units = "weeks")) %/% 52  # Convertir de semanas a años

nadadoresParticipantes <- datos2015 %>%
  distinct(athleteid, .keep_all = TRUE)

#guardamos una copia de seguridad por si se modifica el dataframe más adelante. 

nadadoresParticipantesCopia<-nadadoresParticipantes


nadadoresPruebas <- datos2015 %>%
  distinct(eventid, athleteid, .keep_all = TRUE)


#Copia de seguridad: 
nadadoresPruebasCopia<-nadadoresPruebas


```


A partir de este momento, vamos a estudiar acerca de un target. En este caso, nuestro target, ver si los finalistas van a mejorar su tiempo respecto a la ronda anteriormente nadada. Por lo que, vamos a quedarnos con el conjunto de nadadores que están clasificados a la final de cada prueba, y su tiempo en la ronda anterior. Para ello, voy a ir dividiendo los datos por cada distancia. Elegiré los nadadores que nadaron la final y la semifinal. Pero filtrando los semifinalistas 


```{r}
#Me quedo con los finalistas de las pruebas de 50, 100 y 200:
finalistas1<-datos2015[datos2015$round=="FIN" & datos2015$distance %in% c(50,100,200),]

condicionFiltro<-unique(finalistas1[,c("athleteid", "distance", "stroke")])

#Me quedo con los semifinalistas de las pruebas de 50, 100 y 200: 
semifinalistas1<-datos2015[datos2015$round=="SEM" & datos2015$distance %in% c(50,100,200),]

#Ahora, los filtro para que cumplan esa condición de Filtro.
semifinalistasFiltrados <- merge(semifinalistas1, condicionFiltro, by = c("athleteid", "distance", "stroke"))

#Ahora, hago la unión.

dataframe1 <- rbind(finalistas1, semifinalistasFiltrados)


#Ahora, hago el mismo proceso para las pruebas de 400, 800 y 1500 pero con las finales y preliminares: 

finalistas2<-datos2015[datos2015$round=="FIN" & datos2015$distance %in% c(400,800,1500),]
condicionFiltro<-unique(finalistas2[,c("athleteid", "distance", "stroke")])

semifinalistas2<-datos2015[datos2015$round=="PRE" & datos2015$distance %in% c(400,800,1500),]

#Ahora, los filtro para que cumplan esa condición de Filtro.
semifinalistasFiltrados2 <- merge(semifinalistas2, condicionFiltro, by = c("athleteid", "distance", "stroke"))

#Ahora, hago la unión.

dataframe2 <- rbind(finalistas2, semifinalistasFiltrados2)


#Ahora, hago la unión de mis datos: 

datos2015Target<-rbind(dataframe1, dataframe2)


#Los voy a ordenar por prueba y nombre. 

datos2015Target<-datos2015Target[order(datos2015Target$stroke, datos2015Target$athleteid, datos2015Target$distance), ]


rownames(datos2015Target)<-NULL

```


```{r}
rm(condicionFiltro, dataframe1, dataframe2, finalistas1, finalistas2, semifinalistas1, semifinalistas2, semifinalistasFiltrados, semifinalistasFiltrados2)
```


Vamos a calcular la media, desviación típica, mínimo y máximo de cada parcial: 

```{r}
#hacemos un long to wide. ¿Por cada prueba?

datos2015Target$split<-NULL
datos2015Target$cumswimtime<-NULL

datos2015TargetLong <- datos2015Target %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas

#Una vez hecho, vamos a calcular la media, desviación típica, mínimo y máximo de cada parcial.


datos2015TargetLong$mediaParciales<- rowMeans(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], na.rm=TRUE)

datos2015TargetLong$minimoParciales<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, min, na.rm=TRUE)

datos2015TargetLong$maximoParciales<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, max, na.rm=TRUE)


datos2015TargetLong$sdParcial<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, sd, na.rm=TRUE)

datos2015TargetLong$medianaParciales<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, median, na.rm=TRUE)

datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")]<-NULL


View(datos2015TargetLong)







```





## Partición de los datos. 

La repartición de nuestros datos, será sobre las finales. En total, tengo 8 nadadores por cada final, 2 sexos. En las pruebas de 50 y 100 tengo 4 estilos, lo que suma 128 nadadores. También, tengo en las pruebas de 200, 8 nadadores, 2 sexos y 5 estilos, lo que suma 80. En el 400 tengo 8 nadadores, 2 sexos y 2 estilos, lo que suma 32 nadadores. En el 800 y 1500 tengo 8 nadadores por cada sexo, lo que hace un total de 32 nadadores.

La suma total es de 272 nadadores, aunque debemos tener en cuenta que hubo una baja en la final del 1500 masculino, luego será de 271 nadadores. 


Vamos a ver si estas cuentas son ciertas de la siguiente manera: 

```{r}
nadadoresFinalistas<-nadadoresPruebas[nadadoresPruebas$round=="FIN", ]
rownames(nadadoresFinalistas) <- 1:nrow(nadadoresFinalistas)

```

```{r}
dim(nadadoresFinalistas)
```

Luego, observamos que sí, estamos en lo cierto. Ahora, voy a hacer la repartición de mis datos sobre este dataframe: 


```{r}
n=nrow(nadadoresFinalistas)
set.seed(1312)
indices_validation= sample(1:n, n*0.1)
indices_entrenamiento= c(1:n)[-indices_validation]

#he dividido los datos, ahora, cojo los de entreno y divido otra vez. 
n_entrenamiento=length(indices_entrenamiento)
set.seed(2910)
indices_train=sample(indices_entrenamiento, 0.8*n_entrenamiento)
indices_test=c(1:n)[-c(indices_validation, indices_train)]


nadadoresFinalistas_train=nadadoresFinalistas[indices_train,]
nadadoresFinalistas_test= nadadoresFinalistas[indices_test, ]
nadadoresFinalistas_validation=nadadoresFinalistas[indices_validation, ]

```

Ahora, tenemos los nadadores sobre los qiue vamos a trabajar, 271 (aunque puede haber un mismo nadador que nade varias finales). Ahora, debemos crear de alguna forma los dataframes que queremos usar: 

```{r}
#aquí me quedo.
```

