---
title: "Mundial de natación de Kazán 2015"
author: "Inés Molinero, Javier Villanueva, Salma Ghailan, Alonso González"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    toc: yes
    toc_float:
      collapsed: true
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#Configuro para que no salten warnings en ningún trozo de código.
knitr::opts_chunk$set(warning = FALSE)
# Cargamos las librerias que vamos necesitando a lo largo del codigo
library(randomForest)
library(ipred)
library(rpart)
library(rpart.plot)
library(caret)
library(pastecs)
library(factoextra)
library(dplyr)
library(MASS)
library(rstatix)
library(ggplot2)
library(tidyr)
library(ggimage)
library(countrycode)
library(ggExtra)
library(cluster)
library(purrr)
library(dendextend)
library(RColorBrewer)
library(knitr)
library(FSA)
library(tidyverse)
library(viridis) # Para una paleta amigable para daltónicos
library(e1071)
library(cluster)  
library(class)    
library(caret)  
library(FNN)
library(StatMatch)
library(proxy)
library(counterfactuals)
library(iml)
library(GGally)
library(pROC)

```

# Introducción.

En este proyecto, se analizarán los resultados del **mundial de natación de 2015** con el objetivo de identificar patrones en el desempeño de los nadadores por país y eventos.
Se realizará un análisis exploratorio de datos y se utilizarán técnicas de reducción de dimensionalidad, aprendizaje no supervisado, aprendizaje supervisado, medidas de rendimiento, comparación de modelos y técnicas de Aprendizaje Máquina Explicable.

En primer lugar, veamos con qué datos vamos a tratar.
El conjunto de datos consiste en los resultados del Campeonato Mundial de Natación Kazán del año 2015, con los correspondientes datos de cada nadador y prueba.
Los datos han sido extraídos de [Omega](http://www.omegatiming.com/File/Download?id=00010F0200FFFFFFFFFFFFFFFFFFFF08), la plataforma oficial de tiempos de la World Aquatics.
El conjunto de datos contiene información sobre los nadadores (fecha de nacimiento, país, id), y sobre la prueba nadada (tiempo de reacción, parciales, tiempo total, estilo, serie).

Las variables o atributos que conforman el conjunto de datos son:

-   athleteid: id del nadador
-   lastname: Apellidos del nadador
-   firstname: El nombre del nadador
-   birthdate: Fecha de nacimiento del nadador
-   gender: Género del nadador/a
-   name: Nombre del país
-   code: abreviatura del país.
-   eventid: id de la prueba nadada (único)
-   heat: Serie en la que nadaron
-   lane: Calle en la que nadaron (0 a 9)
-   points: puntos FINA que realizaron. (es una "estimación" entre el mejor tiempo o récord del mundo, y el tiempo realizado. )
-   reactiontime: Tiempo de reacción en la salida.
-   swimtime: tiempo tardado
-   split: Parcial
-   cumswimtime: Tiempo acumulado en el parcial
-   splitdistance: Distancia del parcial
-   daytime: hora a la que se nadó
-   round: ronda (preliminar, semifinal, final)
-   distance: distancia de la prueba
-   relaycount: Número de relevista.
-   stroke: Estilo de nado en el que se realizó la prueba.
-   splitswimtime: Tiempo del parcial (50m)

# Entender los datos.

Primeramente, vamos a leer los datos:

```{r}
datos2015<-read.csv("datos/2015_FINA.csv", header=TRUE, sep = ',')
```

Una vez nuestro programa los ha leído, vamos a averiguar el tamaño de los datos con los que vamos a tratar:

```{r}
dim(datos2015)
```

Las dimensiones del dataframe son 11423 filas y 22 variables o columnas.

Veamos la primera ocurrencia:

```{r}
head(datos2015,1)
```

Observamos Noel Borshi, nadadora albanesa nacida un 13 de febrero de 1996, que tiene como id el número (100784).
Noel Borshi nadó la prueba 1 en la serie 1 y carril 4.
Nadó el 100m Mariposa en la ronda preliminar con un tiempo final de 63.65 segundos y pasó por el primer parcial (50m) en 29.63 segundos.

# Análisis exploratorio de datos.

## Resumen de los datos.

A continuación, vamos a ver un resumen de los datos:

```{r}
summary(datos2015)
```

De aquí, podemos observar que tenemos algunos valores nulos (NA's), durante toda la competición, que como máximo hubo 12 series y como mínimo 1 y que la piscina disponía de 10 carriles numerados del 0 al 9.
También observamos que se nadaron pruebas de 50 y hasta 1500 metros.

Tenemos variables categóricas las cuales se han tratado como continuas de partida.
Por lo cual, usando la librería "dyplr", vamos a convertirlas a variables categóricas en R para tener una mejor visualización de ellas.

```{r}
datos2015<- datos2015 %>% convert_as_factor(gender,name,code,round,heat,lane,stroke, relaycount)

```

Visualicemos ahora de nuevo el resumen:

```{r}
summary(datos2015)
```

Viendo este resumen de los datos podemos comenzar a entender algunas de las variables.

Observamos que las variables name y code toman absolutamente los mismos valores.
Se trata del país de procedencia de cada nadador.

Vemos que hay 5 ***tipos de nado***: braza, mariposa, crol, espalda y estilos individual.

No hemos guardado la distancia como una variable categórica, pero más adelante veremos que hay 6 distancias (50, 100, 200, 400, 800, 1500).
Hay 5 tipos de ronda distintos.

El menor tiempo de reacción fue de 0.42 y el mayor de 0.97.

Viendo los datos, observamos que cada nadador tiene en una prueba concreta, tantas filas como parciales tenía en esa prueba, luego es obvio que para conocer mejor algunas variables, vamos a necesitar limpiar los datos para que los elementos repetidos no causen interferencia en nuestros datos.

A continuación, vamos a ir realizando estudios para tratar de comprender más a fondo algunas variables.

## Variable Relaycount.

Si observamos el resumen de la variable relaycount:

```{r}
summary(datos2015$relaycount)
```

Observamos que sólo toma un único valor, 1.
Esto se debe principalmente a que nuestro conjunto de datos consta de las pruebas individuales del mundial de Kazán 2015, luego como no hay relevos, todos los nadadores son el primer "relevista" en su prueba.

Luego, la eliminamos:

```{r}
datos2015$relaycount <- NULL
```

Luego ahora, tenemos 21 variables en vez de 22.

## Valores NA. Datos faltantes.

Si volvemos a mirar nuestro resumen, observamos que hay valores faltantes.
Vamos a tratar de identificarlos, intentar entender el por qué de esos datos faltantes, y razonar cuándo será conveniente eliminarlos o no de nuestro estudio.

Para ello, vamos a obtener primeramente un resumen de cuántos datos faltantes hay:

```{r}
print(sum(is.na(datos2015)))
```

Observamos que hay 309 valores faltantes.

Vamos a crear una dataframe donde se nos muestren dónde se encuentran los valores faltantes:

```{r}
datosNA <- datos2015[rowSums(is.na(datos2015)) > 0, ]
dim(datosNA)

```

Observamos que, de 11429 observaciones de mi dataframe original, en 73 de ellas, existe algún valor nulo.
Es decir, un 0.63 % por ciento.
Lo cual es un valor muy bajo.

En principio y sin estudiar nada más, podríamos considerar eliminar las filas que contengan datos faltantes ya que toman un valor muy pequeño con respecto al total.
Aún así, vamos a ver dónde se suelen tomar más valores nulos e intentar explicar el por qué.
Hacemos una dataframe adicional con los valores nulos de cada variable en porcentaje:

```{r}
percent_na <- colSums(is.na(datosNA)) / nrow(datosNA) * 100
percent_na

```

Observamos de manera bastante clara que los datos nulos tienen mucho que ver con el tiempo acumulado, los puntos finales, el tiempo de reacción, el tiempo final y el tiempo al paso por el parcial.

A continuación, vamos a intentar clasificar los nulos dependiendo qué falta:

### Valores nulos en los que faltan todas las variables.

Visualicemos los datos donde faltan todas las variables dichas anteriormente:

```{r}
todosNA<-datosNA[is.na(datosNA$points) & is.na(datosNA$reactiontime) & is.na(datosNA$swimtime) & is.na(datosNA$cumswimtime) & is.na(datosNA$splitswimtime), ]

dim(todosNA)
```

Bien, en 59 de las 73 observaciones, faltan, tanto el tiempo de reacción, los puntos finales, el tiempo final, los parciales acumulados...
Es decir, nadadores que posiblemente se dieron de baja en la prueba.

```{r}
summary(todosNA)
```

```{r}
todosNA[todosNA$round=="FIN",]
```

La mayoría de nadadores causaron baja en la ronda preliminar, pero hay uno, el nadador chino Sun Yang, que causó baja en la final del 1500m libres masculino.

Haciendo una pequeña búsqueda en los resultados de la World Aquatics de los mundiales de 2015, observamos que Sun Yang produjo DNS (Did not Start).

```{r}
todosNA[todosNA$firstname=="CESAR",]
```

También, buscando a César Cielo en el 50 libres de las preliminares, observamos que causó baja DNS.
Para ponernos en contexto, Cesar Cielo es a dia de hoy, el poseedor del récord mundial del 50 libres, luego también resultaba raro que causase baja.

Luego todo parece indicar que estos nadadores fueron baja en esa prueba y por ello no sale ningún dato en esas variables.
Vamos a optar por eliminarlos.

```{r}
#Primero datosNA: 
datosNA <- datosNA %>%
  filter(!(is.na(datosNA$points) & is.na(datosNA$reactiontime) & is.na(datosNA$swimtime) & is.na(datosNA$cumswimtime) & is.na(datosNA$splitswimtime)))

#Ahora, los eliminamos de datos2015: 
datos2015<-datos2015 %>%
  filter(!(is.na(datos2015$points) & is.na(datos2015$reactiontime) & is.na(datos2015$swimtime) & is.na(datos2015$cumswimtime) & is.na(datos2015$splitswimtime)))

```

Bien, ahora, tenemos solamente datos en los que falta alguna de las variables.
Analizamos nuevamente para poder reclasificarlos:

```{r}
datosNA
```

Nos quedan solamente 14 filas en los que hay datos nulos.

Si seguimos con nuestra limpieza:

### Valores nulos donde faltan los puntos:

Veamos qué sucede si sólo faltan los puntos:

```{r}
naReactionTime<-datosNA[is.na(datosNA$points),]
naReactionTime
```

Vamos a buscar los resultados de World Aquatics de alguno de ellos, para estimar qué esta sucediendo.
¿Fueron descalificados?.

Nuestro nadador de la primera fila, Ben Treffers, fue descalificado.
Buscamos también a Vladimir Morozov, y también fue descalificado.
Luego, son participantes que nadaron pero quedaron descalificados.
Por tanto, sus datos nos servirán para hacer estudios sobre participación, pero no para cualquier estudio que involucre los resultados.
Luego estos, no los eliminamos del dataframe inicial.

```{r}
datosNA <- datosNA %>%
  filter(!(is.na(datosNA$points)))
```

Me quedan las dos ultimas observaciones por ver:

```{r}
datosNA
```

Tenemos dos observaciones en las cuales no existe el tiempo de reacción.
Seguramente se deba a algún fallo en el sistema electrónico o algún fallo al pasar los datos.
Por lo tanto, al igual que con los anteriores, no lo eliminaremos de nuestro dataframe inicial, pero sí lo tendremos en cuenta cuando tengamos que analizar estudios que tengan que ver con el tiempo de reacción.

```{r}
print(sum(is.na(datos2015)))
```

Luego, de 309 iniciales, vamos a tratar ahora con 14 datos nulos ya controlados.

```{r, echo=FALSE}
#Elimino las cosas creadas para no sobrecargar. Ya que no las vamos a volver a usar.
rm(datosNA, naReactionTime, todosNA, percent_na)
```

## Variable birthdate. Creacion de nueva variable edad

A continuación, vamos a crear una variable llamada *edad*, ya que será más representativo que trabajar con la variable birthdate.
La variable tendrá el valor numérico de la edad de cada participante en el momento del mundial.
Es decir, el 24 de Julio de 2015.

```{r}
datos2015$birthdate <- as.Date(datos2015$birthdate)
#Calculamos la edad
fechaKazan<- as.Date("2015-07-24")
datos2015$edad <- as.numeric(difftime(fechaKazan, datos2015$birthdate, units = "weeks")) %/% 52  # Convertir de semanas a años
```

Además, borramos la variable birthdate:

```{r}
datos2015$birthdate=NULL
```

## Dataframes.

Si visualizamos el dataframe datos2015, observamos por cada prueba de cada nadador, salen n filas que equivalen a los n parciales (de 50m ) en los que constaba la prueba.
Luego, para algunos estudios, usar este dataframe va a suponer duplicar, triplicar e incluso multiplicar por 15 un mismo valor (en el caso de las carreras de 1500m).
Además, no estaríamos haciendo un análisis correcto, puesto que los resultados estarían claramente sesgados hacia los de las distancias más largas.
Por ejemplo, en el caso del tiempo de reacción, los tiempos de los nadadores de 1500 metros se contabilizarían 15 veces.
Mientras que en los nadadores de 50 metros sólo una vez.

A continuación, procedemos a presentar los dataframes que vamos a utilizar dependiendo lo que queramos estudiar:

### Dataframe nadadoresParticipantes.

Utilizaremos este dataframe para realizar análisis sobre el número de nadadores, proporción entre hombres y mujeres, la edad de los participantes, etc.
Es decir, análisis sobre datos que no requieren el conocimiento de la progresión en sus splits.
Para ello, nos bastará con tener la primera fila de cada participante.

Creamos, por tanto, un nuevo dataframe, llamado *nadadoresParticipantes*, el cual constará de todos los participantes sin repetir.
Nos basaremos en la unicidad de la variable athleteid para crearla.

```{r}
nadadoresParticipantes <- datos2015 %>%
  distinct(athleteid, .keep_all = TRUE)

#guardamos una copia de seguridad por si se modifica el dataframe más adelante. 

nadadoresParticipantesCopia<-nadadoresParticipantes
```

```{r}
summary(nadadoresParticipantes)

```

### Dataframe nadadoresPruebas.

Para poder elaborar un estudio de algunas variables como *events*, *reactiontime*, *lane*, *heats* y *daytime*,entre otras cosas, vamos a necesitar un dataframe que refleje a cada nadador y sus pruebas nadadas por filas.

Para poder realizar el dataframe, primero hay que saber si cada prueba, dentro de cada tipo de prueba (preliminar, final, semifinal), tiene un id distinto.

Lo evaluamos seleccionando algún nadador que haya nadado en varias rondas:

```{r}
ejemplo<-datos2015[datos2015$distance == 100 & datos2015$stroke=="BACK" & datos2015$code=="AUS", ]
head(ejemplo,6)
```

Bien, vemos que el australiano nadó tanto las preliminares, como las semifinales como la final y el eventid era distinto entre rondas pero es el mismo en la misma prueba.

```{r, echo=FALSE}
rm(ejemplo)
```

Creamos el siguiente dataframe:

```{r}
nadadoresPruebas <- datos2015 %>%
  distinct(eventid, athleteid, .keep_all = TRUE)

head(nadadoresPruebas,6)

#Copia de seguridad: 
nadadoresPruebasCopia<-nadadoresPruebas
```

Los datos creados, reflejan nadadores y pruebas nadadas por cada uno.

## Estudio sobre el número de nadadores, su género, país y edad.

Usaremos el dataframe nadadoresParticipantes.

Ahora, comenzamos nuestro estudio:

### Edad.

Veamos primeramente un resumen de la edad:

```{r}
summary(nadadoresParticipantes$edad)
```

Observamos que la edad máxima fue de 38 años, la media fue de 21.32 años, y el participante con menos edad fue de 10 años.
Además, el 50% de los participantes estaban entre 19 y 24 años de edad.

Una pregunta razonable sería: ¿El dato relativo al participante de 10 años es un error?

Procedemos a contrastar la información.
De esta forma, podemos ver si de verdad existe este atleta o es un dato mal tomado de nuestra base de datos.
Confirmamos la información, entre otras fuentes, con esta noticia, de la cual añadimos el enlace sobre la joven nadadora de 10 años.
[noticia](https://www.rtve.es/deportes/20150807/nina-10-anos-alzain-tareq-asombra-a-natacion-mundial/1195782.shtml#:~:text=Se%20llama%20Alzain%20Tareq%2C%20tiene,estrella%20medi%C3%A1tica%20de%20la%20jornada.)

Confirmamos mediante su nombre, apellidos y edad, que la noticia se refiere a los datos que tenemos.

```{r}
datos2015[datos2015$edad == 10, ]
```

Se trata de una nadadora de Bahrain que nadó el 50 mariposa y el 50 libres.
Luego podemos concluir que es un dato atípico pero no es erróneo.

De acuerdo con esta nueva variable, vemos cómo se distribuyen las edades.

```{r}
ggplot(nadadoresParticipantes, aes(x = edad)) +
  geom_density(fill = "#0072B2", color = "#0072B2") + # Azul accesible para daltónicos
  ggtitle("Distribución. Edades.")
```

La mayoría de los nadadores parecen tener entre 15 y 25 años, con un pico alrededor de los 20 años.

Esto sugiere que los participantes en la competición están en su mayoría en la etapa juvenil o temprana adultez.

Podríamos preguntarnos si la edad sigue una distribución normal en estos datos, para ello, hacemos uso del test shapiro:

```{r}
shapiro.test(nadadoresParticipantes$edad)
```

El test de shapiro, a priori, nos indica que deberíamos rechazar la hipótesis nula y suponer que no es una normal, aún así, vamos a evaluar de una manera práctica, si podemos suponer su normalidad.
Vamos a realizar 3 evaluaciones para ver si podemos suponer que nuestros datos son normales:

#### Probabilidad de que un nadador tenga más de 29 años:

Para calcular la probabilidad de que un nadador tenga más de 29 años, cuento todos los nadadores que tienen más de 30, y divido sobre el número total de participantes.

```{r}
valor1<- sum(nadadoresParticipantes$edad >=29)/1099
```

#### Calcular media y varianza y calcular la probabilidad Normal.

```{r}
media<-mean(nadadoresParticipantes$edad)
desviacion<-sd(nadadoresParticipantes$edad)

valor2<-1 - pnorm(29, media, sd=desviacion)
```

#### Simular datos de una normal sabiendo media y varianza.

Ahora, simulo datos:

```{r}
datos_simulados <- rnorm(1100, mean = media, sd = desviacion)
## Calculo la probabilidad de 29 o más: 

conteo_mayores_que_29 <- sum(datos_simulados >= 29)

valor3<- conteo_mayores_que_29/1100
```

A continuación, comparo los tres valores obtenidos:

```{r}
valor1
valor2
valor3
```

Y veo que es una diferencia de 0.017 entre el mayor y el menor valor, luego, vamos a suponer la normalidad de nuestros datos.

```{r}
rm(conteo_mayores_que_29, datos_simulados, desviacion, media, valor1, valor2, valor3)
```

Observo que hay una variación de 0.014 entre las probabilidades, al ser una probabilidad tan baja, podríamos asumir normalidad en nuestros datos.

### Análisis de géneros participantes

Veamos el número exacto de mujeres y hombres en la competición:

```{r}
summary(nadadoresParticipantes$gender)
```

Luego, hay 608 hombres y 491 mujeres que participaron en los mundiales de Kazán 2015.

Veamos ahora cómo se distribuyen los hombres y las mujeres y sus respectivas edades:

```{r, warning=FALSE}
ggplot(nadadoresParticipantes, aes(x = edad, colour = gender, linetype = gender)) +
    geom_density(size = 1.2) +  # Aumentar el grosor de las líneas
    scale_color_viridis_d(option = "D", begin = 0.2, end = 0.8) +  # Colores accesibles para daltonismo
    scale_linetype_manual(values = c("solid", "dashed")) +  # Líneas sólidas y punteadas
    theme_minimal() +  # Tema limpio y claro
    labs(
        title = "Densidades de Edad por Género",
        x = "Edad",
        y = "Densidad",
        colour = "Género",
        linetype = "Género"
    )
```

Según observamos, la distribución está ligeramente desplazada a la derecha para los hombres, esto indica que los hombres tienden a ser mayores en promedio que las mujeres.
Esta diferencia en la distribución de edades entre los géneros nos conduce a realizar distintos test estadísticos para confirmar si la diferencia realmente es significativa.

#### Hipótesis:

-   H0: Las medias de los dos grupos son iguales.

-   H1: Las medias de los dos grupos son distintas.

```{r}
t.test(edad~gender,data=nadadoresParticipantes)

```

Hemos comparado las medias de edad entre mujeres (grupo F) y hombres (grupo M), tomando como hipótesis nula que las medias de edad entre mujeres y hombres son iguales, y cómo hipótesis alternativa que las medias de edad entre mujeres y hombres son diferentes.
Aunque el resultado del t-test muestra que hay una diferencia estadísticamente significativa (el p-valor es muy pequeño) entre las edades medias de hombres y mujeres (aproximadamente 1.16 años), en términos prácticos, esta diferencia es relativamente pequeña.
En este caso, puede no ser relevante en términos de la experiencia o desempeño de los nadadores.

No obstante, proseguimos en nuestro análisis exploratorio.

```{r}
tabla1<-table(nadadoresParticipantes$edad>30,nadadoresParticipantes$gender)
chisq.test(tabla1)
```

Por el resultado del siguiente test aplicado, podemos concluir con que **no hay asociación significativa**: Dado que el p-valor es 0.47, entre ser mayor de 30 años y el género de los nadadores en nuestros datos.
En términos sencillos,la edad no parece estar relacionada con el género de los nadadores en cuanto a si son mayores de 30 años.

```{r}
tabla2<-table(nadadoresParticipantes$edad<20,nadadoresParticipantes$gender)
chisq.test(tabla2)
```

Hay una diferencia considerable entre las frecuencias observadas (cuántos hombres y mujeres son menores de 20 años) y las frecuencias esperadas bajo la hipótesis nula (que no hay asociación entre edad y género para menores de 20 años).
Esto sugiere ir un paso más allá, **¿Hay más mujeres menores de edad que hombres menores de edad?**

```{r}
tabla3<-table(nadadoresParticipantes$edad<18,nadadoresParticipantes$gender)
chisq.test(tabla3)
```

Los resultados sugieren que el género y la minoría de edad si que están significativamente relacionados en nuestro conjunto de datos de nadadores.
Esto podría tener implicaciones para el análisis del rendimiento y la participación en competiciones.

Veamos números,

```{r}
tabla3

#Calcular los totales
totales <- colSums(tabla3)

#Calcular el porcentaje de nadadores menores de 18 años por género
porcentajes <- (tabla3[2, ] / totales) * 100  
# fila 2 son los menores de 18

porcentajes
```

De esta forma, ya habiendo confirmado una diferencia significativa.
Podemos ver, de manera más representativa, como existe el doble de proporción de mujeres menores de edad en comparación con los hombres.
Dicho en otras palabras, *2 de cada 10 mujeres son menores de 18 años, mientras que esto sólo ocurre en 1 de cada 10 hombres*:

```{r}

porcentajes <- c(10.88, 21.66)  # 10% para hombres y 20% para mujeres
generos <- c("Hombres", "Mujeres")

porcentajes<- as.data.frame(porcentajes)
#generos<- as.data.frame(generos)

# Crear el gráfico con colores accesibles
ggplot(porcentajes, aes(x = generos, y = porcentajes, fill = generos)) +
  geom_bar(stat = "identity", width = 0.6) +  # Barras con ancho ajustado
  geom_text(aes(label = paste0(porcentajes, "%")), vjust = -0.5, size = 5) +  # Mostrar los porcentajes
  labs(
    title = "Porcentaje de Nadadores Menores de 18 Años por Género",
    x = "Género",
    y = "Porcentaje"
  ) +
  scale_fill_viridis_d(option = "C", begin = 0.2, end = 0.8) +  # Colores accesibles
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16),  # Centrar el título
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    legend.position = "none"  # Ocultar la leyenda
  ) +
  ylim(0, 100)  # Ajustar el límite del eje Y
```

```{r, echo=FALSE, warning=FALSE}

#elimino las cosas creadas para no interferir luego. 

rm(tabla1,tabla2, tabla3, generos, porcentajes, totales, datos_porcentajes)

```

## Análisis de nacionalidades.

Vamos a ver la cantidad de nadadores por país.
Para ello, primero voy a ver cuántos paises hay:

```{r}
nlevels(nadadoresParticipantes$code)
```

Hay 185 países.
Debido a la cantidad de países, ver por países cuántos nadadores hay no va a ser muy interpretable.

```{r eval=FALSE, warning=FALSE, include=FALSE}

nadadoresParticipantes$iso2 <- countrycode(nadadoresParticipantes$name, "country.name", "iso2c")

nombres<- unique(nadadoresParticipantes$name) #Para no repetir
#print(nombres)
manual <- data.frame(
  nombre = c("Fina", "Kosovo", "Micronesia", "Virgin Islands"),
  iso2 = c("FI", "XK", "FM", "VI")  
)

# Agregamos la variable continente 
nadadoresParticipantes$continent <- countrycode(nadadoresParticipantes$iso2, "iso2c", "continent")



nadadoresParticipantes <- nadadoresParticipantes %>%
  mutate(continent = ifelse(iso2 == "XK", "Europe", continent))  


#nadadores por país
resumen_paises <- nadadoresParticipantes %>%
  group_by(name, iso2, continent) %>%
  summarise(num_nadadores = n(), .groups = "drop") %>%
  arrange(desc(num_nadadores))  # Ordenar por número de nadadores

head(resumen_paises,6)
```

Por ello, intentaremos analizar los resultados en función de proporciones relativas a continentes.

```{r}
paleta <- c("Americas" = "red", 
            "Asia" = "yellow", 
            "Europe" = "blue", 
            "Oceania" = "green", "Africa"="black")

```

Como podemos observar en los gráficos, la mayor cantidad de nadadores son de procedencia europea, continuando con Asia y Américas, y teniendo baja proporción los nadadores de África y Oceanía.

Nos preguntamos en esta situación, si los Europeos tendrán los puestos más altos en el ranking.
Es decir, si existe mayor proporción de ganadores en los países con más densidad de participantes.

Para ello, analizaremos los puntos según las nacionalidades de los nadadores.

```{r}
puntos_por_pais <- nadadoresPruebas %>%
  group_by(name) %>%  
  summarise(total_puntos = sum(points, na.rm = TRUE))  

# Ver el resultado
head(puntos_por_pais,20)

```

Lo vemos por continentes:

```{r, warning=FALSE}

nadadoresPruebas$iso2 <- countrycode(nadadoresPruebas$name, "country.name", "iso2c")

nombres<- unique(nadadoresPruebas$name) 

manual <- data.frame(
  nombre = c("Fina", "Kosovo", "Micronesia", "Virgin Islands"),
  iso2 = c("FI", "XK", "FM", "VI")  
)


nadadoresPruebas$continent <- countrycode(nadadoresPruebas$iso2, "iso2c", "continent")

nadadoresPruebas <- nadadoresPruebas %>%
  mutate(continent = ifelse(iso2 == "XK", "Europe", continent))  


puntos_por_continente <- nadadoresPruebas %>%
  group_by(continent) %>% 
  summarise(total_puntos = sum(points, na.rm = TRUE))  

print(puntos_por_continente)
```

Anteriormente hemos hallado para cada contiente todos los puntos conseguidos por los nadadores de dicho continente.
Lo que vamos a hacer a continuación es normalizar los puntos por continente, es decir, para cada continente tomamos todos los puntos de dicho continente y lo dividimos por todos participantes de ese continente y comparamos.

```{r}
# Agrupar por continente, sumar puntos y contar participantes
resumenContinente <- nadadoresPruebas %>%
  group_by(continent) %>%
  summarise(
    puntos_totales_continente = sum(points, na.rm = TRUE),
    numero_Participantes_continente = n()  # Contar los participantes
  ) %>%
  mutate(
    relacion_puntos_por_participante = puntos_totales_continente / numero_Participantes_continente
  )

# Imprimir el resultado
print(resumenContinente %>% select(continent, relacion_puntos_por_participante))
```

Vemos que Europa tiene el mejor promedio con una cierta diferencia, le siguen América y Oceanía (puntuaciones similares), después Asia y por último Africa.

Para terminar con esta sección, vamos a ver los 20 primeros en el ranking, y a hacer un gráfico que nos indique de que pais es cada uno de los 20.

```{r}
datos_100m_top <- nadadoresPruebas[nadadoresPruebas$distance==100,] %>% # Filtra para la prueba de 100 metros
  arrange(desc(points)) %>%           # Ordena por puntos de mayor a menor
  dplyr::slice(1:20)                        # Selecciona las primeras 20 

```

```{r}
conteo_por_continente <- datos_100m_top %>%
  group_by(continent) %>%                                       
  summarise(cantidad_nadadores = n()) %>%                      
  mutate(percent = (cantidad_nadadores / sum(cantidad_nadadores)) * 100)  # Calcula el porcentaje

# Crear el gráfico de distribución porcentual
grafico_distribucion_continente <- ggplot(conteo_por_continente, aes(x = continent, y = percent, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Distribución Porcentual de Nadadores por Continente en los Top 20 - 100 Metros",
       x = "Continente",
       y = "Porcentaje de Nadadores") +
  scale_fill_manual(values = paleta) +                          # Usa la paleta de colores personalizada
  theme_minimal()

# Imprimir el gráfico
print(grafico_distribucion_continente)

```

La alta cantidad de nadadores europeos en el podio de 100 metros (más específico que lo anterior, ya que esto nos mete directamente en los primeros 20) sugiere que hay un fuerte nivel de competencia y entrenamiento en las naciones de este continente.
Esto podría estar relacionado con la inversión en programas de natación.
Le sigue oceanía,ya que Oceanía, aunque es una región más pequeña en términos de población comparada con Europa, ha producido nadadores destacados que compiten a niveles muy altos.
La presencia de nadadores de élite, especialmente de Australia, resalta la calidad del talento en la región.

Los datos indican que África tiene solo un 15% de ganadores en la natación en comparación con otros continentes como Europa y Oceanía, esto puede abrir un amplio espacio para el análisis, ya que muchos países africanos enfrentan desafíos significativos en cuánto a la inversión en infraestructura deportiva.La falta de instalaciones de calidad para la natación, como piscinas adecuadas, puede limitar el desarrollo de talentos.

Realizando un chequeo rápido a la tabla de los 20 mejores, vemos que tenemos South Africa en el top 4 en 100 metros.
La presencia de Sudáfrica en el cuarto lugar es un indicador de que, a pesar de la baja representación general, el continente tiene al menos algunos atletas de élite que pueden competir con los mejores del mundo.
Aunque la cantidad de nadadores africanos en el podio es baja, su éxito en alcanzar los primeros puestos es notable.
Esto podría implicar que los nadadores africanos son altamente competitivos cuando tienen la oportunidad de competir en el más alto nivel.
Además,al centrarse en la prueba de 100 metros, que tiene una gran cantidad de participantes, se obtiene una visión clara del rendimiento de los nadadores en este evento específico.
Esto ayuda a eliminar sesgos que podrían surgir al mirar pruebas con menos competidores.

```{r, echo=FALSE}
rm( conteo_por_continente, datos_100m_top, grafico_distribucion_continente, manual, puntos_por_continente, puntos_por_pais, resumenContinente, nombres, paleta, resumen_paises)
nadadoresParticipantes<-nadadoresParticipantesCopia
nadadoresPruebas<-nadadoresPruebasCopia
```

## Estudio sobre los eventos, reactiontime, lane, heats, daytime:

### Reactiontime.

Veamos cómo se distribuyen los datos de tiempo de reacción de todos los nadadores.
Para ello, no tenemos en cuenta las dos filas con datos nulos.

```{r}
ggplot(na.omit(nadadoresPruebas), aes(x = reactiontime)) +
  geom_density(color = viridis(1, option = "C"), fill = viridis(1, option = "C", alpha = 0.5), size = 1.2) +
  ggtitle("Distribución de Reaction Time") +
  labs(x = "Tiempo de Reacción", y = "Densidad") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centrar y resaltar el título
    axis.title = element_text(size = 14),  # Aumentar tamaño de etiquetas de los ejes
    axis.text = element_text(size = 12)  # Aumentar el tamaño de los valores de los ejes
  )

```

Parece que los datos siguen una distribución normal a priori.
Igual que antes, vamos a hacer el test de shapiro:

```{r}
shapiro.test(na.omit(nadadoresPruebas$reactiontime))
```

Al tener un p-valor tan bajo, no parece que siga una distribución normal.
Aún así, este test puede ser erróneo al tener tantos datos.
Vamos a proceder de maenra análoga a como lo hacíamos con la edad.
Vamos a ver si la densidad de este gráfico es igual o parecido a una normal haciendo las siguientes comparaciones.

#### Probabilidad de que un nadador tenga un reactiontime mayor a 0.8.

Primeramente, voy a calcular cuántas filas de nadadoresPruebas tienen un tiempo de 0.8 o mayor sobre el total.
Esto, obviamente nos da la probabilidad de reactiontime\>0.8 en nuestros datos:

```{r}
valor1<- sum(na.omit(nadadoresPruebas$reactiontime) >0.8)/2804
```

Bien, ahora, voy a calcular la media y desviación típica de que sigue Reactiontime.
Voy a suponer que sigue una distribución normal y voy a calcular su probabilidad teórica.

```{r}
media<-mean(na.omit(nadadoresPruebas$reactiontime))
desviacion<-sd(na.omit(nadadoresPruebas$reactiontime))

valor2<-1 - pnorm(0.8, media, sd=desviacion)
```

Por último, voy a simular 2804 datos de una normal con la media y desviación típica calculada anteriormente y vamos a ver cuál es la probabilidad de que los datos simulados valgan más de 0.8:

```{r}
datos_simulados <- rnorm(2804, mean = media, sd = desviacion)

conteo <- sum(datos_simulados > 0.8)

valor3<- conteo/2804
```

Bien, veo los valores obtenidos:

```{r}
valor1
valor2
valor3
```

Observo que, la diferencia es de menos de 0.01 entre el menor y el mayor valor, luego, podremos suponer que la variable reactiontime sigue una distribución normal.

```{r, echo=FALSE}
rm(conteo, datos_simulados, desviacion, media, valor1, valor2, valor3)
```

### Reactiontime. Hombres vs Mujeres.

Comparamos las funciones de densidad de mujeres y hombres en general:

```{r message=FALSE, warning=FALSE}
nadadoresPruebas <- nadadoresPruebas %>% filter(!is.na(nadadoresPruebas$reactiontime))
ggplot(nadadoresPruebas, aes(x = reactiontime, colour = gender, linetype = gender)) +
  geom_density(size = 1.2) +
  scale_color_viridis_d(option = "C", begin = 0.3, end = 0.7) +  # Colores accesibles
  scale_linetype_manual(values = c("solid", "dashed")) +  # Líneas sólidas y punteadas
  labs(
    title = "Distribución del Tiempo de Reacción por Género",
    x = "Tiempo de Reacción",
    y = "Densidad",
    colour = "Género",
    linetype = "Género"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centrar el título
    axis.title = element_text(size = 14),  # Tamaño de las etiquetas de los ejes
    axis.text = element_text(size = 12),  # Tamaño de los valores de los ejes
    legend.position = "top",  # Ubicar la leyenda en la parte superior
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 11)
  )
```

De esta gráfica nos podemos plantear realizar un contraste de hipótesis, en el cual analizaremos sobre la posible diferencia significativa del tiempo de reacción en ambos géneros.
Por tanto, realizamos el siguiente test:

-   H0: El tiempo de reacción es igual en mujeres y hombres.
-   H1: El tiempo de reacción es menor en hombres que en mujeres.

```{r}
t.test(reactiontime~gender,data=nadadoresParticipantes)
```

Si observamos los resultados, el p- valor nos indica que hay una evidencia significativa para rechazar la hipótesis nula, y por ende concluir con que hay una diferencia estadística en el tiempo de reacción dependiendo del género.
Ahora que hemos determinado que la diferencia es estadísticamente significativa, es importante considerar si la diferencia es también significativa en la práctica o si tiene relevancia a la hora de los resultados finales.
Calculamos la diferencia relativa, ya que los tiempos de reacción son muy pequeños y de esta forma nos podemos hacer una idea de lo representativa que es la diferencia de medias.

```{r}
mediaTiempoReaccion <- mean(nadadoresPruebas$reactiontime)
mediaTiempoReaccion
(0.7166871-0.6922862)/mediaTiempoReaccion*100
```

Obtenemos que las mujeres tardan un 3.5% más de tiempo que los hombres.
Es decir que, si mantenemos en igualdad todas las demás variables, si un hombre tarda 22 segundos en un 50, una mujer tardará 3.5% más de tiempo, es decir, 22.77 segundos.
Una diferencia **significativamente** grande si hablamos de una prueba tan corta.

### Reactiontime. Distancias largas vs distancias cortas.

Vamos a comparar ahora las funciones de densidad de las chicas en la prueba de 800m libres y 50m libres:

Primeramente calculamos el conjunto de datos:

```{r}
nadadorasComparacionReactionTime<-nadadoresPruebas[(nadadoresPruebas$distance==50 | nadadoresPruebas$distance==800) & nadadoresPruebas$gender=="F" , ]

```

```{r}

ggplot(nadadorasComparacionReactionTime, aes(x = factor(distance), y = reactiontime, fill = factor(distance))) +
  geom_boxplot(alpha = 0.7, size = 1.2, outlier.shape = 16, outlier.size = 4) +  # Mejorar visibilidad de los outliers
  scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8) +  # Usar colores accesibles de viridis
  labs(
    title = "Boxplot de Tiempo de Reacción: 50m vs 800m",
    x = "Distancia (m)",
    y = "Tiempo de Reacción"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centrar y resaltar el título
    axis.title = element_text(size = 14),  # Etiquetas de los ejes más grandes
    axis.text = element_text(size = 12),  # Etiquetas del eje
    legend.position = "none"  # Ocultar leyenda ya que está implícita en las etiquetas
  )
```

El gráfico muestra los boxplots del tiempo de reacción para la prueba de 50 metros y otra para 800 metros.

```{r}
ggplot(nadadorasComparacionReactionTime, aes(x = reactiontime, fill = factor(distance), group = distance)) +
  geom_density(alpha = 0.6, size = 1.2) +  # Curvas semi-transparentes con líneas más gruesas
  scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8) +  # Colores accesibles con viridis
  ggtitle("Distribución del Tiempo de Reacción: 800m vs 50m Libre") +
  labs(fill = "Distancia (m)") +  
  theme_minimal() +  
  xlab("Tiempo de Reacción (s)") +  
  ylab("Densidad") +
  theme(
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),  # Centrar y resaltar el título
    axis.title = element_text(size = 14),  # Etiquetas de los ejes más grandes
    axis.text = element_text(size = 12),  # Etiquetas del eje
    legend.position = "top"  # Colocar la leyenda en la parte superior
  )
```

Las curvas se encuentran en un rango de aproximadamente 0.5 a 1 segundos, que representa los tiempos de reacción.
Para los 50 metros, la densidad es más alta en el rango de tiempos de reacción más cortos, lo que indica que las nadadoras tienden a tener tiempos de reacción más rápidos en esta distancia.
Esto es esperado, ya que la carrera de 50 metros es más corta y requiere reacciones más rápidas y explosivas.
En cuanto a la de 800 metros, la curva muestra una mayor dispersión en los tiempos de reacción, con una densidad más amplia.
Esto sugiere que los tiempos de reacción son más variados en esta distancia, probablemente debido a la naturaleza más larga y estratégica de la carrera, donde el triunfo de las nadadoras puede estar influenciado por otras variables más determinantes.

Aquí también podemos hacer un test de hipótesis.

```{r}
t.test(reactiontime~distance,data=nadadorasComparacionReactionTime)
```

Veamos nuestros resultados del test.
Por un lado tenemos el valor del estadístico t calculado, como es un valor negativo indica que la media del primer grupo (50 metros) es menor que la del segundo grupo (800 metros).El valor del p-valor (que es extremadamente bajo) indica que hay una diferencia estadísticamente significativa entre las medias de los dos grupos.
Las nadadoras que participan en distancias más cortas (50 metros) tienen un tiempo de reacción más rápido en comparación con aquellas que nadan distancias más largas (800 metros).Luego, habíamos identificado correctamente la tendencia del gráfico, en términos estadísticos.

A continuación, realizamos el mismo estudio pero con hombres y vemos si la situación es similar.

```{r}
nadadoresComparacionReactionTime<-nadadoresPruebas[(nadadoresPruebas$distance==50 | nadadoresPruebas$distance==800) & nadadoresPruebas$gender=="M", ]
```

```{r}
ggplot(nadadoresComparacionReactionTime, aes(x = factor(distance), y = reactiontime, fill = factor(distance))) +
  geom_boxplot() +
  labs(title = "Boxplot de Reaction Time: 50m vs 800m en hombres",
       x = "Distancia (m)",
       y = "Tiempo de Reacción") +
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  
  theme_minimal()

# Crear el gráfico de densidad con colores por distancia
ggplot(nadadoresComparacionReactionTime, aes(x = reactiontime, fill = factor(distance), group = distance)) +
  geom_density(alpha = 0.6) +  #curvas 
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  
  ggtitle("Distribución del Tiempo de Reacción: 800m libre vs 50m en hombres") +
  labs(fill = "Distancia (m)") +  
  theme_minimal() +  
  xlab("Tiempo de Reacción (s)") +  
  ylab("Densidad")

```

```{r}
t.test(reactiontime~distance,data=nadadoresComparacionReactionTime)
```

Al realizar el t-test para este grupo, vemos también como la diferencia es significativa entre el tiempo de reacción para la prueba de 50 metros y la de 800.

La diferencia entre estos dos extremos en las pruebas es muy significativa.
Dados estos resultados, queremos ver las tendencias en las carreras de distancia intermedia, dada nuestra intuición de que el tiempo de reacción aumente de manera gradual.
Es decir, cuál es la diferencia entre las pruebas de 50 metros, las de 100, 200, etc.

Para ello, realizaremos un gráfico de densidad conjunto.

```{r}
ggplot(nadadoresPruebas, aes(x = reactiontime, color = as.factor(distance), fill = as.factor(distance))) +
  geom_density(alpha = 0.3) +  # Ajustar la transparencia
  ggtitle("Distribución comparada de Reaction time") +
  labs(x = "Tiempo de Reacción", y = "Densidad", color = "Distancia", fill = "Distancia") +
  theme_minimal()
```

Como podemos observar, nuestras suposiciones parecen ser ciertas acerca de que las medias de los tiempos de reacción aumentan según la carrera es más larga.
Si bien es cierto, para distancias largas, como son 800 y 1500 metros, no se observan diferencias en torno a su valor central.
Del mismo modo, para carreras de 100 y 200 tampoco se observa una diferencia signifiticativa.

Contrastamos esto de forma más precisa realizando el test ANOVA de diferencia de medias.

```{r}
anova_tiempoReaccion_distancia <- aov(reactiontime ~ as.factor(distance), data = na.omit(nadadoresPruebas))
summary(anova_tiempoReaccion_distancia)
```

Interpretando estos resultados, tenemos que el p-valor es de orden e\^-16.
Por ello, podemos concluir que hay diferencias significativas en los tiempos de reacción entre al menos uno de los grupos de distancia.
Esto indica que, al menos una distancia tiene un tiempo de reacción diferente en comparación con las otras distancias.
El valor de F es alto (56.98), sugiere que la variación entre los grupos es mucho mayor que la variación dentro de los grupos.
Esto refuerza la idea de que las medias de los tiempos de reacción son significativamente diferentes entre las carreras de diferente distancia.

```{r, echo=FALSE}
rm(anova_tiempoReaccion_distancia, nadadorasComparacionReactionTime, nadadoresComparacionReactionTime, mediaTiempoReaccion)

#restauro nadadoresPruebas para el siguiente estudio: 
nadadoresPruebas<-nadadoresPruebasCopia

```

### Calles usadas.

Veamos cómo se distribuyen las calles usadas:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = nadadoresPruebas$lane, fill = factor(lane))) + 
  geom_bar() +
  scale_fill_viridis_d(option = "D") + # Paleta Okabe-Ito
  theme_bw() +
  labs(fill = "Lane") # Etiqueta para la leyenda

```

Se observa que las calles menos usadas son tanto la 0 como la 9.
Esto es un dato que puede resultar curioso al visualizar los datos, pero tiene una clara explicación.

Las calles 0 y 9 sólo son usadas en las rondas preliminares.
Además, las series de cada prueba se confeccionan rellenando de mejor a peor tiempo con el siguiente orden: 4-5-3-6-2-7-1-8-0-9.
Luego, es obvio que si en una prueba tengo 18 nadadores, una serie ocupará todas las calles, pero otra ocupará sólo 8, luego las calles 0 y 9 quedarán libres.

¿Habrá alguna relación entre la calle usada y el tiempo de reacción?

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = reactiontime, color = factor(lane), fill = factor(lane))) +
  geom_density(alpha = 0.6) + # Densidades con transparencia
  facet_wrap(~ lane) +        # Facetas por lane
  theme_bw() +
  labs(
    title = "Distribución de Densidades de Tiempos de Reacción por Calle",
    x = "Tiempo de Reacción",
    y = "Densidad",
    color = "Lane", 
    fill = "Lane"
  ) +
  scale_fill_viridis_d(option = "D") +  # Paleta daltónica para relleno
  scale_color_viridis_d(option = "D")  # Paleta daltónica para bordes
```

Como podemos ver, no parece haber diferencias significativas según el tipo de calle en los tiempos de reacción.

De nuevo, podemos realizar un test anova sobre la diferencia de medias.

```{r}
anova_tiempoReaccion_Calles <- aov(reactiontime ~ as.factor(lane), data = na.omit(nadadoresPruebas))
summary(anova_tiempoReaccion_Calles)
```

El p-valor de nuestro análisis es menor de 0.005, por lo que podríamos sugerir que sí tiene cierta influencia según el número de calle empleada.
Sin embargo, existen muchas variables en nuestro conjunto de datos que podrían influir, por lo que no tiene sentido seguir con este estudio.

### Daytime.

Si observamos los valores que toma la variable Daytime, observamos que toma valores numéricos de 3 y 4 cifras.
Parece corresponder a la hora y minutos en la que cada nadador nadó la prueba.
Luego vamos a cambiar su formato para intentar sacar conclusiones acerca de esta variable:

```{r}
# Función para convertir
convertir_a_hhmm <- function(tiempo_numerico) {
  # Convertir el número a un string y separar horas y minutos
  horas <- tiempo_numerico %/% 100
  minutos <- tiempo_numerico %% 100
  
  # Crear un objeto de tiempo en formato hh:mm
  tiempo_formateado <- sprintf("%02d:%02d", horas, minutos)
  return(tiempo_formateado)
}

# Aplicar la función a todos los tiempos
tiempos_hhmm <- sapply(nadadoresPruebas$daytime, convertir_a_hhmm)
head(tiempos_hhmm)

```

Bien, ya hemos convertido esos números de 3 y 4 cifras a un formato hora/minutos.
Ahora, lo representamos en una gráfica:

```{r}
# Crear la columna 'tiempo_hhmm'
nadadoresPruebas$tiempo_hhmm <- sapply(nadadoresPruebas$daytime, convertir_a_hhmm)

# Convertir la nueva columna 'tiempo_hhmm' a formato POSIXct
nadadoresPruebas$tiempo_hhmm <- as.POSIXct(nadadoresPruebas$tiempo_hhmm, format = "%H:%M")

# Creo la gráfica.
ggplot(nadadoresPruebas, aes(x = tiempo_hhmm)) +
  geom_histogram(
    binwidth = 3600, 
    color = "black", 
    fill = viridis(1, option = "D")  # Paleta daltónica
  ) +
  scale_x_datetime(date_labels = "%H:%M", breaks = "1 hour") +  # Etiquetas cada hora
  labs(
    x = "Tiempo (hh:mm)",
    y = "Frecuencia de nadadores"
  ) +
  theme_minimal()
```

Luego, podemos observar de manera clara que, cada día de competición constaba de 2 sesiones, una matinal y otra vespertina, y que las franjas horarias van, por la mañana de 9:30 a 12:30, y por la tarde de 17:30 a 19:30.

#### Pruebas matinales y vespertinas.

Observamos que el número de nadadores que nadan por la mañana es mucho mayor al de por la tarde.

Vamos a ver un resumen de qué pruebas se nadan por la mañana y cuáles por la tarde:

```{r}
nadadoresPruebas$tiempo_hhmm<- as.POSIXct(nadadoresPruebas$tiempo_hhmm, format = "%H:%M")
#intervalo para las matinales
limite_inferior1 <- as.POSIXct("09:30", format = "%H:%M")
limite_superior1 <- as.POSIXct("13:00", format = "%H:%M")
#intervalo para las vespertinas
limite_inferior <- as.POSIXct("17:00", format = "%H:%M")
limite_superior <- as.POSIXct("20:00", format = "%H:%M")
#Creamos los dataframes.
pruebasMatinales<-subset(nadadoresPruebas, nadadoresPruebas$tiempo_hhmm >= limite_inferior1 & nadadoresPruebas$tiempo_hhmm <= limite_superior1)

pruebasVespertinas<-subset(nadadoresPruebas, nadadoresPruebas$tiempo_hhmm >= limite_inferior & nadadoresPruebas$tiempo_hhmm <= limite_superior)
```

Bien, dividida ya nuestras pruebas en la sesion matinal y la vespertina, veamos un resumen de los datos:

```{r}
dim(pruebasMatinales)
dim(pruebasVespertinas)
```

De aquí observamos que, mientras que por las mañanas se nada un 75% de las pruebas del mundial, por las tardes sólo se nada un 25%.
Veamos si hay alguna variable que nos pueda ayudar:

```{r}
print("Resumen de rondas nadadas en sesiones matinales.")
summary(pruebasMatinales$round)
print("Resumen de rondas nadadas en sesiones vespertinas.")
summary(pruebasVespertinas$round)
```

Luego podemos concluir que, el formato que sigue el mundial de Kazán 2015 es, nadar por las mañanas las series preliminares de cada prueba, mientras que por las tardes sólo nadan los nadadores clasificados a semifinales y finales.

```{r, echo=FALSE}
rm(limite_inferior, limite_inferior1, limite_superior, limite_superior1, tiempos_hhmm, convertir_a_hhmm,pruebasMatinales, pruebasVespertinas, anova_tiempoReaccion_Calles)

nadadoresPruebas<-nadadoresPruebasCopia
```

## Estudio sobre la variable distancia y su asociación con los tipos de nado.

A continuación, nos preguntamos, ¿existen pruebas por cada estilo y cada distancia?
Es decir, al haber 5 estilos y 6 distancias, ¿hay 30 pruebas distintas?
Vamos a responder a la pregunta analizando el dataframe nadadoresPruebas:

Para analizar la relación entre las distancias y los estilos de nado en este conjunto de datos, examinaremos cómo se distribuyen los distintos estilos (BACK, BREAST, FLY, FREE, MEDLEY) en función de la distancia recorrida en metros (50, 100, 200, 400, 800, 1500).

```{r}
distancia_stroke <- table(nadadoresPruebas$distance, nadadoresPruebas$stroke)
print(distancia_stroke)

```

A partir de la tabla proporcionada, se observa lo siguiente:

-   En 50 y 100 metros, se nadan 4 estilos.
    (BACK, BREAST, FLY, FREE).
    No se nada MEDLEY ya que, al ser un mundial en piscina de 50m, no podemos cumplir que se nade como mínimo un largo a cada estilo, ya que en estas pruebas sólo se nada 1 o 2 largos en total.

-   En las pruebas contempladas para 200m, entran los 5 estilos.
    (BACK, BREAST, FLY, FREE).

-   En la distancia de 400m, sólo hay 2 pruebas.
    400m Medley y 400m Free.

-   En 800 y 1500m, sólo hay 1 prueba respectivamente, cuyo estilo (stroke) es libre (FREE)

Estas conclusiones se ven muy claras en el siguiente gráfico:

```{r}
ggplot(nadadoresPruebas, aes(x = factor(distance), y = stroke)) +
  geom_count(aes(color = ..n.., size = ..n..)) +  # Color y tamaño según la frecuencia
  scale_color_viridis_c(option = "D") +          # Paleta continua para daltónicos
  labs(
    x = "Distancia",
    y = "Estilo de Nado",
    size = "Frecuencia",
    color = "Frecuencia"
  ) +
  ggtitle("Frecuencia de Estilos de Nado según la Distancia") +
  theme_minimal()
```

Además, podemos observar que contra más larga es la prueba, menos frecuencia tiene, es decir, menos nadadores participan.
Esto tiene sentido ya que, si participasen los mismos nadadores en una prueba de 50 metros que en una de 1500, entonces las sesiones durarían todo el día o incluso habría que extender los días que comprenden el mundial.

Ahora nos preguntamos, ¿hay las mismas pruebas para mujeres y hombres?

Primero, crearemos subconjuntos de datos para cada género.

```{r}
# Filtrar los datos por género
nadadoresFemeninas <- subset(nadadoresPruebas, gender == "F")
nadadoresMasculinos <- subset(nadadoresPruebas, gender == "M")
```

```{r}
#género femenino
nadadorasPruebas<- nadadoresPruebas[nadadoresPruebas$gender=="F", ]

ggplot(nadadorasPruebas, aes(x = factor(distance), y = stroke)) +
  geom_count(aes(color = ..n.., size = ..n..)) +  # Color y tamaño según la frecuencia
  scale_color_viridis_c(option = "D") +          # Paleta continua para daltónicos
  labs(
    x = "Distancia",
    y = "Estilo de Nado",
    size = "Frecuencia",
    color = "Frecuencia"
  ) +
  ggtitle("Frecuencia de Estilos de Nado según la Distancia para Mujeres") +
  theme_minimal()

nadadoresPruebasM<- nadadoresPruebas[nadadoresPruebas$gender=="M", ]

ggplot(nadadoresPruebasM, aes(x = factor(distance), y = stroke)) +
  geom_count(aes(color = ..n.., size = ..n..)) +  # Color y tamaño según la frecuencia
  scale_color_viridis_c(option = "D") +          # Paleta continua para daltónicos
  labs(
    x = "Distancia",
    y = "Estilo de Nado",
    size = "Frecuencia",
    color = "Frecuencia"
  ) +
  ggtitle("Frecuencia de Estilos de Nado según la Distancia para Hombres") +
  theme_minimal()

```

Parece que todo está funcionando como esperábamos, tanto en el análisis conjunto como en los análisis individuales.
Esto confirma que los resultados son consistentes y los datos están bien estructurados para las pruebas.

```{r, echo=FALSE}
rm(nadadorasPruebas, nadadoresPruebasM, distancia_stroke, nadadoresFemeninas, nadadoresMasculinos)

```

## Estudio sobre la relación entre la edad de los nadadores y las distancias que nadan.

A continuación, vamos a tratar de estudiar si existe algún tipo de relación entre la edad que tienen los nadadores y las pruebas que nadan.
Para ello, voy a clasificar en 4 grupos: - Grupo 1: Menores de 18.
- Grupo 2: Entre 19 y 24 años.
- Grupo 3: Entre 25 y 29 años.
- Grupo 4: Mayores de 30 años.

Para ello, vamos a crear una nueva variable en nuestro dataframe nadadoresPruebas:

```{r}
nadadoresPruebas$grupo_edad <- cut(
  nadadoresPruebas$edad,
  breaks = c(-Inf, 18, 24, 29, Inf),
  labels = c(1, 2, 3, 4),
  right = FALSE
)

```

Bien, una vez creada la nueva variable, ahora voy a construir una tabla que, para cada distancia, ponga el número de nadadores que nada esa prueba.

```{r}
# Contar el número de nadadores en cada grupo de edad y distancia
tabla_grupos <- nadadoresPruebas %>%
  group_by(grupo_edad, distance) %>%
  summarise(num_nadadores = n(), .groups = 'drop')

# Convertir a una tabla de contingencia para que los grupos de edad sean filas y las distancias columnas
tabla_final <- tidyr::pivot_wider(tabla_grupos, names_from = distance, values_from = num_nadadores, values_fill = list(num_nadadores = 0))

# Ver la tabla resultante
print(tabla_final)
```

Vamos ahora a calcular en porcentaje sobre el total de cada grupo, el porcentaje de nadadores que nadan cada prueba agrupado por grupo de edad.
Para ello:

```{r}
# Calcular el total de nadadores por grupo de edad
total_por_grupo <- rowSums(tabla_final[, -1])

# Calcular el porcentaje y añadirlo a la tabla
tabla_porcentajes <- tabla_final %>%
  mutate(across(-grupo_edad, ~ . / total_por_grupo[grupo_edad] * 100))

# Ver la tabla de porcentajes
print(tabla_porcentajes)
```

Si observo esta tabla, puedo ver que, los menores de 18 años nadan en general más pruebas de 50 y 100 metros.
En las edades medias, hay una distribución muy igual para las pruebas tanto de 50, 100 y 200 metros.

A continuación, vamos a evaluar el porcentaje de nadadores de cada grupo por prueba compardo con los nadadores totales que hubo en dicha prueba.
Es decir, la siguiente gráfica:

```{r}
# Calcular los porcentajes de cada columna sobre la suma total de la columna
tabla_porcentajes2 <- tabla_grupos %>%
  group_by(distance) %>%
  mutate(
    porcentaje_columna = (num_nadadores / sum(num_nadadores)) * 100  # Porcentaje sobre la suma de la columna
  ) %>%
  ungroup()

# Ver la tabla resultante con los porcentajes por columna
print(tabla_porcentajes2)
```

Aquí, observamos que sobre el total de nadadores, la distancia que menos nada el grupo 1 es el 200.
Sobre el total, las pruebas que en porcentaje nadan menos el grupo 2 son los 50 y los 100.El grupo 3, tiende a nadar pruebas más cortas en lugar de largas.
Y el último grupo también.

Luego, podríamos concluir que la distribución para los menores de 18 años es bastante simétrica, es decir, son aptos para nadar cualquier tipo de prueba.
Para los del grupo 2, nadan en menos proporción pruebas explosivas como el 50 y 100 y es más frecuente verlos en distancias un poco mayores, esto es razonable ya que el pico de rendimiento en los nadadores se alcanza en las edades de este segundo grupo, luego están más y mejor preparados para nadar distancias más largas.
Para el grupo 3 y 4, las distancias largas y de resistencia ya no son pruebas en las que destaquen (en general), por ello, tienden a ser nadadores que nadan pruebas cortas.

```{r, echo=FALSE}
rm(tabla_final, tabla_grupos, tabla_porcentajes, tabla_porcentajes2,total_por_grupo)

nadadoresPruebas<-nadadoresPruebasCopia

```

## Estudio sobre la variable round.

A continuación, vamos a intentar entender más sobre la variable ronda.
Para ello, primero vemos un resumen:

```{r}
summary(datos2015$round)
```

Observamos que toma 5 posibles valores, tenemos controlados tanto FIN (final), como PRE (preliminar) y SEM (semifinal).
Pero SOP y SOS no parece tan claro saber qué es.
Vamos a comenzar dejando de lado SOP y SOS, nos vamos a centrar en controlar los otros 3 valores.

### ¿Cuántos nadadores nadan cada ronda?

Una pregunta natural podría ser, ¿cuántos nadadores pasan de ronda?
¿Todos?
Está claro que al ver que por la mañana en preliminares nadan el 75% y por las tardes son semifinales y finales y son un 25%.
Veamoslo con distintas pruebas:

#### 50 libre femenino:

Seleccionamos las nadadoras que nadaron preliminares en el 50 libre femenino:

```{r}
free50PrelimWomens<- nadadoresPruebas[nadadoresPruebas$round=="PRE" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]

head(free50PrelimWomens,10)
```

Ahora, vamos a hacer el ranking de resultados de esta prueba, para ello:

```{r}
free50PrelimWomens<-free50PrelimWomens[order(free50PrelimWomens$swimtime), ]

dim(free50PrelimWomens)
```

Observamos que hubo 119 nadadoras que nadaron las preliminares del 50 libres.
Veamos ahora cuántas nadaron las semifinales:

```{r}
free50SemisWomens<-nadadoresPruebas[nadadoresPruebas$round=="SEM" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]
```

Antes de ordenarlas, veamos cuántas filas tengo en mi nuevo data frame:

```{r}
dim(free50SemisWomens)
```

Es decir, de 119, sólo se clasificaron 16.
Veamos si fueron las 16 primeras.
Para ello, voy a coger las 16 primeras de las prelims, voy ahora a ordenarlas por athleteid, y hacer lo mismo con las de las semifinales, a ver si coincide:

```{r}
free50PrelimWomens<-head(free50PrelimWomens, 16)

#Ordeno: 

free50PrelimWomens<-free50PrelimWomens[order(free50PrelimWomens$athleteid), ]
free50SemisWomens<-free50SemisWomens[order(free50SemisWomens$athleteid), ]

free50PrelimWomens
free50SemisWomens

```

Luego, podemos observar claramente que, las 16 primeras de las preliminares, consiguieron clasificarse a las semifinales.
Hagamos el mismo trabajo con el dataframe *free50SemisWomens* para ver cuántas nadadoras se clasificaron en la final:

```{r}
free50SemisWomens<-free50SemisWomens[order(free50SemisWomens$swimtime), ]

```

Al igual que antes, confeccionamos el dataframe de la final:

```{r}
free50FinalWomens<-nadadoresPruebas[nadadoresPruebas$round=="FIN" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]

dim(free50FinalWomens)
```

Observamos que hay 8, luego las 8 primeras se clasificaron a la final.

### ¿Se nadan las 3 rondas en cada prueba?

Esta cuestión nos surge ya que, algunas pruebas requieren más esfuerzo y el tiempo de descanso para la recuperación total es más largo, por ello alomejor hay pruebas en las que sólo hay 1 ronda, o 2, o esta suposición es falsa y en cada prueba se nadan 3 rondas.
Para ello, echemos un cálculo inicial.
Hay 2 géneros, pruebas de 50, 100, 200, 400, 800 y 1500 metros.
Veamos qué valores toman las rondas en cada una de estas pruebas.
Para ello:

```{r}
print("Rondas que se nadan en las pruebas de 50 metros: ")
summary(nadadoresPruebas[nadadoresPruebas$distance==50, ]$round)
print("Rondas que se nadan en las pruebas de 100 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==100, ]$round)
print("Rondas que se nadan en las pruebas de 200 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==200, ]$round)
print("Rondas que se nadan en las pruebas de 400 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==400, ]$round)
print("Rondas que se nadan en las pruebas de 800 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==800, ]$round)
print("Rondas que se nadan en las pruebas de 1500 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==1500, ]$round)
```

Luego, observamos que en las pruebas de 400, 800 y 1500 metros no hay semifinales, tan sólo una ronda preliminar y una ronda final.

También podemos sacar conclusiones gracias al estudio hecho en el apartado anterior.
En los 50 por ejemplo, hay 128 nadadores que nadan semifinales, hay dos géneros, luego 64 nadadores por género nadaron semifinales, además, hay 4 estilos, luego 16 nadadores nadaron las semifinales de cada prueba, lo cual concuerda con lo visto anteriormente.

Destaca a la vista que, en las pruebas de 200 metros, hay más nadadores.
¿Por qué sucede esto?.
Veamos:

```{r}
print("Estilos que se nadan en pruebas de 50 metros: ")
summary(nadadoresPruebas[nadadoresPruebas$distance==50, ]$stroke)
print("Estilos que se nadan en pruebas de 200 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==200, ]$stroke)
```

Hay más nadadores que nadan semifinales puesto que hay 5 pruebas, no 4.
Si echamos los cálculos, 160/(2\*5)=16 nadadores, igual que en las demás.

Se puede ver de manera análoga que nadan 8 nadadores cada final.

Ahora, ya que hemos analizado a fondo qué sucede con las finales, semifinales y preliminares, vamos a ver qué significan los otros dos valores que toma la variable *round*.

### Rondas SOP

Bien, primeramente, vamos a observar las filas tales que toman ese valor.
Lo hacemos de la siguiente manera:

```{r}
datosSOP<-datos2015[datos2015$round=="SOP",]

datosSOP
```

Observamos 4 filas, que se trata, viendo que es el mismo *eventid*, de una prueba que nadan sólo 2 nadadoras, Osman y Kelly.
En este caso, un 100 mariposa.
Es curioso que estas dos nadadoras naden una sóla prueba.
Además, nadaron a las 11:56, por la mañana, donde sólo se nadan preliminares.
Vamos a ver si descubrimos algo viendo la clasificación de ese 100 mariposa en la ronda preliminar:

```{r}
fly100PREWomen<-nadadoresPruebas[nadadoresPruebas$distance==100 & nadadoresPruebas$stroke=="FLY" & nadadoresPruebas$round=="PRE" & nadadoresPruebas$gender=="F", ]

#Ahora ordenamos por tiempo
fly100PREWomen<-fly100PREWomen[order(fly100PREWomen$swimtime), ]
#Las ordeno
rownames(fly100PREWomen) <- 1:nrow(fly100PREWomen)
head(fly100PREWomen,20)

```

Si busco a Osman y Kelly en el anterior dataframe, observo que se encuentran en el puesto 16 y 17 respectivamente y que, hicieron el mismo tiempo.
Luego tiene sentido razonar que, las rondas SOP son rondas de desempate para ver quién pasa a la siguiente ronda.

### Rondas SOS

Viendo el razonamiento de las rondas SOP, intuimos que las rondas SOS deben ser rondas de desempate entre nadadores de las semifinales.
De todas maneras, vamos a verlo.
Para ello, si nos fijamos en una de los dataframes anteriores, en la prueba de 200 metros había 4 nadadores que nadan la ronda SOS.
Vamos a visualizarlo:

```{r}
datosSOS<-nadadoresPruebas[nadadoresPruebas$round=="SOS" & nadadoresPruebas$distance==200, ]
datosSOS
```

Vemos que se nadaron dos rondas SOS, una para la prueba de 200m braza femenino, y otra para la prueba de 200 estilos masculino.
Elijamos el 200 estilos masculino, visualicemos el ranking de las semifinales y veamos si están Roberto Pavoni y Conor Dwyer empatados en el 8vo y 9no puesto:

```{r}
medley200SEM<-nadadoresPruebas[nadadoresPruebas$round=="SEM" & nadadoresPruebas$distance==200 & nadadoresPruebas$gender=="M" & nadadoresPruebas$stroke=="MEDLEY", ]

#Ahora, ordeno igual que antes: 

medley200SEM<-medley200SEM[order(medley200SEM$swimtime), ]
#Las ordeno
rownames(medley200SEM) <- 1:nrow(medley200SEM)
medley200SEM
```

Y efectivamente, empataron con un tiempo de 118.54 segundos, luego SOS equivale a las rondas de desempate producidas en las rondas semifinales.
Además, observamos que se realizan por las tardes.

Luego, ya hemos resuelto las dudas acerca de Round.

```{r, echo=FALSE}
rm(datosSOP, datosSOS, fly100PREWomen, free50FinalWomens, free50PrelimWomens, free50SemisWomens, medley200SEM)

```

## Estudios relacionados con los puntos.

Veamos las posibles relaciones de puntos con las demás variables:

Antes de ello, vamos a tener que eliminar de este estudio a los nadadores descalificados (es decir, los que tienen NA points).

```{r}
nadadoresPruebas <- nadadoresPruebas %>% filter(!is.na(nadadoresPruebas$points))
```

### Mejor nadador por prueba nadada. MVP de los mundiales.

Veamos ahora cómo se distribuyen los puntos.

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = points)) +
  geom_density(fill = viridis(1, option = "D"), color = "black", alpha = 0.8) + # Color accesible
  ggtitle("Distribución de Puntos") +
  labs(x = "Puntos", y = "Densidad") + # Etiquetas descriptivas
  theme_minimal(base_size = 14) + # Tema limpio y texto más grande
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), # Centrar título
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14)
  )
```

Observamos que la mayoría de puntos se encuentran a partir de los 750/800 puntos, y esto, tiene sentido si razonamos que para entrar a los mundiales de natación, se necesitan unas marcas mínimas (una cantidad de puntos preestablecida).
Luego es normal encontrar una gran cantidad de datos que tengan más de 750 puntos ya que había un "corte" para la inscripción en la competición.
Esto hace que la gráfica no esté más distribuida por todos los posibles valores de puntos.

Ahora nos surge la siguiente pregunta: *¿Quién rindió mejor en los campeonatos?*.

Podemos buscar el nadador que hizo más puntos:

```{r}
datos2015[which.max(datos2015$points), ]
```

Observamos que la nadadora que cosechó más puntos en una prueba fue Katie Ledecky en los 1500 metros.
Buscando, casualmente observamos que batió el récord[<https://www.rtve.es/deportes/20150803/ledecky-bate-record-del-mundo-1500-libres/1193160.shtml>] del mundo en dicha prueba.

Ahora, vamos a buscar al nadador que, en promedio, consiguió más puntos, podríamos denominarlo el *MVP* del Mundial Kazán 2015.
Para ello:

```{r}
#Usamos nadadoresPruebas, donde tenemos cada nadador y la prueba que realizó. 

media_puntos <- aggregate(nadadoresPruebas$points ~ nadadoresPruebas$athleteid, data = nadadoresPruebas, FUN = mean)
media_puntos <- media_puntos[order(media_puntos$`nadadoresPruebas$points`, decreasing = TRUE), ]
media_puntos<- rename(media_puntos, "athleteid"="nadadoresPruebas$athleteid")
media_puntos<-rename(media_puntos, "meanPoints"="nadadoresPruebas$points")

head(media_puntos,5)
```

El atleta con id 108588 es el que hizo más puntos, veamos quien es:

```{r}
nadadoresPruebas[nadadoresPruebas$athleteid==108588	, ]
```

Luego, el MVP fue el británico Adam Peaty, que nadó 50, 100 y 200 braza.
Veamos quiénes fueron los integrantes del podio:

```{r}
nadadoresParticipantes[nadadoresParticipantes$athleteid==102630 | nadadoresParticipantes$athleteid==105594, ]
```

Completaron el podio Cameron Van der Burgh, de Sudáfrica, y Katie Ledecky.

### Puntos. Hombres vs Mujeres

A continuación, vamos a comparar los puntos realizados por hombres y mujeres, para ver si podemos sacar alguna conclusión.

Primeramente, vamos a ver la función de densidad:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = points, colour = gender)) +
  geom_density() +
  ggtitle("Distribución de Puntos por Sexo") +
  labs(x = "Puntos", y = "Densidad") +
  scale_colour_viridis(discrete = TRUE, option = "D") + # Paleta accesible
  theme_minimal(base_size = 14) + # Tema limpio y texto más grande
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"), # Centrar título
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```

A priori, parece haber dos distribuciones muy igualadas.
Tiene sentido ya que, los puntos se definen de manera separada para cada sexo.
Es decir, la distribución de los puntos se calculan con un algoritmo que se basa en la distribución de tiempos para esa prueba y ordenada respecto al récord mundial en dicha prueba.
Nadadores con puntos cercanos a 1000 son nadadores élite cuyo tiempo está muy cerca del récord mundial.
En este caso, hay dos distribuciones por cada prueba, una para las chicas y otra para los chicos, luego tiene sentido que la gráfica anterior sea tan parecida.

### Puntos. ¿La edad influye?

Una buena manera de medir el rendimiento con respecto a la edad del nadador, es verlo a través de los puntos obtenidos.

```{r, warning=FALSE}
# Resumen de puntos por edad
resumen_puntos <- nadadoresPruebas %>%
  group_by(edad, points) %>%
  summarise(frecuencia = n(), .groups = 'drop')

# Crear el gráfico de calor
ggplot(resumen_puntos, aes(x = edad, y = points)) +
  geom_tile(aes(fill = frecuencia), color = "black") +
  # Usar una paleta de colores divergente
  scale_fill_gradientn(colors = brewer.pal(9, "Reds"), 
                       limits = c(min(resumen_puntos$frecuencia), max(resumen_puntos$frecuencia))) + 
  theme_bw() +
  labs(title = "Gráfico de Calor: Edades y Puntos Obtenidos",
       x = "Edad",
       y = "Puntos Obtenidos") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

```{r}
# Crear una nueva columna que clasifica a los nadadores en grupos de edad
nadadoresPruebas <- nadadoresPruebas %>%
  mutate(grupo_edad = case_when(
    edad < 18 ~ "Menores de 18",
    edad >= 18 & edad <= 30 ~ "Entre 18 y 30",
    edad > 30 ~ "Mayores de 30"
  ))

# Calcular el promedio de puntos por grupo de edad
promedio_puntos <- nadadoresPruebas %>%
  group_by(grupo_edad) %>%
  summarise(promedio = mean(points, na.rm = TRUE))

# Crear un gráfico de barras para visualizar el promedio de puntos
ggplot(promedio_puntos, aes(x = grupo_edad, y = promedio, fill = grupo_edad)) +
  geom_bar(stat = "identity", color = "black") +
  scale_fill_brewer(palette = "Reds") +  # Cambiar la paleta si es necesario
  theme_bw() +
  labs(title = "Promedio de Puntos por Grupo de Edad",
       x = "Grupo de Edad",
       y = "Promedio de Puntos") +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = "none")
```

Vamos a comparar los puntos con la edad.
Para ello, vamos a dividir en 3 grupos por edades (menores de 18, entre 18 y 30 y mayores de 30) y a comparar el promedio de puntos cosechados por cada franja de edad.

```{r}
# Mostrar el promedio de puntos en una tabla
promedio_puntos %>%
  kable(caption = "Promedio de Puntos por Grupo de Edad", 
        col.names = c("Grupo de Edad", "Promedio de Puntos"))

```

En el grupo de edad entre 18 y 30, el promedio de Puntos es 817.76.Este grupo presenta el promedio más alto en comparación con los otros grupos.
Esto podría indicar que los nadadores en este rango de edad tienen un rendimiento superior en términos de puntos acumulados.
Esto puede ser atribuible a varios factores, como una mayor experiencia.
El grupo de Edad Mayores de 30 tiene un promedio de 806.32 puntos.
Los nadadores mayores de 30 años tienen un promedio de puntos ligeramente inferior al grupo de 18 a 30 años.
Sin embargo, el rendimiento sigue siendo fuerte, lo que sugiere que, aunque pueden enfrentar desafíos relacionados con la edad, muchos continúan siendo competitivos.
El grupo de Edad Menores de 18 tiene un promedio de 621.36 puntos.
Este grupo muestra el promedio más bajo en comparación con los otros dos.
Esto puede ser indicativo de que los nadadores jóvenes aún están en desarrollo y adquiriendo habilidades y experiencia.
Es natural que los nadadores más jóvenes, al estar en una etapa temprana de su carrera, acumulen menos puntos.

La diferencia significativa en el rendimiento entre los grupos puede sugerir que la edad tiene un impacto positivo en el rendimiento de los nadadores, al menos hasta cierto punto.
Esto también resalta la importancia del entrenamiento y la experiencia que se adquiere con la edad.
Es posible que los nadadores más jóvenes tengan que enfocarse en su desarrollo técnico y competitivo para alcanzar a sus contrapartes mayores.
Esto podría incluir mejorar sus técnicas de natación, preparación física, y estrategias de carrera.

Realizamos un test para ver si la diferencia es significativa

```{r}
# Realiza la prueba de Kruskal-Wallis
kruskal_result <- kruskal.test(points ~ grupo_edad, data = nadadoresPruebas)
print(kruskal_result)
```

El p-value \< 2.2e-16: Este valor p es extremadamente bajo, lo que indica que hay diferencias significativas en los puntos entre al menos uno de los grupos de edad.
Dado que el valor p es muy pequeño, puedes rechazar la hipótesis nula, que sostiene que no hay diferencias en las medianas de los puntos entre los grupos.

Aunque Kruskal-Wallis indica que hay diferencias, no te dice cuáles son esos grupos que difieren.
Por lo tanto, es recomendable realizar pruebas post-hoc para identificar qué grupos son significativamente diferentes entre sí.

```{r, warning=FALSE}
# Prueba de Dunn
dunn_test <- dunnTest(points ~ grupo_edad, data = nadadoresPruebas, method = "bonferroni")
print(dunn_test)
```

Entre 18 y 30 vs. Mayores de 30: No hay evidencia suficiente para afirmar que hay una diferencia significativa en los puntos entre estos dos grupos de edad.
Entre 18 y 30 vs. Menores de 18: Hay una diferencia altamente significativa en los puntos entre estos dos grupos.
Esto indica que los nadadores menores de 18 años obtienen significativamente menos puntos que los nadadores entre 18 y 30.
Mayores de 30 vs. Menores de 18: También hay una diferencia altamente significativa entre estos grupos, sugiriendo que los nadadores mayores de 30 años obtienen significativamente más puntos que los nadadores menores de 18.

La comparación muestra que, mientras que no hay diferencia significativa entre los grupos de 18-30 y mayores de 30, los menores de 18 años se desempeñan significativamente peor en términos de puntos en comparación con ambos grupos de mayores edad.

```{r}
ggplot(nadadoresPruebas, aes(x = grupo_edad, y = points, fill = grupo_edad)) +
  geom_boxplot() +
  labs(
    title = "Distribución de Puntos por Grupo de Edad", 
    x = "Grupo de Edad", 
    y = "Puntos"
  ) +
  scale_fill_viridis(discrete = TRUE, option = "D") + # Paleta viridis para colores accesibles
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )

```

```{r, echo=FALSE}
#vuelvo de nuevo a la original

rm(anova_puntos_genero, dunn_test, kruskal_result, media_puntos, modelo, promedio_puntos, resumen_puntos)
nadadoresPruebas<-nadadoresPruebasCopia
```

### Modelo de regresión lineal: reactiontime vs swimtime.

Empezamos viendo la relación lineal (que ya sabemos que será alta) entre puntos y tiempo.
Es evidente que a mayor tiempo, hay menos puntos.
Veámoslo

```{r}
nadadoresPruebas50crol<- nadadoresPruebas[nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=='FREE', ]
t= nadadoresPruebas50crol$swimtime
p= nadadoresPruebas50crol$points
cor(nadadoresPruebas50crol$swimtime,nadadoresPruebas50crol$points)
head(nadadoresPruebas50crol,10)

```

Esto no es de mucho estudio, ya que es lo lógico.

Veamos los puntos respecto al tiempo de reacción:

```{r}
nadadoresPruebas<- na.omit(nadadoresPruebas)
x= nadadoresPruebas$points
y=nadadoresPruebas$reactiontime
```

```{r}
cor(x,y)
```

Parecen no estar correlacionadas el tiempo de reaccion y los puntos de manera lineal.
Pero a lo mejor, en pruebas específicas , como las pruebas de distancias cortas la correlación es mayor.

```{r}
nadadoresPruebas50<- nadadoresPruebas[nadadoresPruebas$distance==50, ]
X=nadadoresPruebas50$reactiontime
Y=nadadoresPruebas50$points
cor(X,Y)
```

Ya tenemos nuestro objetivo de estudio ya que para comenzar con la modelización estadística, debemos contextualizar el problema, definiendo objetivos y variables.

Queremos investigar si existe relación entre el tiempo de reacción y puntos.
Una pregunta que puede surgirnos es, ¿A mayores valores del tiempo de reacción, hay mayores valores de puntos?
Luego, nuestro objetivo será saber si hay algún tipo de relación lineal, y las variables, por ende, serán tiempo de reacción y puntos.
La variable tiempo de reacción, será nuestra variable independiente, y puntos será la variable dependiente.

A continuación, procedemos a realizar una inspección gráfica simple, para identificar tendencias.

```{r}
plot(X,Y,xlab="Tiempo de reacción",ylab="Puntos")
```

```{r}
cov(X,Y)
```

Esta covarianza, positiva y grande en valor absoluto, nos indica que hay relación negativa entre las variables(ya lo habíamos intuido pero gracias al signo lo hemos confirmado).

A pesar de la confirmación, en este momento nos surge un problema, pues, la covarianza toma valores en todos los números reales, dependiendo de las magnitudes del tiempo de reacción y puntos, y de sus unidades .
Por eso, calcularemos el coeficiente de correlación lineal, que se obtiene tipificando la covarianza, es decir, dividiendo la covarianza entre las desviaciones típicas muestrales (obteniendo un coeficiente entre -1 y 1)

```{r}
cor(X,Y)
```

De manera adicional, podemos incluir histogramas marginales en cada eje del gráfico, para ello usamos las librerías `ggplot2` y `ggExtra`.

```{r}
datos<-data.frame(x=X,y=Y)

p<-ggplot(datos, aes(x = X, y = Y)) +
  geom_point()
#vemos la nube de puntos 
print(p)
#Especificamos que se añadan histogramas en los márgenes
ggMarginal(p, type = "histogram")

```

Como hemos visto, si la relacion lineal es fuerte tiene sentido querer ajustar una recta a la nube de puntos.
Es decir, considerar un modelo de regresion lineal simple.

La función que ajusta el modelo de regresión lineal simple en R es `lm`(con parametros B_0,B_1 y sigma\^2), directamente hacemos un `summary` para que nos devuelva la información más importante, aunque realmente `lm` calcula muchas cosas: estimaciones, residuos, predicciones, etc.

```{r}
lm=lm(Y~X)
summary(lm)
```

Podemos añadir la recta de regresión al gráfico usando el comando `abline`, y el objeto donde hemos guardado el ajuste de la recta, en este caso `lm4`:

```{r}
#representamos
plot(X,Y)
#añadimos la recta de regresion
abline(lm)
```

Los coeficientes de la regresión estimados también están en el objeto donde hemos guardado el ajuste, en `lm`

```{r}
#generamos un vector con los coeficientes de la regresion
coeficientes=lm$coefficients
#comprobamos que es lo mismo que nos salía en el summary
coeficientes
```

Sabemos que el valor de los puntos cuando X=0, es decir, que el tiempo de reacción sea cero, es de 1809 aproximadamente.
Este parámetro no tendría sentido, pues el tiempo de reacción nunca va a ser cero.
Por otro lado la pendiente es -1562.315, lo que nos muestra que por cada valor que aumenta X, Y aumenta lo indicado.

```{r, echo=FALSE}

#Este código al final del estudio para no sobrecargar el entorno (Enviroment)
rm( datos, lm, coeficientes, t, x, X, y, Y, nadadoresPruebas50, nadadoresPruebas50crol, p)

nadadoresPruebas<- nadadoresPruebasCopia

```

## Prueba 800m Libre femenino.

Quiero evaluar la prueba 800m libres.

Veamos qué nadadores nadaron el 800 libre femenino:

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
nadadoras800free<-nadadoresPruebas[nadadoresPruebas$distance==800 & nadadoresPruebas$gender=="F", ]

dim(nadadoras800free)
```

Se observa que no hay descalificaciones en el 800 libres femenino.
Tenemos que 51 chicas nadaron el 800 libres, algunas de ellas dos veces ya que pasaron a la final.

Nos vamos a fijar en la final, para ello, filtramos otra vez los datos:

```{r}
nadadoras800free<-datos2015[datos2015$gender=="F" & datos2015$distance==800 & datos2015$round=="FIN", ]

```

#### Estudio sobre los parciales de la carrera.

Vamos a evaluar cómo fueron los parciales de las nadadoras, para ello hacemos el siguiente gráfico:

```{r, warning=FALSE}
ggplot(nadadoras800free, aes(y=nadadoras800free$lastname, x=nadadoras800free$splitswimtime, fill=nadadoras800free$lastname))+
  geom_boxplot()+
  labs(x="Parciales", y="Nadadoras")
```

De aquí podemos observar la media y los cuantiles de los parciales de las nadadoras.
Observamos que casi todas tienen 1 o incluso 2 puntos atípicos, seguramente se deban al primer y último parcial de la prueba.
Además, podemos observar que algunas nadadoras como Kapas y Friis, tuvieron una desviación muy pequeñita en sus parciales, es decir, fueron a un ritmo constante durante toda la prueba clavando sus parciales.

Vamos a observar, para cada nadador, los parciales realizados para ver si podemos conseguir algún patrón de tipo de carrera:

```{r, warning=FALSE}
ggplot(nadadoras800free, aes(x=nadadoras800free$splitdistance, y=nadadoras800free$splitswimtime, group = lastname, colour =lastname )) + 
  geom_line()  + 
  geom_point( size=2, shape=21, fill="white") + 
  theme_minimal()+
  labs(x="Parciales", y="Tiempos por parcial.")
```

Observamos que todas nadan muy rápido tanto el primer parcial como el último.
Además, vemos de manera clara como Ledecky parece que alterna un largo un poco más rapido y luego otro más lento durante toda su prueba.
¿Puede ser una estrategia de carrera?
Lo veremos más adelante.
También vemos alguna otra nadadora más que hace algo similar como Van Rouwendaal.
Otras en cambio, intentan conservar el ritmo marcado desde el inicio y ser constantes.
Carlin mete un cambio de ritmo muy drástico al paso de los 650m de 31s altos a 31s bajos y sigue luego bajando.

#### Visualización de la carrera.

Ahora, vamos a definir un dataframe en el que nos va a importar el nombre, la suma total de tiempo al paso de cada parcial:

```{r}
nadadoras800free <- nadadoras800free %>%
  dplyr::select(lastname,firstname,gender,reactiontime,splitdistance,cumswimtime, swimtime)

```

Visualizamos la carrera:

```{r}
# Ordenar los datos por tiempo
nadadoras800free <- nadadoras800free %>%
  arrange(splitdistance, cumswimtime)

# Crear un índice de posición
nadadoras800free <- nadadoras800free %>%
  group_by(splitdistance) %>%
  mutate(Posicion = rank(cumswimtime, ties.method = "first"))



ggplot(nadadoras800free, aes(x = splitdistance, y = Posicion, group = lastname)) +
  geom_line(aes(color = lastname, alpha = 1), size = 2) +
  geom_point(aes(color = lastname, alpha = 1), size = 4) +
  scale_y_reverse(breaks = 1:nrow(nadadoras800free))
```

Observamos como Ledecky lidera toda la carrera, Boyle alcanza al paso de los 100 metros la segunda posición y la mantiene.
La pelea por la última medalla en juego dura hasta los 700 metros, donde un adelantamiento de Carlin a Ashwood hace que la nadadora Jaz Carlin alcance el bronce olímpico.

```{r, echo=FALSE}
rm(nadadoras800free)
```

# PCA's

## Análisis de componentes principales del 800 libres femenino. Ronda preliminar.

Lo primero que debemos hacer es cargar los datos:

```{r}
prueba800libresPreliminar<- datos2015[datos2015$distance==800 & datos2015$gender=="F" & datos2015$stroke=="FREE" & datos2015$round=="PRE", ]

prueba800libresPreliminar <- prueba800libresPreliminar %>%
    dplyr::select(lastname, reactiontime, splitdistance, splitswimtime, edad)
```

Bien, ahora, debemos encontrar la manera de crear un dataframe en la que nos quedemos con el nombre, apellido y parciales.

```{r, warning=FALSE}
pruebawide <- prueba800libresPreliminar %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
#omito los valores nulos: 
pruebawide<- na.omit(pruebawide)
pruebawide<- as.data.frame(pruebawide)
rownames(pruebawide) <- pruebawide$lastname

```

Ahora que ya tenemos nuestro dataframe hecho, vamos a hacer el PCA:

```{r}
pca800libres<-prcomp(pruebawide[,-1], scale=T)

plot(pca800libres)

```

Vemos la importancia de cadad componente.

Observemos además, un resumen numérico:

```{r}
summary(pca800libres)
```

Viendo el pca, observamos que con la primera componente, tenemos un 84% de la varianza.
Con pc2 un 6%, luego con esas dos logramos explicar un 90% de los datos.

Hagamos una interpretación previa a la graficación de los datos:

```{r}
pca800libres
```

La PCA1 corresponde a una media ponderada en la cual, lo que más ponderan son los parciales de la prueba, siendo los más significativos del 200 al 650.
También toma algo de importancia la edad pero no se verá reflejada.
Luego, nos esperaremos más a la izquierda los nadadores cuyo tiempo medio sea menor (es decir, las más rapidas de las preliminares), y a la derecha las nadadoras más lentas en promedio.

La PCA2, cobra muchísima importancia el tiempo de reacción y la edad.
Luego, esperaremos, contra más arriba se encuentren, nadadoras con un buen tiempo de reacción o pocos años, y abajo nadadoras con mal tiempo de reacción o muchos años.

Ahora, veamos cómo se ven los datos:

```{r}
plot(pca800libres$x[,1:2], type="n")
text(pca800libres$x[,1:2],rownames(pruebawide), cex = 0.4)

```

Luego, podríamos decir que, el grupo de Ledecky, Carlin...
fueron las más rapidas de las preliminares.
Chentson, Holowchak y Rannvaardottir las más lentas.

También, podríamos decir que, nadadoras como Jo, corresponden a un tiempo de reacción muy bajo junto con una edad baja.
Nadadoras como Kobrich y Elhenicka, serán nadadoras con más años y que además tienen un mal tiempo de reacción en comparación con todas las demás.

Veámos la ponderación de las variables con el siguiente gráfico:

```{r}
fviz_pca_var(pca800libres, col.var = "red")
```

Viendo esta interpretación, podemos observar de una mejor manera, cuando un nadador va a estar más "arriba" o "abajo", si es causa de la edad o del tiempo de reacción.
Luego, si nos fijamos en las nadadoras del gráfico anterior, podremos asegurar que, Gill, tiene un tiempo de reacción pésimo, ledecky es rápida y joven y buen tiempo de reacción.
Hassler es una nadadora con más edad pero de las más rapidas pero con mal tiempo de reacción.

```{r}
#biplot(pca800libres)

fviz_pca_biplot(pca800libres, repel = TRUE)
```

```{r, echo=FALSE}
rm(pca800libres, prueba800libresPreliminar, pruebawide)
```

## Análisis de componentes principales en la carrera preliminar de 1500 metros

Vamos a ver en qué estilo predominan los nadadores de 1500 metros.

```{r}
summary(nadadoresPruebas$stroke[nadadoresPruebas$distance == 1500])
summary(nadadoresPruebas$round[nadadoresPruebas$distance == 1500])
```

Como podemos observar, todos los nadadores nadan en estilo libre.
Por tanto, no seleccionaremos según esa imposición, ya que nos viene de los propios datos.
Gracias a ello, tenemos un enfoque más global de la carrera de 1500 metros.

Además, tenemos 70 participantes en rondas preliminares y 15 finales.
Por tanto, tomaremos la ronda preliminar para hacer nuestro análisis de componentes principales.

```{r}
# Filtro de pruebas de 1500m masculino
datos1500Masc <- datos2015[datos2015$distance==1500 & datos2015$gender=="M" & datos2015$round =="PRE",]

# Selección de columnas relevantes
datos1500Masc <- datos1500Masc %>% dplyr::select(lastname, reactiontime, splitdistance, splitswimtime)
head(datos1500Masc,15)
```

```{r}
prueba1500 <- datos1500Masc %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas

#Eliminamos duplicados y NA de la columna 'lastname'
prueba1500 <- prueba1500[!duplicated(prueba1500$lastname) & !is.na(prueba1500$lastname), ]

prueba1500 <- as.data.frame(prueba1500)

# Asignar los nombres de fila como el apellido del nadador
row.names(prueba1500) <- prueba1500$lastname

#Eliminamos filas con NA restantes
prueba1500 <- na.omit(prueba1500)
head(prueba1500,15)
```

Con todo esto, estamos preparados para realizar el PCA:

```{r}
#Realizamos el PCA
pca_1500masculino <- prcomp(prueba1500[,-1], scale=T)

# Resultados del PCA
summary(pca_1500masculino)

```

Por tanto, vemos el Análisis de Componentes Principales (PCA) en los datos de nadadores masculinos en la carrera de 1500 metros, excluyendo la primera variable, que es el nombre.

Observamos que el primer componente principal (PC1) tiene una desviación estándar de 5.0272 y explica el 81.52% de la varianza total.
Este componente captura la mayor parte de la variabilidad en los datos, lo que sugiere que una sola dirección en el espacio de los datos contiene gran parte de la información relevante.
Los siguientes componentes, como PC2 y PC3, explican 7.75% y 3.47% de la varianza respectivamente.
Estos valores disminuyen progresivamente, lo que indica que los componentes adicionales explican cada vez menos de la variabilidad total.
Así pues, los primeros dos componentes principales explican el 89,27% de la varianza.
Si añadimos el tercer componente, logran explicar el 92.73% de la varianza, lo que puede ser suficiente para una interpretación efectiva de los datos.

Visualizamos ahora cómo se distribuyen los datos en las dos primeras componentes principales y observamos la influencia de las variables en estas componentes.

```{r}
fviz_pca_biplot(pca_1500masculino, repel = TRUE)

```

Viendo el gráfico, podemos interpretar la primera componente como la rapidez en cada split de los participantes.
Cuantos mayores tiempos tienen en cada split, mas desplazados estarán hacia la izquierda.
Por tanto, los nadadores mas a la derecha serán aquellos con mejores resultados.
Vemos como el 81,5% de la varianza de los resultados está explicado por estos tiempos, como podría imaginarse en un principio.
Si nos enfocamos en lo que explica la componente 2, vemos que mayores tiempos de los primeros splits condicionan su desplazamiento hacia abajo, y los tiempos mayores en los ultimos splits desplazan los puntos hacia arriba.
Esto parece indicar que la componente 2 captura las diferencias entre el rendimiento en las etapas iniciales y finales de la prueba, posiblemente destacando la resistencia o la fatiga en los nadadores.
Además, es claramente visible como el tiempo del último split (cuando se completan los 1500m) es muy influyente en la posición de estos nadadores.
Es decir, los tiempos en esta última parte parecen ser muy decisivos en cuanto a su resultado final.

Si observamos la influencia del tiempo de reacción, los tiempos de reacción altos ejercen influencia a favor del eje x e y, en sus sentidos positivos.
Con lo cual, el tiempo de reacción alto parece estar asociado con un rendimiento positivo en los splits y posiblemente en la resistencia hacia el final de la prueba.

Para ver si estas cuestiones se cumplen, vamos a observar si los primeros puestos del ranking de puntos de esta categoría coincide con lo visto en el gráfico.

```{r}
# Filtro de pruebas de 1500m masculino
resumen1500 <- datos2015[datos2015$distance==1500 & datos2015$gender=="M" & datos2015$round =="PRE",]

# Selección de columnas relevantes
resumen1500 <- resumen1500 %>% dplyr::select(lastname,points) %>%
    distinct() %>%         
    arrange(desc(points))


resumen1500
```

Como podemos comprobar, Paltrinieri, Jaeger, Sun y Milne aparecen en los puntos más extremos del eje x.
Además, se localizan en la posición central, lo que parece indicar que sus tiempos son bastante estables durante todo el recorrido.
Si visualizamos los últimos nadadores, que son Arias Dourdet, Butler y Sim Wee Sheng, observamos que efectivamente están en los extremos izquierdos del eje x.
Además, Arias Dourdet y Butler están desplazados hacia el eje y, lo que parece indicar que obtuvieron tiempos más largos en sus splits finales, posiblemente debido a una falta de resistencia y mayor fatiga en estos tiempos, que es un factor crucial para el desarrollo de este tipo de pruebas.

```{r, echo=FALSE}
rm(datos1500Masc, pca_1500masculino, resumen1500)
```

# Clusters

## Cluster sobre el 800m libres femenino. Análisis de estrategias de las nadadoras.

Voy a crear a continuación un dataframe en el cual, contenga el nombre de las nadadoras del 800 libres femenino.
Además, quiero los parciales al paso por cada 50 y el tiempo final.

Vamos a intentar, normalizar de cierta manera los parciales respecto del tiempo final, para intentar ver estrategias de carrera en las nadadoras.
Obsérvese que, normalizamos los datos porque pueden existir dos nadadoras cuya estrategia de carrera sea la misma, pero que se encuentren muy alejadas en el cluster debido a que sus tiempos son lo suficientemente distintos.
Es por ello que normalizaremos los datos.

Empecemos creando los dataframes de manera análoga a como lo hicimos en el PCA:

```{r, warning=FALSE}
prueba800libresPreliminar<- datos2015[datos2015$distance==800 & datos2015$gender=="F" & datos2015$stroke=="FREE" & datos2015$round=="PRE", ]

prueba800libresPreliminar <- prueba800libresPreliminar %>%
    dplyr::select(lastname, splitdistance, splitswimtime,swimtime)

free800WomensPre <- prueba800libresPreliminar %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
#omito los valores nulos: 
free800WomensPre<- na.omit(free800WomensPre)

free800WomensPre <- as.data.frame(free800WomensPre)

rownames(free800WomensPre) <- free800WomensPre$lastname
```

A continuación, vamos a echar un vistazo a lo creado:

```{r}
head(free800WomensPre, 10)
```

Ahora, voy a normalizar los datos dividiendo cada pacial por el tiempo total, que dará una especie de "porcentaje" de cuánto tardan en cada parcial:

```{r}
free800WomensNormalizado <- free800WomensPre %>%
  mutate(across(c(`50`, `100`, `150`, `200`, `250`, `300`, `350`, `400`, `450`, 
                  `500`, `550`, `600`, `650`, `700`, `750`, `800`), 
                ~ . / swimtime))

#free800WomensNormalizado$swimtime=NULL
free800WomensNormalizado <- as.data.frame(free800WomensNormalizado)
rownames(free800WomensNormalizado) <- free800WomensNormalizado$lastname


```

Bien, ahora, voy a tratar de hacer un cluster:

En primer lugar vamos a calcular la distancia Euclídea entre las observaciones de la base de datos.

```{r}
distance <- get_dist(free800WomensNormalizado[,-c(1,2)])

fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Esto empieza a ilustrar qué estados tienen grandes disimilitudes (rojo) frente a los que parecen ser bastante similares (verde azulado).

Veamos ahora, mediante el método de las siluetas, el número óptimo de clusters:

```{r}
fviz_nbclust(free800WomensNormalizado[,-c(1,2)], kmeans, method = "silhouette")
```

A continuación, hacemos el cluster:

```{r}
cluster800libres <- kmeans(free800WomensNormalizado[,-c(1,2)], centers = 3, nstart = 25)
cluster800libres
```

```{r}
fviz_cluster(cluster800libres, data = free800WomensNormalizado[,-c(1,2)])
```

Bien, ahora para poder sacar las conclusiones debidas, voy a querer graficar el dataframe, donde cada nadadora (fila), va a tener asociado un cluster.

```{r}
free800WomensNormalizado$cluster<-cluster800libres$cluster

```

A continuación, vuelvo al formato long, para ello:

```{r}
prueba800long <- free800WomensNormalizado %>%
  pivot_longer(cols = c("50", "100", "150", "200", "250", "300", "350", 
                         "400", "450", "500", "550", "600", "650", 
                         "700", "750", "800"), 
               names_to = "splitdistance", 
               values_to = "splitswimtime")



```

Gráfica:

```{r}
ggplot(prueba800long, aes(x = as.numeric(splitdistance), 
                          y = splitswimtime, 
                          group = lastname, 
                          color = factor(cluster))) +
  geom_line(alpha = 0.6) +  # Agrega líneas para cada nadadora
  geom_point() +             # Agrega puntos en cada parcial
  labs(x = "Parcial (m)", 
       y = "Tiempo de Nado (segundos)", 
       color = "Cluster") +
  theme_minimal() +
  ggtitle("Tiempos de Nado por Parciales Agrupados por Cluster")
```

Parece que este gráfico no es lo suficientemente claro, voy a evaluar nadadoras por cluster de manera separada:

```{r}
# Filtrar datos por cluster y graficar
for (i in unique(prueba800long$cluster)) {
  p <- ggplot(prueba800long[prueba800long$cluster == i, ], 
               aes(x = as.numeric(splitdistance), 
                   y = splitswimtime, 
                   group = lastname, 
                   color = factor(cluster))) +
    geom_line(alpha = 0.6) + 
    geom_point() +
    labs(x = "Parcial (m)", 
         y = "Tiempo de Nado (segundos)", 
         color = "Cluster") +
    theme_minimal() +
    ggtitle(paste("Tiempos de Nado del Cluster", i))

  print(p)  # Imprime la gráfica
}
```

Para analizar mejor las estrategias, intentamos no fijarnos en el primer y último largo, ya que corresponden para todas las nadadoras, a largos en los que van más rápido.
Tras ver las tres gráficas, se ve que, las nadadoras pertenecientes al cluster 1, son nadadoras que empiezan relativamente rápido pero que con el paso de los metros, empiezan a subir de tiempos cada parcial.

Las nadadoras del cluster 2, se aprecia que sus parciales tienen una forma de U invertida, empiezan rápido, sobre la mitad de la prueba, es donde más lento van, y luego vuelven a acelerar.

Las nadadoras del último cluster, observamos que son nadadoras muy constantes en cuanto a los parciales.

Vamos a evaluar estas 3 últimas gráficas graficando los centroides de cada cluster:

```{r}
centroides <- as.data.frame(cluster800libres$centers)
centroides$cluster<- factor(rownames(centroides)) 
#Los vuelvo long: 
centroideslong <- centroides %>%
  pivot_longer(cols = c("50", "100", "150", "200", "250", "300", "350", 
                         "400", "450", "500", "550", "600", "650", 
                         "700", "750", "800"), 
               names_to = "splitdistance", 
               values_to = "splitswimtime")


# Gráfico
ggplot(centroideslong, aes(x = as.numeric(splitdistance), y = splitswimtime, color = cluster, group = cluster)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_viridis_d() +  # Colores amigables para daltónicos
  labs(x = "Split Distance (m)", y = "Split Swim Time (s)", color = "Centroide") +
  theme_minimal()

```

### Mejor cluster.

A continuación, vamos a evaluar cuál cluster tiene las mejores nadadoras, es decir, las nadadoras que pasaron a la final:

Vamos a ordenar el data frame *free800WomensNormalizado*:

```{r}
free800WomensNormalizado <- free800WomensNormalizado[order(free800WomensNormalizado$swimtime), ]

finalistas<-head(free800WomensNormalizado, 8)

conteo <- table(finalistas$cluster)
conteo
```

Observamos que, hay nadadoras tanto del 3er cluster como del 1ro (5 y 3).
Ahora, vamos a calcular la media de tiempos de cada cluster para ver "cuál" es el más rapido en media.

```{r}
media_swimtime_por_cluster <- aggregate(free800WomensNormalizado$swimtime ~ free800WomensNormalizado$cluster, data = free800WomensNormalizado, FUN = mean, na.rm = TRUE)

media_swimtime_por_cluster
```

## Cluster para la prueba de 1500 masculina

```{r}
# escalado de todas las variables
clusterprueba1500 <- scale(prueba1500[,-1])

summary(clusterprueba1500)
```

```{r}
distance <- get_dist(clusterprueba1500)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k2 <- kmeans(clusterprueba1500, centers = 2, nstart = 25)
str(k2)
```

```{r}
fviz_cluster(k2, data = clusterprueba1500)
```

Como vemos, con 2 clusters nos divide a los participantes según la velocidad.
Es decir, los que pertenecen al cluster rojo serían los de tiempos más altos, y los azules los que están en mejores posiciones de resultados.

Nos preguntamos, si el número óptimo de clústeres para dividir a nuestro grupo total es realmente 2, o podemos dividirlos en más grupos.
Para ello, utilizamos el método del codo.

```{r}
# Reproducible
set.seed(123)

fviz_nbclust(clusterprueba1500, kmeans, method = "wss")
```

Parece que sí que tenemos una mejoría si continuamos diviendo nuestro grupo en 3 o incluso 4.
Por encima de estos números, no obtenemos grandes mejoras en nuestro análisis.

Por tanto, probamos con k=3 y k=4 y observamos los resultados

```{r}
k3 <- kmeans(clusterprueba1500, centers = 3, nstart = 25)

fviz_cluster(k3, data = clusterprueba1500)
```

```{r}
k4 <- kmeans(clusterprueba1500, centers = 4, nstart = 25)

fviz_cluster(k4, data = clusterprueba1500)
```

Como podemos observar en ambos gráficos, la segregación de nadadores sigue estando bastante influida por su posición relativa al eje x.
Es decir, nos clasifica los grupos según sus velocidades.
Con 3 clústeres, tendríamos los nadadores lentos, los intermedios, y los muy rápidos.
En el segundo gráfico con 4 clusteres, podemos observar los grupos muy lentos (prácticamente valores outiers), los centrales divididos en mas y menos lentos y un último grupo, de competidores de alta calificación.
Observando ambos, los dos grupos de la derecha contienen prácticamente los mismos puntos.
Sin embargo,si que existe una división entre los puntos de la izquierda.
La elección de k=3 o k=4 vendrá por el interés del estudio que queramos realizar.
Si no nos interesan los nadadores de peor cualificación, no será necesario segregar a los nadadores en 4 grupos.
Sin embargo, si queremos analizar estos nadadores con peores marcas parece interesante ajustarnos a un nivel de k=4.

Utilizamos otros métodos para decidir si nuestro razonamiento es correcto.
Para ello, utilizamos el método de "silueta" y el método "GAP".

```{r}
fviz_nbclust(clusterprueba1500, kmeans, method = "silhouette")
```

```{r}
set.seed(123)
gap_stat <- clusGap(clusterprueba1500, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)

print(gap_stat, method = "firstmax")
fviz_gap_stat(gap_stat)
```

Utilizando estos dos últimos métodos, nos dan el resultado de que el número óptimo de clústers son dos en "silueta" y uno en "Gap".
Puesto que cada método nos determina un número distinto de k, utilizaremos la división en grupos según el objetivo a tratar, como hemos comentado recientemente.

##Cluster jerarquico prueba de 1500 metros masculina

### Cluster aglomerativo. AGNES.

Queremos hacer un cluster jerárquico de nuestra prueba.
Para ello, calculamos el valor del coeficiente aglomerativo

```{r}
# Clustering jerárquico usando enlace completo
hc2 <- agnes(clusterprueba1500, method = "complete" )

hc2$ac
```

El coeficiente aglomerativo tiene un valor cercano al 1, con lo que sugiere una fuerte estructura de agrupamiento.
Vamos ahora a evaluar qué metodo nos da un coeficiente mayor y emplearemos esa estructura de agrupacion con el objetivo de conseguir una estructura de agrupación más fuerte.

```{r}
# Métodos evaluados
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# Función para calcular el coeficiente de agrupamiento
ac <- function(x) {
  agnes(clusterprueba1500, method = x)$ac
}

map_dbl(m, ac)
```

Como vemos, lo conseguimos con el método ward.
Por tanto, utilizamos ese método para realizar el dendrograma

```{r}
# Matriz de disimilaridades
d <- dist(clusterprueba1500, method = "euclidean")

# Clustering jerárquico usando enlace completo
hc1 <- hclust(d, method = "ward" )

# Dendrograma
plot(hc1, cex = 0.6, hang = -1)
```

Interpretando el dendrograma, vemos como los primeros pasos de agrupamiento son entre distintas muy pequeñas.
Por tanto, no tiene sentido cortar en esas etapas iniciales.
El gráfico parece sugerir la aglomeración en 3 grupos.

### Cluster divisivo. DIANA.

Calculamos ahora el coeficiente de división.

```{r}
# Clustering jerárquico divisivo
hc4 <- diana(clusterprueba1500)

# Coeficiente de división; cantidad de estructura de agrupación encontrada
hc4$dc
```

Como podemos ver, tenemos un coeficiente de división cercano al 1.
Con lo cual, podemos proceder a realizar el dendograma.

```{r}

# Drendrograma
pltree(hc4, cex = 0.6, hang = -1, main = "Dendrogram de DIANA")
```

Utilizamos ahora la función "cutree" para dividir nuestro dendrograma en los clústers que consideremos.
En este caso, utilizamos k=4

```{r}
# Método de Ward
hc5 <- hclust(d, method = "ward.D2" )

# Cortamos en 4 clusters
sub_grp <- cutree(hc5, k = 4)

# Visualizamos el corte en el dendrograma
plot(hc5, cex = 0.6)
rect.hclust(hc5, k = 4, border = 2:5)
```

Veamos si coincide con los clusters que hemos considerado en el apartado previo

```{r}
# Visualización
#Cluster realizado con el método de división
fviz_cluster(list(data=clusterprueba1500,cluster=sub_grp))

#Cluster realizado con kmeans
fviz_cluster(k4, data = clusterprueba1500)
```

Como vemos, las divisiones son similares, pero no son iguales.
Esto se debe al método de agregación que difiere en ambos casos.

A su vez, comparamos si los dendrogramas utilizados para agregar o dividir son isomorfos.

```{r}

# Matriz de distancias
res.dist <- dist(clusterprueba1500, method = "euclidean")

# Calcuamos los dos clustering jerárquicos
hc1 <- hclust(res.dist, method = "ward")
hc2 <- hclust(res.dist, method = "ward.D2")

# Dendrogramas
dend1 <- as.dendrogram (hc1)
dend2 <- as.dendrogram (hc2)

# los enfrentamos
tanglegram(dend1, dend2)
```

Como podemos observar, no nos dan dendrogramas isomorfos puesto que los dos métodos manejan de manera diferente las distancias entre grupos durante el proceso de fusión.

```{r, warning=FALSE}
rm(clusterprueba1500, clusterprueba200, datos1500Masc, dend1, dend2, hc1, hc2, hc200, hc4, hc5, hc5_200, k2, k200, k3, k4, k5_200, pca_1500masculino, prueba1500, prueba200MariposaMasc, pruebita, d, d200, distance, distancias, ac, sub_grp, res.dist, m)
```

```{r, warning=FALSE}
rm(centroides, centroideslong, cluster800libres, componentess, finalistas, free800WomensNormalizado, free800WomensPre, gap_stat, media_swimtime_por_cluster, auto, conteo, p, prueba200MariposaMasc2, prueba800libresPreliminar, prueba800long, R, i, Cor_CompVar, Cor_CompVar_retenidos)
```

# Objetivo del análisis y partición de los datos.

Nuestro objetivo en esta sección es **predecir** si los nadadores que llegan a la final, van a disminuir su tiempo en esa prueba (tomarán el valor 1), o si en cambio, no lo harán (tomarán el valor 0).
Para ello, vamos a crear la tabla `datos2015Target`.

A partir de este momento, vamos a estudiar acerca de un target.
En este caso, nuestro target es ver si los finalistas van a mejorar su tiempo respecto a la ronda anteriormente nadada.
Por lo que, vamos a quedarnos con el conjunto de **nadadores que están clasificados a la final de cada prueba**, y su tiempo en la ronda anterior.
Para ello, voy a ir dividiendo los datos por cada distancia.
Elegiré los nadadores que nadaron la final y la semifinal.
Pero filtrando los semifinalistas

```{r}
#Me quedo con los finalistas de las pruebas de 50, 100 y 200:
finalistas1<-datos2015[datos2015$round=="FIN" & datos2015$distance %in% c(50,100,200),]

condicionFiltro<-unique(finalistas1[,c("athleteid", "distance", "stroke")])

#Me quedo con los semifinalistas de las pruebas de 50, 100 y 200: 
semifinalistas1<-datos2015[datos2015$round=="SEM" & datos2015$distance %in% c(50,100,200),]

#Ahora, los filtro para que cumplan esa condición de Filtro.
semifinalistasFiltrados <- merge(semifinalistas1, condicionFiltro, by = c("athleteid", "distance", "stroke"))

#Ahora, hago la unión.

dataframe1 <- rbind(finalistas1, semifinalistasFiltrados)

#Ahora, hago el mismo proceso para las pruebas de 400, 800 y 1500 pero con las finales y preliminares: 

finalistas2<-datos2015[datos2015$round=="FIN" & datos2015$distance %in% c(400,800,1500),]
condicionFiltro<-unique(finalistas2[,c("athleteid", "distance", "stroke")])

semifinalistas2<-datos2015[datos2015$round=="PRE" & datos2015$distance %in% c(400,800,1500),]

#Ahora, los filtro para que cumplan esa condición de Filtro.
semifinalistasFiltrados2 <- merge(semifinalistas2, condicionFiltro, by = c("athleteid", "distance", "stroke"))

#Ahora, hago la unión.

dataframe2 <- rbind(finalistas2, semifinalistasFiltrados2)


#Ahora, hago la unión de mis datos: 

datos2015Target<-rbind(dataframe1, dataframe2)

#Los voy a ordenar por prueba y nombre. 

datos2015Target<-datos2015Target[order(datos2015Target$stroke, datos2015Target$athleteid, datos2015Target$distance), ]

rownames(datos2015Target)<-NULL
```

Borramos todos los objetos auxiliares usados para obtener la tabla `datos2015Target`

```{r}
rm(condicionFiltro, dataframe1, dataframe2, finalistas1, finalistas2, semifinalistas1, semifinalistas2, semifinalistasFiltrados, semifinalistasFiltrados2)
```

Vamos a calcular la media, desviación típica, mínimo y máximo de cada parcial:

```{r}
#Hacemos un long to wide.

datos2015Target$split<-NULL
datos2015Target$cumswimtime<-NULL

datos2015TargetLong <- datos2015Target %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas

#Una vez hecho, vamos a calcular la media, desviación típica, mínimo y máximo de cada parcial.

datos2015TargetLong$mediaParciales <- rowMeans(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], na.rm=TRUE)

datos2015TargetLong$minimoParciales <- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, min, na.rm=TRUE)

datos2015TargetLong$maximoParciales <- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, max, na.rm=TRUE)

datos2015TargetLong$sdParcial<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, sd, na.rm=TRUE)

datos2015TargetLong$medianaParciales<- apply(datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")], 1, median, na.rm=TRUE)

datos2015TargetLong[, c("50", "100", "150", "200", "250", "300", "350", "400", "450", "500", "550", "600", "650", "700", "750", "800", "850", "900", "950", "1000", "1050", "1100", "1150", "1200", "1250", "1300", "1350", "1400", "1450", "1500")]<-NULL

rm(datos2015Target)
```

Ahora, busco que, para cada nadador que nada la final en una prueba de una distancia determinada, en sus columnas aparezcan las variables de las finales y las semifinales a la vez.
Para ello, voy a dividir el dataframe `datos2015TargetLong` en 2, uno con los finalistas y otro con los semifinalistas.

```{r}
dataframe1<-datos2015TargetLong[datos2015TargetLong$round=="FIN", ]
dataframe2<-datos2015TargetLong[datos2015TargetLong$round == "PRE" | datos2015TargetLong$round== "SEM", ]

#Voy a renombrar las variables para que, al hacer el merge, se puedan ver las variables de manera intuitiva.

dataframe1 <- dataframe1 %>%
  rename(
    eventidF= eventid,
    heatF= heat,
    laneF= lane,
    pointF= points,
    reactiontimeF= reactiontime,
    swimtimeF = swimtime,
    daytimeF= daytime,
    mediaParcialesF= mediaParciales,
    minimoParcialesF= minimoParciales,
    maximoParcialesF= maximoParciales,
    sdParcialF= sdParcial,
    medianaParcialesF= medianaParciales
  )

dataframe2<- dataframe2%>%
  rename(
    eventidP= eventid,
    heatP= heat,
    laneP= lane,
    pointP= points,
    reactiontimeP= reactiontime,
    swimtimeP = swimtime,
    daytimeP= daytime,
    mediaParcialesP= mediaParciales,
    minimoParcialesP= minimoParciales,
    maximoParcialesP= maximoParciales,
    sdParcialP= sdParcial,
    medianaParcialesP= medianaParciales
  )
#Ahora, quiero hacer un join por athleteid, distance, stroke: 

datos2015Target <- merge(dataframe1, dataframe2, by = c("athleteid", "distance", "stroke"), all = FALSE)

# Eliminar una o varias columnas
datos2015Target <- datos2015Target %>% select(-round.x, -lastname.y, -firstname.y, -gender.y, -name.y, -code.y, -round.y, -edad.y)

#Renombro aquellas que tienen el .x o .y:

datos2015Target<- datos2015Target%>%
  rename(
    lastname= lastname.x,
    firstname= firstname.x,
    gender= gender.x,
    name= name.x,
    code= code.x,
    edad= edad.x
  )
```

```{r}
rm(dataframe1, dataframe2, datos2015TargetLong )
```

Bien, me falta ahora, añadir el target:

```{r}
# Crear la nueva variable target según la condición
datos2015Target$target <- ifelse(datos2015Target$swimtimeF - datos2015Target$swimtimeP < 0, 1, 0)
```

Si visualizo al primer nadador:

```{r}
head(datos2015Target,1)
```

Observo que Joseph Schooling, nadó la final más rapido que la final, por lo que tienen de target un 1.




## Categorización de algunas variables. 

Algunas de nuestras variables, son categóricas, pero tienen demasiadas categorías, por lo que si queremos hacer modelos como k-vecinos o árboles, puede que no sean todo lo generales que deberían. Por ejemplo, la variable país, puede servirnos para un modelo k-vecinos, pero en un árbol de decisión podría hacer una división si perteneces a un conjunto de países muy específico. Como el objetivo es predecir con modelos lo más generales posibles, a continuación voy a ir evaluando las variables a las cuales les debemos hacer un tratamiento distinto de los datos: 

### Daytime. 

Vamos a categorizar de cierta manera esta variable daytime. Como vimos en el EDA, tenemos dos sesiones, matinal y vespertina, luego, vamos a agrupar por sesión. Para ello, hacemos lo siguiente: 

```{r}
# Visto en el eda, se puede dividir por sesión si cojo del mínimo a 2, 
datos2015Target$sesionP <- ifelse(datos2015Target$daytimeP<1400, "Matinal", "Vespertina")
datos2015Target$sesionP <- as.factor(datos2015Target$sesionP)

```

Cabe destacar que, la sesion de las finales es SIEMPRE vespertina, luego no es necesario crear esa nueva variable.

### País.
Nuestra variable país está bien, nos será útil en modelos que buscan más especificidad como los k-vecinos, pero en modelos como árboles de decisión, puede no ser lo suficientemente general. Por ello, vamos a agrupar por continente: 

```{r}
datos2015Target$continente <- countrycode(datos2015Target$code, origin = "iso3c", destination = "continent")

datos2015Target$continente <- as.factor(datos2015Target$continente)

summary(datos2015Target$continente)

```

Si observo, hay algunos países que no los está cogiendo, voy a ver cuáles son: 

```{r}
naContinentes<- datos2015Target[is.na(datos2015Target$continente),]

summary(naContinentes$code)
```

Observo que países como Alemania, Países Bajos, Dinamarca... No me los está cogiendo adecuadamente, luego voy a proceder a hacerlo manualmente. Para ello: 

```{r}
datos2015Target$continente[datos2015Target$code == "GER" | datos2015Target$code == "NED" |
                             datos2015Target$code == "DEN" | datos2015Target$code == "GRE"  
                           | datos2015Target$code == "SLO" ] <- "Europe"

datos2015Target$continente[datos2015Target$code == "RSA"]<- "Africa"

datos2015Target$continente[datos2015Target$code == "SIN" | datos2015Target$code == "BAH"]<- "Asia"

datos2015Target$continente[datos2015Target$code == "CHI"]<- "Americas"



```


Visualicemos que todo esté en orden: 

```{r}
summary(datos2015Target$continente)
```

Perfecto, podemos proseguir. 

```{r}
rm(naContinentes)
```


## Partición de los datos.

La repartición de nuestros datos, será sobre las finales.
En total, tengo 8 nadadores por cada final, 2 sexos.
En las pruebas de 50 y 100 tengo 4 estilos, lo que suma 128 nadadores.
También, tengo en las pruebas de 200, 8 nadadores, 2 sexos y 5 estilos, lo que suma 80.
En el 400 tengo 8 nadadores, 2 sexos y 2 estilos, lo que suma 32 nadadores.
En el 800 y 1500 tengo 8 nadadores por cada sexo, lo que hace un total de 32 nadadores.

La suma total es de 272 nadadores, aunque debemos tener en cuenta que hubo una baja en la final del 1500 masculino, luego será de 271 nadadores.

Vamos a ver si estas cuentas son ciertas de la siguiente manera:

```{r}
nadadoresFinalistas<-nadadoresPruebas[nadadoresPruebas$round=="FIN", ]
rownames(nadadoresFinalistas) <- 1:nrow(nadadoresFinalistas)
```

```{r}
dim(nadadoresFinalistas)
```

Luego, observamos que sí, estamos en lo cierto.
Ahora, voy a hacer la repartición de mis datos sobre el dataframe creado anteriormente:

```{r}
n=nrow(datos2015Target)
set.seed(1312)
indices_validation= sample(1:n, n*0.1)
indices_entrenamiento= c(1:n)[-indices_validation]

#he dividido los datos, ahora, cojo los de entreno y divido otra vez. 
n_entrenamiento=length(indices_entrenamiento)
set.seed(2910)
indices_train=sample(indices_entrenamiento, 0.8*n_entrenamiento)
indices_test=c(1:n)[-c(indices_validation, indices_train)]
#reinicio las filas por si acaso:
rownames(datos2015Target) <- NULL
#hago la repartición:
datos2015Target_train=datos2015Target[indices_train,]
datos2015Target_test= datos2015Target[indices_test, ]
datos2015Target_validation=datos2015Target[indices_validation, ]
```

```{r}
# Elimino las tablas que no voy a usar: 

rm(datos2015, nadadoresParticipantes, nadadoresPruebas, nadadoresParticipantesCopia, nadadoresPruebasCopia, nadadoresFinalistas )
```

# Análisis previo de los datos.

Antes de comenzar nuestro estudio, vamos a evaluar el total de nadadores que sí bajan de tiempo y el total que NO lo hacen.
Lo hacemos:

```{r}
datos2015Target_train$target <- as.factor(datos2015Target_train$target)
summary(datos2015Target_train$target)

112/(112+83)
```

Luego, un 57.43% baja de marca.
Luego, tiene sentido intentar buscar mediante medidas de rendimiento, esas predicciones sobre nuevas observaciones.
Vamos a evaluar todos los modelos de rendimiento vistos en teoría, y elegiremos el (los) que nos aporten un mayor rendimiento en las medidas (DECIDIRLAS).

## Posibles variables que influyan en la respuesta.

A continuación, voy a evaluar en mi conjunto de datos, si existe algún patrón que nos pueda decir si las nadadoras bajan o no de tiempo, es decir, si alguna variable dictamina más que otras.
Para ello, voy a empezar analizando la edad.
Voy a evaluar si existe algún tipo de relación entre la edad y si bajan o no tiempo.
Para ello:

```{r}
# Agrupar edades en intervalos (por ejemplo, cada 5 años)
df<-datos2015Target_train
df <- df %>%
  mutate(grupo_edad = cut(edad, breaks = seq(10, 45, by = 5), right = FALSE))

## Calcular el porcentaje de nadadores que bajan (1) y que no bajan (0) por grupo de edad
porcentajes <- df %>%
  group_by(grupo_edad, target) %>%
  summarise(total = n(), .groups = "drop") %>%
  group_by(grupo_edad) %>%
  mutate(porcentaje = total / sum(total) * 100)

# Graficar: Gráfico de barras de porcentaje
ggplot(porcentajes, aes(x = grupo_edad, y = porcentaje, fill = factor(target))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Porcentaje de Nadadores que Bajan y no Bajan por Grupo de Edad",
    x = "Grupo de Edad",
    y = "Porcentaje",
    fill = "¿Bajan?"
  ) +
  theme_minimal()
```

Parece que, a partir de los 30 años, hay más porcentaje de nadadores que no consiguen bajar la marca.
Parece haber relación, luego lo tendremos en cuenta.

```{r, echo=FALSE}
rm(conteo, df, porcentajes)
```

Continuamos nuestro estudio haciendo algo muy similar con los estilos.
Es decir, ¿alguno de los 5 estilos tiene relación con que se baje la marca?
Lo vemos en el siguiente gráfico:

```{r}
datos<- datos2015Target_train
# Calcular el porcentaje de nadadores que bajan (1) y que no bajan (0) por Stroke
porcentajes <- datos %>%
  group_by(stroke, target) %>%
  summarise(total = n(), .groups = "drop") %>%
  group_by(stroke) %>%
  mutate(porcentaje = total / sum(total) * 100)

# Graficar: Gráfico de barras de porcentaje
ggplot(porcentajes, aes(x = stroke, y = porcentaje, fill = factor(target))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Porcentaje de Nadadores que Bajan y No Bajan por Stroke",
    x = "Tipo de Stroke",
    y = "Porcentaje",
    fill = "¿Bajan?"
  ) +
  theme_minimal()
```

Bueno, parece que, hay algunos estilos mucho más influyentes que otros.
Medley y Free, son estilos que parece que tienen un porcentaje alto de bajar.
También el estilo braza no parece un estilo en el que se baje en las finales.

Prosigo el estudio haciendo lo mismo con las distancias:

```{r}
datos<-datos2015Target_train
datos$distance<- as.factor(datos$distance)
# Calcular el porcentaje de nadadores que bajan (1) y que no bajan (0) por Stroke
porcentajes <- datos %>%
  group_by(distance, target) %>%
  summarise(total = n(), .groups = "drop") %>%
  group_by(distance) %>%
  mutate(porcentaje = total / sum(total) * 100)

# Graficar: Gráfico de barras de porcentaje
ggplot(porcentajes, aes(x = distance, y = porcentaje, fill = factor(target))) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Porcentaje de Nadadores que Bajan y No Bajan por distancia",
    x = "Tipo de Stroke",
    y = "Porcentaje",
    fill = "¿Bajan?"
  ) +
  theme_minimal()
```

A partir de los 200 metros, se observa una tendencia en la que los nadadores parecen reservar parte de su energía durante las etapas iniciales para maximizar su rendimiento en las finales, donde efectivamente logran disminuir sus tiempos.
Este comportamiento sugiere que es necesario considerar este factor en el análisis.

```{r, echo=FALSE}
rm(datos, porcentajes)
```

# Medidas de rendimiento.

En los modelos que vamos a calcular a continuación, nuestro objetivo va a ser que, cada vez que digamos que un nadador baja de tiempo, sea cierto, es decir, voy a intentar minimizar el error que se produce cuando predigo que un nadador SÍ baja de tiempo, pero en realidad no lo hace.
Me interesa minimizar los falsos positivos.
Una tabla de contingencia, es una herramienta que permite evaluar el rendimiento de un modelo de clasificación. Esta tabla resume las predicciones del modelo comparándolas con los valores reales y se utiliza principalmente en problemas de clasificación binaria (aunque puede ampliarse a multiclase).


```{r, echo=FALSE}
# Crear la tabla en formato data frame
tabla <- data.frame(
  " " = c("(1)", "(0)"),
  "(1)" = c("Verdaderos Positivos (TP)", "Falsos Negativos (FN)"),
  "(0)" = c("Falsos Positivos (FP)", "Verdaderos Negativos (TN)")
)

# Imprimir la tabla con knitr::kable
knitr::kable(tabla, format = "markdown", align = "c", col.names = c("", "(1)", "(0)"))

```



- TP (Verdaderos Positivos): Casos positivos correctamente predichos por el modelo.
- FN (Falsos Negativos): Casos positivos que el modelo clasificó incorrectamente como negativos.
- FP (Falsos Positivos): Casos negativos que el modelo clasificó incorrectamente como positivos.
- TN (Verdaderos Negativos): Casos negativos correctamente predichos por el modelo.

Por tanto, utilizaremos distintos modelos y evaluaremos su calidad mediante medidas de rendimiento que parten de la matriz de confusión, ya que nuestra variable objetivo es binaria (0,1).

Comentaremos las principales métricas de rendimiento, haciendo mayor hincapié en las siguientes:

-   Accuracy o Exactitud $= \frac{TP + TN}{N}$. Mide la proporción de predicciones correctas hechas por un modelo de clasificación. Es uno de los indicadores más utilizados para evaluar el desempeño de un modelo de clasificación. Intentaremos maximizar este valor.
-   FPR (tasa de falsos positivos) $= \frac{FP}{FP+TN}$ Intentaremos minimizar este valor ya que mide la proporción de negativos reales que el modelo clasifica incorrectamente como positivos.

# Modelos K-Vecinos.

El método de los k vecinos más cercanos (abreviatura de “k nearest neighbors” en inglés), se cuenta entre los enfoques más simples y ampliamente utilizados en el campo del Machine Learning. Su simplicidad conceptual y eficacia en problemas de clasificación y regresión lo convierten en una herramienta fundamental en análisis predictivo.
El k-NN se basa en la noción de similitud entre observaciones, donde se mide la distancia entre los puntos de datos en el espacio multidimensional. La idea central es que los puntos cercanos en el espacio de características  son similares y, por lo tanto, deben compartir la misma etiqueta de clase.

En un problema de clasificación, el algoritmo asigna a una observación desconocida (nuevo dato) la clase predominante entre sus k vecinos más cercanos. La distancia entre un punto de prueba y todos los puntos del conjunto de entrenamiento se calcula utilizando una métrica de distancia, como:  

 **Distancia Euclídea**:  
     \[
     d(p, q) = \sqrt{\sum_{i=1}^n (p_i - q_i)^2}
     \]  

 **Distancia Manhattan**:  
     \[
     d(p, q) = \sum_{i=1}^n |p_i - q_i|
     \]  

 **Distancia de Gower** para datos mixtos (numéricos y categóricos). 

El parámetro *k* es crucial para el rendimiento del modelo:  
   - Un valor de **k pequeño** puede llevar a un modelo **sensible al ruido** y con riesgo de sobreajuste.  
   - Un valor de **k grande** suaviza las predicciones, pero puede perder patrones locales importantes.  

Para elegir el valor óptimo de *k*, se utiliza **validación cruzada**.

En nuestro caso, el objetivo es **predecir si un nadador mejora su tiempo** en la final respecto a las preliminares. Las principales consideraciones fueron:  

- Se seleccionaron variables continuas para el análisis.  
- Se seleccionaron variables relevantes (continuas) para el análisis. 
- Se implementaron distancias sobre las variables (relevantes y continuas) para el análisis. 


## Modelo 1.

En este modelo, seleccionaremos todas las variables continuas disponibles y las escalaremos para que tengan una contribución equitativa en el cálculo de la distancia. Utilizaremos la distancia Euclídea como métrica para determinar los vecinos más cercanos.
La distancia Euclídea entre dos puntos \( p \) y \( q \) en un espacio n-dimensional se define como:

\[
d(p, q) = \sqrt{\sum_{i=1}^n (p_i - q_i)^2}
\]

Donde \( p_i \) y \( q_i \) son las coordenadas de los puntos \( p \) y \( q \).


```{r}
# Elegimos todas las variables continuas.
df <- datos2015Target_train %>% select(target, reactiontimeF, edad, pointP, reactiontimeP, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)

#Entrenamos el modelo. 
modelo1knn = knn3(scale(df[,-1]), as.factor(df$target), k=3, prob=TRUE)

```

Una vez entrenado, evaluaremos el modelo en el conjunto de entrenamiento calculando la matriz de confusión y las métricas de rendimiento.
En función de los resultados, evaluaremos si este modelo logra un buen equilibrio entre sensibilidad y especificidad, o si es necesario ajustar parámetros como el número de vecinos k o la selección de variables.

```{r}
predicciones <- predict(modelo1knn, newdata = scale(df[,-1]), type = "class")
matrizconfusion1 <- confusionMatrix(predicciones, as.factor(df$target), positive = "1")
print(matrizconfusion1)
```
El modelo muestra buen rendimiento para los positivos (bajar de tiempo), pero su rendimiento en la clase negativa es bajo.
Dado nuestro objetivo de minimizar los falsos positivos, este modelo no cumple los requisitos necesarios.
Por lo tanto, podemos concluir con que el modelo falla demasiado en nuestros datos de entrenamiento. Luego, no va a ser un buen modelo. Nos servirá como modelo base para intentar encontrar uno mejor. 


```{r}
rm(predicciones, matrizconfusion1, df)
```

## Modelo 2. 

Para mejorar el rendimiento del modelo y evitar el ruido generado por variables irrelevantes, realizamos una selección de las variables más importantes que deberían incluirse en el modelo. Esta selección permitirá identificar las características más relevantes que determinan si un nadador baja de tiempo o no.

Para ello, volvemos a cargar todas las variables categóricas: 

```{r}
df <- datos2015Target_train %>% select(target, reactiontimeF, edad, pointP, reactiontimeP, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)

df_test<- datos2015Target_test %>% select(target, reactiontimeF, edad, pointP, reactiontimeP, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)

```

Para refinar aún más nuestro modelo KNN, implementaremos un procedimiento de Eliminación Recursiva de Características (RFE). Este método, utilizando validación cruzada, seleccionará las características más relevantes que optimizan el rendimiento del modelo, reduciendo el impacto del ruido de variables irrelevantes.

El RFE seleccionará las variables más influyentes para predecir el objetivo (target). Los resultados incluirán, tanto la lista de las mejores variables seleccionadas, como las métricas de rendimiento asociadas con cada tamaño de subconjunto.

```{r}
x <- scale(df[,-1])
y <- df$target  # Variable objetivo

# Crear un objeto de control para el entrenamiento
ctrl <- rfeControl(functions=rfFuncs, method="cv", number=10)

# Hacer la selección de variables con RFE
result <- rfe(x, y, sizes=c(1:ncol(x)), rfeControl=ctrl)

# Ver los resultados
print(result)
```

```{r}
rm(ctrl, result, x, y)
```


Después de implementar el proceso de selección de características mediante RFE, hemos identificado las variables más relevantes para la predicción del objetivo (target). Estas variables seleccionadas serán utilizadas para ajustar un modelo KNN más eficiente y preciso.
Las variables seleccionadas son swimtimeP,mediaParcialesP,minimoParcialesP, maximoParcialesP y medianaParcialesP.

```{r}
df <- datos2015Target_train %>% select(target, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)

df_test<- datos2015Target_test%>% select(target, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)


#Entreno el modelo. 
modelo2knn = knn3(scale(df[,-1]), as.factor(df$target), k=3, prob=TRUE)
```

Una vez que hemos entrenado el modelo KNN con las variables seleccionadas, es fundamental analizar su rendimiento en el conjunto de datos de entrenamiento (train) para asegurarnos de que el modelo ha capturado correctamente los patrones presentes en los datos.

```{r}
predicciones <- predict(modelo2knn, newdata = scale(df[,-1]), type = "class")
matrizconfusion1 <- confusionMatrix(predicciones, as.factor(df$target), positive = "1")
print(matrizconfusion1)
```
El modelo clasifica correctamente el 78.97% de las observaciones. El modelo clasifica correctamente el 63.86% de los nadadores que no bajan de tiempo.
Vistos los resultados del modelo en el conjunto de entrenamiento, esto nos dará una idea inicial del ajuste del modelo. Sin embargo, lo más importante es cómo se comporta en datos no vistos.

El modelo entrenado es ahora evaluado en el conjunto de prueba (test) para medir su capacidad de generalización y comprobar si puede mantener un rendimiento adecuado fuera del conjunto de entrenamiento.

```{r}
predicciones <- predict(modelo2knn, newdata = scale(df_test[,-1]), type = "class")
matrizconfusion1 <- confusionMatrix(predicciones, as.factor(df_test$target), positive = "1")
print(matrizconfusion1)

```

Dado que el objetivo principal es maximizar el Accuracy y minimizar la tasa de falsos positivos (FPR), evaluemos estas métricas basándonos en los resultados del modelo. 

El modelo clasifica correctamente el 65.31% de los casos en el conjunto de prueba.

```{r}
rm(matrizconfusion1, df, df_test)
```



## Modelo 3 

En este paso, seleccionamos las variables predictoras más relevantes para el modelo basado en K-Vecinos, según los resultados obtenidos en el modelo previo. Estas variables han demostrado ser las más representativas para predecir el target, que indica si un nadador logra mejorar su tiempo en la final. 
Las variables seleccionadas eran:
- swimtimeP
- mediaParcialesP: 
- minimoParcialesP: 
- maximoParcialesP
- medianaParcialesP


```{r}
df <- datos2015Target_train %>% select(target, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)

df_test<- datos2015Target_test%>% select(target, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)

```


Mientras que knn3 entrena un modelo K-Vecinos y lo almacena para futuras predicciones, knn3Train calcula directamente las predicciones sobre un conjunto de prueba proporcionado, basado en los datos de entrenamiento, sin guardar un modelo explícito.

En este ejemplo, utilizamos knn3Train para implementar un modelo KNN con un  escalado de datos y la distancia Manhattan como métrica.

```{r}
#los empleamos escalados
x_train <- as.matrix(scale(df[, -1]))  
x_test <- as.matrix(scale(df_test[, -1]))

dist_train <- proxy::dist(x_train, method = "manhattan")
dist_test <- proxy::dist(x_test, x_train, method = "manhattan")


modelo3knn <- knn3Train(
  train = x_train,
  test = x_test,
  cl = as.factor(df$target),
  k = 3,
  prob = TRUE
)
```

El modelo knn3Train devuelve directamente las predicciones sobre el conjunto de prueba. Las predicciones se pueden usar para construir una matriz de confusión .

```{r}

matriz_confusion <- confusionMatrix(as.factor(modelo3knn), as.factor(df_test$target), positive = "1")

# Mostrar la matriz de confusión y métricas
print(matriz_confusion)
```
El modelo clasifica correctamente aproximadamente el 65% de los casos en el conjunto de prueba. Aunque supera el azar, es similar al modelo basado en la distancia euclidiana.

La FPR es idéntica para ambas distancias (58.33%), indicando que el cambio en la métrica de distancia no mejora la clasificación de negativos reales.


```{r}
#elimino el modelo porque el que me sirve es el modelo 2
rm(df,df_test,dist_train,dist_test,matriz_confusion, x_train,x_test,modelo3knn)
```


## Resumen y decisión

A continuación haremos un resumen de los modelos ajustados.

1.  modelo1KNN:En este modelo se seleccionaron todas las variables continuas disponibles y se escalaron para garantizar que tengan una contribución equitativa en el cálculo de la distancia. Se utilizó la distancia Euclídea como métrica principal para determinar los vecinos más cercanos. A pesar de las limitaciones, este modelo será la base para explorar mejoras, como la selección de variables relevantes, la optimización del número k, o el uso de métricas de distancia alternativas.

2. modelo2KNN: En este modelo, se buscó mejorar el rendimiento del KNN reduciendo el impacto del ruido generado por variables irrelevantes. Para ello, se implementó Eliminación Recursiva de Características con validación cruzada para seleccionar las variables más importantes, se utilizó la distancia Euclídea como métrica y se escalaron las variables seleccionadas para asegurar contribuciones equitativas. Aunque el modelo mejora en comparación con la versión inicial al seleccionar variables relevantes, todavía tiene dificultades para generalizar bien en datos no vistos, particularmente en la clase negativa.

3. modelo3KNN: En este modelo, se seleccionaron las mismas variables relevantes identificadas en el Modelo 2. El objetivo principal fue evaluar el impacto de utilizar la distancia Manhattan como métrica en lugar de la distancia Euclídea.
La distancia Manhattan no mejora el rendimiento respecto a la distancia Euclídea en este contexto.

Basándome en el resumen anterior que se presentó, tenemos 2 modelos principales (modelo1knn y modelo2knn)

```{r}
df_test1 <- datos2015Target_test %>% select(target, reactiontimeF, edad, pointP, reactiontimeP, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)

df_test2<- datos2015Target_test%>% select(target, swimtimeP, mediaParcialesP, minimoParcialesP, maximoParcialesP, medianaParcialesP)

```

La curva ROC mide la sensibilidad (tasa de verdaderos positivos) frente a la especificidad (1 - tasa de falsos positivos).

Ambas curvas parecen similares y están relativamente cerca de la diagonal (línea gris), lo que sugiere un desempeño moderado para ambos modelos.

```{r}
probs_knn1 <- predict(modelo1knn, newdata = df_test1[,-1], type = "prob")[, 2]

probs_knn2<- predict(modelo2knn, newdata = df_test2[,-1], type = "prob")[, 2]


#Generar las curvas ROC para cada modelo
roc_knn1 <- roc(df_test1$target, probs_knn1)
roc_knn2<- roc(df_test2$target, probs_knn2)

#mirar los dataframes. 

# Calcular el AUC para cada modelo
auc_knn1 <- auc(roc_knn1)
auc_knn2<- auc(roc_knn2)

#auc_knn_es_3 <- auc(roc_knn_es_3)
#auc_knn_selected <- auc(roc_knn_selected)

# Imprimir los valores de AUC
cat("AUC KNN modelo 1", auc_knn1, "\n")
cat("AUC KNN modelo 2:", auc_knn2, "\n")


#cat("AUC KNN sin escalar k=3:", auc_knn_es_3, "\n")
#cat("AUC KNN con variables seleccionadas:", auc_knn_selected, "\n")

# Graficar las curvas ROC
plot(roc_knn1, col = "blue", lwd = 2, main = "Comparación de Curvas ROC para Modelos KNN")
lines(roc_knn2, col = "red", lwd = 2)

#lines(roc_knn_es_3, col = "green", lwd = 2)
#lines(roc_knn_selected, col = "purple", lwd = 2)

abline(a = 0, b = 1, col = "gray", lty = 2)

legend("bottomright", legend = c("KNN modelo 1", "KNN modelo2"),
       col = c("blue", "red", "green", "purple"), lwd = 2, cex = 0.5) 
```

El modelo 2 tiene una ligera ventaja en términos de capacidad discriminativa, ya que su AUC está por encima de 0.5, lo que indica que puede distinguir mejor entre nadadores que bajan y no bajan de tiempo. En contraste, el modelo 1 (AUC ~ 0.4983) está prácticamente en el azar (similar a tirar una moneda al aire).

Aunque el AUC del modelo 2 es superior, un valor de 0.5275 sigue siendo bajo. Esto sugiere que ambos modelos tienen un desempeño moderado y que todavía hay espacio para mejorar, ya sea ajustando hiperparámetros (k), probando otras distancias (como Gower), o incluyendo nuevas variables predictoras.

```{r}
rm(auc_knn1,auc_knn2,roc_knn1,roc_knn2,df_test1,df_test2)
```

Mantenemos el modelo 2 como el mejor hasta ahora, ya que tiene un AUC superior.

# Árboles de decisión

Los árboles de decisión son un modelo de aprendizaje supervisado ampliamente utilizado debido a su capacidad de manejar tanto variables categóricas como numéricas, su facilidad de interpretación y su robustez frente a datos no escalados.
Estos algoritmos seleccionan secuencialmente las características más informativas (ganancia de información o reducción de entropía) para predecir una variable objetivo, dividiendo los datos en ramas basadas en dichas características.

En este análisis, implementamos un árbol de decisión para predecir si un nadador mejorará su tiempo en la final (target).

## Modelo 1.

En este modelo inicial:

- Se utilizan todas las variables disponibles para el modelo.
- La variable code (país) se sustituye por el continente, con el objetivo de reducir la granularidad y mejorar la generalización.
- La variable daytimeP se reemplaza por una variable categórica que indique si la sesión fue matinal o vespertina.

Primero, realizamos los cambios necesarios en las variables y seleccionamos las que serán usadas en el modelo:

```{r}
df_arbol <- datos2015Target_train %>% select(target, distance, stroke, gender, continente ,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, sesionP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)
df_test_arbol <- datos2015Target_test %>% select(target, distance, stroke, gender, continente,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, sesionP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)


## Además, defino mi variable distancia como categórica.
df_arbol$distance<- as.factor(df_arbol$distance)
df_test_arbol$distance<- as.factor(df_test_arbol$distance)
```

A continuación, ajustamos el primer árbol de decisión utilizando todas las variables seleccionadas:

```{r}
arbol1 <- rpart(target~., data = df_arbol, method = 'class')
rpart.plot(arbol1, extra = 1)
arbol1
```
El árbol clasifica 195 observaciones en base a las variables seleccionadas. La variable swimtime es la primera variable utilizada para dividir, lo que indica su importancia clave. Los nadadores con tiempos menores a 106.15 segundos son más propensos a no bajar su tiempo (clase 0). La medianaParcialesP, se utiliza en varios nodos secundarios, mostrando que afecta la clasificación tanto en clases 0 como 1. laneP y laneF, los carriles en preliminares y finales, tienen un impacto notable en las probabilidades de clasificación. El continente es introducido en un nodo profundo, sugiriendo que su efecto es menor comparado con otras variables.

Primero, evaluamos el modelo en el conjunto de entrenamiento para entender su desempeño inicial.

```{r}
prediction <- predict(arbol1, df_arbol, type = 'class')
cf_train <- confusionMatrix(prediction, as.factor(df_arbol$target),positive="1",
                      mode = 'everything')

cf_train
```

Nuestro árbol inicial presenta buenos resultados, con una precisión (Accuracy) del 81.1%, lo cual se considera un desempeño notable.

El modelo muestra un buen ajuste en los datos de entrenamiento, con alta sensibilidad y precisión. Sin embargo, puede ser debido al sobreajuste. Esto deberá confirmarse evaluando el modelo en el conjunto de prueba:

```{r}
prediction <- predict(arbol1, df_test_arbol, type = 'class')
cf_test <- confusionMatrix(prediction, as.factor(df_test_arbol$target),positive="1",
                      mode = 'everything')

cf_test
```

Al evaluar el modelo en el conjunto de prueba, los resultados reflejan un desempeño significativamente inferior al observado en el entrenamiento. Esto sugiere una posible falta de generalización, especialmente en términos de exactitud y especificidad. El alto número de falsos positivos sugiere que el modelo tiene dificultades para diferenciar correctamente entre nadadores que bajan y no bajan su tiempo.

```{r, warning=FALSE}
rm(df_arbol, df_test_arbol, cf_test, cf_train, prediction)
```

## Modelo 2.

La función utilizada para generar el árbol en el modelo anterior incluye valores predeterminados que no se ajustan completamente a las necesidades de este análisis, por lo que será necesario personalizarlos.

En este modelo, ajustamos la estructura del árbol de decisión modificando los parámetros predeterminados con la función rpart.control. Esto nos permite controlar aspectos clave del árbol, como el número mínimo de observaciones necesarias para dividir un nodo, el tamaño mínimo de un nodo terminal, la profundidad máxima del árbol y el parámetro de complejidad (cp).


Para este modelo, utilizamos un conjunto de variables relevantes que combinan datos categóricos y continuos:

```{r}
df_arbol <- datos2015Target_train %>% select(target, distance, stroke, gender, continente ,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, sesionP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)
df_test_arbol <- datos2015Target_test %>% select(target, distance, stroke, gender, continente,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, sesionP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)


## Además, defino mi variable distancia como categórica.
df_arbol$distance<- as.factor(df_arbol$distance)
df_test_arbol$distance<- as.factor(df_test_arbol$distance)
```

Se emplean los siguientes parámetros de control:
```{r}
control_tree <- rpart.control(minsplit = 4,
                         minbucket = 2,
                         maxdepth = 5,
                         cp = 0)
```

El árbol se entrena utilizando las variables seleccionadas y el control previamente configurado:

```{r}
# Entrenar el árbol de decisión
arbol2 <- rpart(target ~ ., data = df_arbol, method = "class", control = control_tree)

```

Para interpretar fácilmente las divisiones y decisiones del modelo, podemos graficar el árbol generado:

```{r}
# Modificar las etiquetas con salto de línea
rpart.plot(arbol2, 
           type = 1, 
           extra = 104, 
           branch=1,
           space=0.5,
           under = TRUE, 
           cex = 0.3, 
           box.palette = "Blues", 
           tweak = 1.5,
           fallen.leaves = TRUE, 
           main = "Árbol de Decisión")

```

Cada hoja (nodo final) indica una predicción (0 o 1), con precisión y porcentaje de datos representados.

A continuación, procedemos a realizar las predicciones correspondientes en nuestros conjuntos de datos tanto de train como de test.

Comenzamos en train:

```{r}
# Predicciones en el conjunto de entrenamiento
pred_train <- predict(arbol2, newdata = df_arbol, type = "class")
cf_train <- confusionMatrix(pred_train, as.factor(df_arbol$target),positive="1",
                      mode = 'everything')
cf_train
```


En general, el modelo muestra un buen rendimiento: la precisión (87.69%) es bastante alta, lo que indica que la mayoría de las predicciones son correctas.
La sensibilidad (95.54%) es excelente, lo que significa que el modelo es muy eficaz para identificar correctamente los casos positivos (en este caso, los nadadores que bajan de tiempo).
La especificidad (77.11%) también es razonable, indicando que el modelo es relativamente bueno para identificar los casos negativos, aunque podría mejorarse.

Lo analizamos con los datos test:

```{r}
pred_test <- predict(arbol2, newdata = df_test_arbol, type = "class")
cf_test <- confusionMatrix(pred_test, as.factor(df_test_arbol$target),positive="1",
                      mode = 'everything')
cf_test
```

El modelo tiene un buen desempeño en el conjunto de entrenamiento, pero tiene un bajo desempeño en datos no vistos, lo que sugiere sobreajuste.
En este caso, tiene un accuracy de 57.14%, lo que indica que el modelo acierta en aproximadamente la mitad de las predicciones y el valor de especificidad es relativamente bajo, lo que indica que el modelo está cometiendo bastantes falsos positivos.

```{r warning=FALSE}
rm(df_arbol, df_test_arbol, cf_test, cf_train, control_tree, pred_test, pred_train)
```


## Modelo 3.

En este modelo, buscamos optimizar el parámetro de complejidad (cp) del árbol de decisión utilizando validación cruzada. Este proceso ayuda a determinar el nivel óptimo de poda, equilibrando la capacidad del modelo para generalizar sin sobreajustar.

Comenzamos con las mismas variables que el modelo anterior:

```{r}
df_arbol <- datos2015Target_train %>% select(target, distance, stroke, gender, continente ,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, sesionP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)
df_test_arbol <- datos2015Target_test %>% select(target, distance, stroke, gender, continente,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, sesionP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)


## Además, defino mi variable distancia como categórica.
df_arbol$distance<- as.factor(df_arbol$distance)
df_test_arbol$distance<- as.factor(df_test_arbol$distance)
```

Se utiliza el conjunto de entrenamiento df_arbol para buscar el mejor valor de cp mediante validación cruzada de 10 particiones.

```{r}
# Validación cruzada para encontrar el mejor cp
set.seed(123)
control <- trainControl(method = "cv", number = 10)  # 10-fold validation
arbol_cv <- train(target ~ ., 
                  data = df_arbol, 
                  method = "rpart", 
                  trControl = control, 
                  tuneLength = 10)   

```

El mejor valor de cp se obtiene automáticamente al ajustar el modelo y se puede visualizar:

```{r}
# Mejor valor de cp
print(arbol_cv$bestTune)
```
Controlar la profundidad del árbol (usando parámetros como maxdepth o cp) es un equivalente funcional a realizar selección de variables. Sin embargo, realizar una selección previa puede ser útil en contextos específicos, especialmente si buscamos comparar resultados entre diferentes modelos o reducir la complejidad del análisis.

Para determinar las características más relevantes en el modelo, analizamos la importancia de las variables. Esto ayuda a identificar aquellas que tienen un impacto significativo en la predicción de la variable objetivo (target).


```{r}
# Importancia de las variables
importancia <- varImp(arbol_cv, scale = TRUE)
print(importancia)
```

A partir de los resultados obtenidos, seleccionamos las variables más importantes, descartando aquellas que tienen una contribución baja al modelo. Esto permite simplificar el modelo y reducir el ruido generado por características irrelevantes.

Con las variables seleccionadas (swimtimeP, stroke, medianaParcialesP), construimos un nuevo árbol utilizando el mejor valor de cp encontrado en el paso anterior:

```{r}
set.seed(123)
arbol4 <- rpart(target ~ ., 
                        data = df_arbol %>% select(swimtimeP, stroke, medianaParcialesP,target), 
                        method = "class", 
                        control = rpart.control(cp = arbol_cv$bestTune$cp))
```

```{r}
# Visualización del árbol reducido
rpart.plot(arbol4, type = 3, extra = 104, under = TRUE, cex = 0.8)

```

En este árbol toma la variable más importante el tiempo de nado en el parcial.
En concreto, es relevante si los nadadores tienen un tiempo mayor o menor de 106 segundos, probablemente indique una división entre las pruebas de larga y baja distancia. Posteriormene divide según las medianas de dichos parciales.
Por último, utiliza nuevamente los tiempos de los parciales.
En resumen, el árbol toma como las variables más influyentes las basadas en los tiempos y sus medianas parciales.

Si tenemos en cuenta el funcionamiento de un árbol de decisión, la selección de variables nos sirve para visualizar que, efectivamente, está eligiendo las más importantes. Es decir, aquellas tales que con su clasificación en las primeras etapas se reduce la entropía, la incertidumbre. El resultado sería el mismo sin la elección pero nos sirve para confirmar nuestros conocimientos previos. 

Evaluamos el modelo en entrenamiento,

```{r}
prediction <- predict(arbol4, df_arbol, type = 'class')
cf_train <- confusionMatrix(prediction, as.factor(df_arbol$target),positive="1",
                      mode = 'everything')

cf_train
```
Este modelo logra un rendimiento equilibrado en el conjunto de entrenamiento, identificando correctamente tanto positivos como negativos.

Y en test:

```{r}
prediction <- predict(arbol4, df_test_arbol, type = 'class')
cf_test <- confusionMatrix(prediction, as.factor(df_test_arbol$target),positive="1",
                      mode = 'everything')

cf_test
```
El Accuracy es de un 59.18%, lo que significa que el modelo clasifica correctamente aproximadamente 6 de cada 10 observaciones.
El modelo muestra una pérdida notable de rendimiento al predecir con los datos de prueba. Esto podría deberse a sobreajuste, donde el modelo aprende demasiado de los patrones específicos del conjunto de entrenamiento y no generaliza bien en datos no vistos.

El balanced accucary es de 58.83%, que es el promedio de la sensibilidad y la especificidad. Muestra que el modelo no está logrando un equilibrio óptimo entre las clases positivas y negativas.

Aunque identifica correctamente los positivos (bajar de tiempo), el modelo tiene problemas significativos con la clasificación de los negativos, generando muchos falsos positivos, lo que no es ideal para nuestro objetivo. Tiene un valor elevado, lo que significa que más de la mitad de los nadadores que realmente no bajan de tiempo fueron clasificados incorrectamente como que sí bajan. Este es un punto débil del modelo.

```{r}
#cambio de nombre
arbol3= arbol4
#no eliminar arbolcv lo uso abajo
rm(arbol4, df_arbol, df_test_arbol, cf_train, cf_test, prediction,importancia,control)
```



## Resumen y decisión.

1. Arbol1: Se entrenó con todas las variables relevantes, reemplazando code (país) por continente y daytimeP por sesion. Utilizó los parámetros por defecto de la función rpart. Aunque el modelo funciona bien en entrenamiento, su bajo rendimiento en prueba revela una falta de capacidad de generalización.

2. Arbol2: Se utilizó la función rpart.control para personalizar la estructura del árbol. El ajuste de los parámetros reduce la complejidad del modelo, pero no logra una mejora significativa en la generalización.

3. Arbol3: Se utilizó validación cruzada (10-fold) para determinar el mejor valor del parámetro cp, reduciendo la complejidad del árbol. Se eliminaron variables de baja importancia para simplificar el modelo. La validación cruzada ayuda a reducir la complejidad del modelo sin comprometer el rendimiento en entrenamiento.

Los tres modelos basados en árboles muestran un rendimiento adecuado en el conjunto de entrenamiento, pero fallan en generalizar bien en el conjunto de prueba, con una precisión en prueba que oscila entre el 55% y el 59%.

El Modelo 2 y el Modelo 3, con ajustes de control y validación cruzada respectivamente, ofrecen mejoras en simplicidad sin sacrificar el rendimiento, pero no resuelven completamente los problemas de sobreajuste.

Si graficamos las medidas de rendimiento en los datos test de los tres modelos anteriores, tenemos: 

```{r}
# Supongamos que tienes las métricas
metricas <- data.frame(
  Modelo = c("Árbol 1", "Árbol 2", "Árbol 3"),
  Precision = c(0.555, 0.571, 0.59),
  Sensibilidad = c(0.68, 0.68, 0.76),
  Especificidad = c(0.41, 0.458, 0.41)
)

# Melt para graficar con ggplot
metricas_melt <- melt(metricas)

ggplot(metricas_melt, aes(x = Modelo, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Comparación de Métricas entre Modelos", x = "Modelo", y = "Valor") +
  theme_minimal()

```

# Métodos de ensamblado.

Los métodos de ensamblado son técnicas avanzadas de aprendizaje automático que combinan múltiples modelos base para mejorar la precisión, la robustez y la generalización de las predicciones.
El objetivo principal de estos métodos es reducir el error del modelo base mediante la integración de varios predictores, lo que permite capturar diferentes patrones en los datos.

## Bagging.

Bagging es un método de ensamblado paralelo que busca reducir la varianza de los modelos base, mejorando la precisión general de las predicciones.
Este enfoque es particularmente útil en algoritmos inestables, como árboles de decisión, que pueden producir modelos muy diferentes con ligeros cambios en los datos de entrenamiento.

### Modelo 1.

En este paso, utilizaremos el modelo 3 basado en árboles de decisión como modelo base para implementar un modelo de Bagging. El objetivo es mejorar la generalización y la precisión del modelo al combinar múltiples árboles entrenados en subconjuntos de datos de entrenamiento.

Primero, seleccionamos las variables relevantes para el análisis y aseguramos que las variables categóricas se traten adecuadamente.

```{r}
df_arbol <- datos2015Target_train %>% select(target, distance, stroke, gender, name,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)
df_test_arbol <- datos2015Target_test %>% select(target, distance, stroke, gender, name,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)

## Además, defino mi variable distancia como categórica.
df_arbol$distance<- as.factor(df_arbol$distance)
df_test_arbol$distance<- as.factor(df_test_arbol$distance)
```

En este caso, utilizaremos la función bagging de la librería ipred para entrenar un modelo de Bagging basado en árboles de decisión. El objetivo es mejorar el rendimiento del modelo base:

```{r}
# Bagging
modeloBagging1 <- bagging(target ~., data=df_arbol, coob=TRUE,nbagg=50,
               rpart= rpart.control(minsplit = 4,
                             minbucket = 2,
                             maxdepth = 1,
                             cp = 0))

```

Una vez entrenado el modelo de Bagging, evaluamos su desempeño en el conjunto de entrenamiento utilizando la función predict para obtener las probabilidades de cada clase. Luego, transformamos estas probabilidades en predicciones binarias (0 o 1) con un umbral del 50%. Finalmente, calculamos la matriz de confusión y otras métricas.

```{r}
pred_bag_train <- predict(modeloBagging1, df_arbol,type="prob")[,2]
clase.pred.bag.train=ifelse(pred_bag_train>0.5,"1","0")
cf_bag_train <- confusionMatrix(as.factor(clase.pred.bag.train), as.factor(df_arbol$target))

cf_bag_train
```

El modelo de Bagging ha logrado un rendimiento perfecto en el conjunto de entrenamiento. Esto sugiere que el modelo ha aprendido todos los patrones presentes en los datos de entrenamiento. Sin embargo, un desempeño perfecto en este conjunto puede ser una señal de sobreajuste.

El siguiente paso será evaluar el modelo en el conjunto de prueba para determinar si estas métricas se mantienen o si el modelo ha perdido su capacidad de generalización.

```{r}
pred_bag_test <- predict(modeloBagging1, df_test_arbol,type="prob")[,2]
clase.pred.bag.test=ifelse(pred_bag_test>0.5,"1","0")
cf_bag_test <- confusionMatrix(as.factor(clase.pred.bag.test), as.factor(df_test_arbol$target))

cf_bag_test
```

Aunque el modelo de Bagging tiene un buen desempeño en la identificación de nadadores que bajan su tiempo (sensibilidad alta), su capacidad para clasificar correctamente los nadadores que no bajan su tiempo es limitada (especificidad baja). Esto sugiere que el modelo tiende a clasificar como positivos a muchos casos que en realidad son negativos, lo que se refleja en una alta Tasa de Falsos Positivos.

El marcado contraste entre el rendimiento perfecto en el conjunto de entrenamiento y el bajo rendimiento en el conjunto de prueba confirma que el modelo sufre de sobreajuste. Este problema podría abordarse ajustando los hiperparámetros del modelo, reduciendo la complejidad de los árboles base, o aumentando la cantidad de datos disponibles para el entrenamiento.

```{r}
rm(cf_bag_train, cf_bag_test)
```

### Modelo 2.

Una vez definidos los árboles, entrenamos un nuevo modelo de Bagging con ajustes en los hiperparámetros. Este ajuste busca mejorar la generalización del modelo, manteniendo un balance adecuado entre sensibilidad y especificidad.

```{r}
# Bagging
modeloBagging2 <- bagging(target ~., data=df_arbol, coob=TRUE,nbagg=20,
               rpart= rpart.control(minsplit = 6,
                             maxdepth = 5,
                             cp = 0.8))

```

Vemos ahora sus predicciones en train y su matriz de confusión,

```{r}
pred_bag_train <- predict(modeloBagging2, df_arbol,type="prob")[,2]
clase.pred.bag.train=ifelse(pred_bag_train>0.5,"1","0")
cf_bag_train <- confusionMatrix(as.factor(clase.pred.bag.train), as.factor(df_arbol$target),positive="1")

cf_bag_train
```

Estos resultados son típicos de un modelo sobreajustado, ya que logra una precisión perfecta en el conjunto de entrenamiento pero probablemente no generaliza bien en datos de prueba. Para validar el modelo, es esencial evaluar su rendimiento en el conjunto de prueba, donde se podría observar una caída significativa en la precisión y otras métricas, lo que confirmaría el sobreajuste.

```{r}
pred_bag_test <- predict(modeloBagging2, df_test_arbol,type="prob")[,2]
clase.pred.bag.test=ifelse(pred_bag_test>0.5,"1","0")
cf_bag_test <- confusionMatrix(as.factor(clase.pred.bag.test), as.factor(df_test_arbol$target),positive="1")

cf_bag_test
```
El modelo muestra un claro sobreajuste. Si bien funciona perfectamente en el conjunto de entrenamiento, su rendimiento en el conjunto de prueba es malo, lo que sugiere que no puede generalizar bien. Eso si, se comporta ligeramente mejor que en el caso anterior.

```{r}
rm(cf_bag_train, cf_bag_test)
```


### Modelo 3.

En este modelo, emplearemos el mismo conjunto de parámetros utilizados en el árbol 3, el cual demostró ser el más prometedor entre los modelos basados en árboles de decisión. Además, repetiremos la selección de variables realizada en ese modelo.

```{r}
# Bagging
set.seed(123)
modeloBagging3 <- bagging(target ~., df_arbol %>% select(swimtimeP, stroke, medianaParcialesP,target), coob=TRUE,nbagg=25,
               rpar=rpart.control(cp = arbol_cv$bestTune$cp))


```

Este modelo debería proporcionar una mejora en la capacidad de generalización debido al ajuste fino del parámetro de complejidad (cp) y la reducción de ruido gracias a la selección de variables clave. Una comparación entre las métricas de los conjuntos de entrenamiento y prueba determinará si el modelo logra un buen equilibrio entre sensibilidad y especificidad, minimizando los falsos positivos.

```{r}
pred_bag_train <- predict(modeloBagging3, df_arbol,type="prob")[,2]
clase.pred.bag.train=ifelse(pred_bag_train>0.5,"1","0")
cf_bag_train <- confusionMatrix(as.factor(clase.pred.bag.train), as.factor(df_arbol$target),positive="1")

cf_bag_train
```

Vemos cómo se comporta el modelo en los datos test:

```{r}
pred_bag_test <- predict(modeloBagging3, df_test_arbol,type="prob")[,2]
clase.pred.bag.test=ifelse(pred_bag_test>0.5,"1","0")
cf_bag_test <- confusionMatrix(as.factor(clase.pred.bag.test), as.factor(df_test_arbol$target),positive="1")

cf_bag_test
```
Esto indica que el modelo clasifica correctamente el 63.27% de los casos en el conjunto de prueba, lo cual es una mejora respecto a algunos de los modelos previos.
La especificidad relativamente baja (45.83%) implica que el modelo no clasifica correctamente a muchos nadadores que no bajan de tiempo, lo que podría llevar a falsos positivos.

En cualquier caso, es un modelo con mejora.

```{r}
rm(cf_bag_train, cf_bag_test)
```


### Modelo 4.

En este apartado, vamos a realizar un bagging sobre nuestro mejor modelo knn para ver si logra mejorar.

Voy a meter exactamente los mismos parámetros de control que empleábamos en el modeloknn2. Además, recordamos que hacíamos selección de variables.

La función bagging de la librería ipred está diseñada principalmente para modelos como árboles de decisión y regresión logística.  KNN no está directamente soportadopara el bagging en esta función. Esto se debe a que KNN es un modelo basado en instancias y no un modelo paramétrico que pueda ser "entrenado" explícitamente en un subconjunto de datos.

(hay que hacerlo manualmente, hacer si hay tiempo)



Conclusion Bagging:Modelo 3 candidato


### Resumen y decision.

# Random Forest 
Un Bosque Aleatorio es una potente técnica de ensamblado que utiliza un conjunto de DTs para mejorar la precisión de las predicciones.
En lugar de confiar en un solo árbol, se construye un bosque compuesto por numerosos árboles individuales.
La singularidad de un Bosque Aleatorio radica en cómo se crean y combinan estos árboles.

Cada árbol dentro del Bosque Aleatorio no se crea a partir de todo el conjunto de datos, sino que se entrena con un subconjunto aleatorio de variables y un conjunto de observaciones seleccionadas al azar.
Este proceso de muestreo aleatorio introduce diversidad en la construcción de cada árbol, lo que ayuda a mitigar la tendencia de DT a sobreajustar los datos.

Cada árbol individual en el Bosque Aleatorio genera una predicción para la variable objetivo, pero no se espera que cada árbol sea altamente efectivo por sí solo.
La fortaleza del método radica en la combinación de numerosos árboles, cada uno de los cuales opera en una región diferente del espacio de características.
El Bosque Aleatorio se basa en una regla de decisión que cuenta los votos de cada árbol para determinar la predicción final.
En teoría, un gran número de modelos relativamente no correlacionados que funcionan como un comité superarán a cualquier modelo individual.

### Modelo 1
```{r}
df_random <- datos2015Target_train %>% select(target, distance, stroke, gender,continente, heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)
df_test_random <- datos2015Target_test %>% select(target, distance, stroke, gender, continente,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)

## Además, defino mi variable distancia como categórica.
df_random$distance<- as.factor(df_random$distance)
df_test_random$distance<- as.factor(df_test_random$distance)

str(df_random)
```

```{r}
set.seed(123)
rf1 <- randomForest(
  target ~ ., 
  data = df_random, 
  importance = TRUE, 
  proximity = TRUE,
  ntree = 20, 
  mtry = 6
)
```

```{r}
# Graficar el error
plot(rf1)
legend("right", colnames(rf1$err.rate), lty = 1:5, col = 1:6)

```
(Parece que en 50 se establece, lo pongo pruebo y parece que con 10 va bien)

```{r}
library(caret)
# Predicción en el conjunto de entrenamiento
pred_rf_train <- predict(rf1, df_random, type = "prob")[, 2]  
clase_pred_rf_train <- ifelse(pred_rf_train > 0.5, "1", "0")  
cf_rf_train <- confusionMatrix(as.factor(clase_pred_rf_train), as.factor(df_random$target), positive = "1")

# prueba

pred_rf_test <- predict(rf1, df_test_random, type = "prob")[, 2] 
clase_pred_rf_test <- ifelse(pred_rf_test > 0.5, "1","0")   

cf_rf_test <- confusionMatrix(as.factor(clase_pred_rf_test), as.factor(df_test_random$target), positive = "1")
print(cf_rf_test)


```

```{r}

# Importancia de las variables
var_importance <- importance(rf1)
print(var_importance)
varImpPlot(rf1)

```
```{r}
rm(var_importance,pred_rf_train, clase_pred_rf_train,cf_rf_train,pred_rf_test,clase_pred_rf_test ,cf_rf_test)
```

## Modelo 2
ESTO ES UN INTENTO DE ENCONTRAR UN MEJOR RANDOM FOREST PERO REALMENTE ESTA MAL PLANTEADO. DEBIDO A LA NATURALEZA DEL RANDOM DEBERIAMOS CONSEGUIR UNO CON MEJOR RENDIMIENTO(INTENTARLO :( )

Realmente con un buen Random hemos ganado y te realiza seleccion, pero realizo selección de variables manual por si algún casual mejora

```{r}
set.seed(213)
rf2 <- randomForest(
  target ~ ., 
  data = df_random %>% select(laneP,swimtimeP,daytimeP,maximoParcialesP,target), 
  importance = TRUE, 
  proximity = TRUE,
  ntree = 20, 
  mtry = 6
)
```

```{r}
# Graficar el error
plot(rf2)
legend("right", colnames(rf1$err.rate), lty = 1:5, col = 1:6)

```
```{r}
# Predicción en el conjunto de entrenamiento
pred_rf_train <- predict(rf2, df_random, type = "prob")[, 2]  
clase_pred_rf_train <- ifelse(pred_rf_train > 0.5, "1", "0")  
cf_rf_train <- confusionMatrix(as.factor(clase_pred_rf_train), as.factor(df_random$target), positive = "1")
print(cf_rf_train)
# prueba

pred_rf_test <- predict(rf2, df_test_random, type = "prob")[, 2] 
clase_pred_rf_test <- ifelse(pred_rf_test > 0.5, "1","0")   

cf_rf_test <- confusionMatrix(as.factor(clase_pred_rf_test), as.factor(df_test_random$target), positive = "1")
print(cf_rf_test)


```

```{r}
rm(pred_rf_train, clase_pred_rf_train,cf_rf_train,pred_rf_test,clase_pred_rf_test ,cf_rf_test)

#rm(df_random,df_test_random) #lo uso en contrafacticos y shap
```


#Modelo 3 Random Forest.
Con el objetivo de mejorar nuestro modelo de Random Forest, realizaremos algunas modificaciones: 

- Estandarizar los datos. Aunque Random Forest no suele ser tan sensible a la escala de las variables como otros modelos (como KNN por ejemplo), a veces normalizar o estandarizar las variables puede mejorar el rendimiento,
- Ajustar parámetros como ntree, mtry y nodesize.

  * ntree: número de árboles en el bosque. Cuantos más árboles haya, mejor será la estabilidad y precisión del modelo, pero también aumentará el tiempo de cómputo. Aumentamos en este modelo el valor, ya que lo teníamos en 20.
  * mtry: número de variables aleatorias que se consideran para cada división en un árbol. Un valor demasiado bajo puede subajustar, mientras que un valor demasiado alto puede hacer que los árboles se sobreajusten. Usualmente se toma el valor de la raiz cuadrada del número de predictores. En este modelo, se probarán distintos valores y se establecerá el mejor de ellos. Los valores irán de 3 a 9, rangos lógicos para este problema. 
  * nodesize: número mínimo de observaciones en cada nodo terminal de un árbol. Un valor bajo puede llevar a árboles más complejos, pero también puede resultar en sobreajuste.El valor por dfecto es 1, con lo que aumentaremos dicho valor en búsqueda de unos resultados mejores. 

- Utilizar la validación cruzada para obtener predicciones más robustas y evitar el sobreajuste.

```{r}

set.seed(123)
#Tomo el dataframe necesario
df_random <- datos2015Target_train %>% select(target, distance, stroke, gender,continente, heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)

df_test_random <- datos2015Target_test %>% select(target, distance, stroke, gender, continente,heatF, laneF, edad, heatP, laneP, pointP, reactiontimeP, swimtimeP, daytimeP, mediaParcialesP, medianaParcialesP, maximoParcialesP, minimoParcialesP)

## Además, defino mi variable distancia como categórica.
df_random$distance<- as.factor(df_random$distance)
df_test_random$distance<- as.factor(df_test_random$distance)

#Estandarizo
preProc <- preProcess(df_random[, -which(names(df_random) == "target","distance")], 
                      method = c("center", "scale"))

# Aplicar la estandarización a los datos
df_random_std <- predict(preProc, df_random)


# Crear control de validación cruzada (10 pliegues)
train_control <- trainControl(method = "cv", 
                              number = 10,  
                              search = "grid",  # Usar búsqueda en cuadrícula
                              savePredictions = "final")


# Búsqueda para el parámetro mtry (número de predictores por división)
tune_grid <- expand.grid(.mtry = c(3,4, 5,6, 7,8, 9))  

# Ajustar el modelo Random Forest usando validación cruzada y búsqueda de parámetros
rf_model <- randomForest(
  target ~ .,                 
  data = df_random_std,       
  method = "rf", 
  metric="Spec",    # Optimizar la especificidad
  trControl = train_control, 
  tuneGrid = tune_grid, # Búsqueda para mtry
  ntree = 200          # Número de árboles en el modelo
)


plot(rf_model)

```
```{r}
# Asegurar que target sea un factor en ambos conjuntos de datos
df_random$target <- as.factor(df_random$target)
df_test_random$target <- as.factor(df_test_random$target)

# Predicción en el conjunto de entrenamiento
pred_rf_train <- predict(rf_model, df_random, type = "prob")[, 2]
clase_pred_rf_train <- factor(ifelse(pred_rf_train > 0.7, "1", "0"), levels = c("0", "1"))

# Matriz de confusión para el conjunto de entrenamiento
cf_rf_train <- caret::confusionMatrix(clase_pred_rf_train, df_random$target, positive= "1")
print(cf_rf_train)

# Predicción en el conjunto de prueba
pred_rf_test <- predict(rf_model, df_test_random, type = "prob")[, 2]
clase_pred_rf_test <- factor(ifelse(pred_rf_test > 0.5, "1", "0"), levels = c("0", "1"))

# Matriz de confusión para el conjunto de prueba
cf_rf_test <- caret::confusionMatrix(clase_pred_rf_test, df_test_random$target,positive="1")
print(cf_rf_test)

```

Tenemos una precisión en torno al 53%. Sin embargo, si nuestro objetivo es minimizar los falsos positivos este es el mejor modelo. Teniendo como criterio de medida la especificidad, obtenemos un 91% en los datos de test. 

##Conclusiones del Random Forest


# Técnica SHAP

La técnica SHAP (SHapley Additive exPlanations) descompone la predicción de un modelo en contribuciones atribuibles a cada característica. Es una técnica de interpretabilidad, que da respuesta al por qué del valor de la predicción de una observación o qué impacto tiene cada caracterísitica en dicha perdicción.
Esta técnica está basada en la teoría de juegos. Se calculan los valores de Shapley, que determinan cuánto contribuye cada característica en un modelo predictivo, considerando todas las combinaciones posibles de características.


Elegimos el modelo de Random Forest que nos dió mejores resultados. Tras esto, creamos un predictor. Este predictor conectará la técnica SHAP con el modelo que hemos elegido, separando la variable objetivo de las explicativas. 

```{r}
# Crear un predictor para el modelo
predictor_rf2 <- Predictor$new(
  model = rf2,
  data = df_random %>% select(laneP, swimtimeP, daytimeP, maximoParcialesP),  # Variables explicativas
  y = df_random$target                                                     # Variable objetivo
)

```

Posteriormente, se calculan los valores SHAP para la primera fila de df_random.

```{r}
# Calcular valores SHAP para una observación específica (primera fila)
shap_rf2 <- Shapley$new(
  predictor = predictor_rf2,
  x.interest = df_random[1, c("laneP", "swimtimeP", "daytimeP", "maximoParcialesP")]
)

# Mostrar los valores SHAP calculados
shap_rf2$results

```
Estima cómo cada característica influye en la predicción del modelo para esta observación.
SHAP evalúa el modelo para todas las combinaciones posibles de variables (introduciéndolas o desechándolas). Luego el método promedia estas contribuciones marginales para determinar el impacto de cada característica.


```{r}
# Gráfico de contribuciones SHAP
plot(shap_rf2)

```
Representando los resultados para la primera fila tenemos que las variables que influyen en la bajada de tiempos es predominantemente el tiempo máximo de los parciales. En segundo y tercer lugar, el tiempo de los parciales y el número de calle. En último lugar, no parece ser muy influyente el tiempo del parcial (la sesión).

Calculamos ahora los valores SHAP para todas las observaciones
```{r}
# Calcular valores SHAP para múltiples observaciones
shap_rf2_global <- FeatureImp$new(predictor_rf2, loss = "ce")

# Gráfico de importancia global basado en SHAP
plot(shap_rf2_global)

```
Vemos como la importancia en el conjunto de datos la obtiene la variable swimtimeP. Es decir, el tiempo de nado de los parciales. 

```{r}
# Calcular valores SHAP para una fila específica del conjunto de prueba
shap_test <- Shapley$new(
  predictor = predictor_rf2,
  x.interest = df_test_random[1, c("laneP", "swimtimeP", "daytimeP", "maximoParcialesP")]
)

# Mostrar resultados en tabla
print(shap_test$results)

# Visualizar resultados para esta observación
plot(shap_test)


```


```{r}
# Calcular valores SHAP para múltiples observaciones
#shap_rf2_global_test <- FeatureImp$new(predictor_rf2, loss = "ce",data = df_test_random)

# Gráfico de importancia global basado en SHAP
#plot(shap_rf2_global_test)

```

```{r}
# Calcular SHAP para las primeras 5 filas del conjunto de prueba
shap_results <- lapply(1:5, function(i) {
  shap <- Shapley$new(
    predictor = predictor_rf2,
    x.interest = df_test_random[i, c("laneP", "swimtimeP", "daytimeP", "maximoParcialesP")]
  )
  return(shap$results)
})

# Combinar resultados en un único data frame
shap_combined <- do.call(rbind, shap_results)
print(shap_combined)


```

(comentario ines: me falta rellenar y lo de los hastaghs q no se q le pasa pero da error, creo q es algo del df pero no se)

# Contrafácticos

El análisis contrafáctico permite explorar cómo los cambios en las variables de entrada afectan las predicciones del modelo. A continuación, se detalla la implementación de este método utilizando el modelo rf1 . Este procedimiento es útil para identificar qué variables tienen mayor influencia en el modelo y cómo se pueden ajustar para obtener un resultado deseado.

### Manera 1

Seleccionamos un registro específico del conjunto de datos para analizarlo:
```{r}
df_random[10,]
```
Esto nos permite ver las características originales de la observación seleccionada. A partir de esta información, realizaremos cambios en las variables relevantes.

```{r}
set.seed(2345)
rf1 <- randomForest(
  target ~ ., 
  data = df_random[-10,], 
  importance = TRUE, 
  proximity = TRUE,
  ntree = 20, 
  mtry = 6
)

# Tenemos que usar iml::Predictor para poner el modelo en el formato adecuado
# type='prob' para tener las probabilidades y no las etiquetas binarizadas
predictor = iml::Predictor$new(rf1, type = "prob") 

# Punto de interés para buscar contrafácticos
x_interest = df_random[10, ]

```

Obtenemos las probabilidades predichas por el modelo para el punto de interés (x_interest). Esto es útil para interpretar cómo el modelo clasifica ese caso particular antes de generar contrafácticos.

```{r}
# Predicción de la probabilidad de cada clase
predictor$predict(x_interest) 

```
Esto significa que el modelo predice un 10% de probabilidad de que el nadador no baje su tiempo.

Esto indica un 90% de probabilidad de que el nadador sí baje su tiempo.

En este caso, el modelo está bastante seguro de que el nadador bajará su tiempo en la final, con una probabilidad alta (90%). Dado que la probabilidad ya está a favor de la clase positiva (1), probablemente no sea necesario generar contrafácticos para modificar esta predicción, ya que el objetivo parece haberse logrado. Igualmente procedemos.

```{r}
head(df_random)
```


El código utiliza el método MOCClassif para determinar los cambios necesarios en las características de un punto de interés (x_interest) para mover su predicción a una clase deseada  con una probabilidad dentro de un rango definido. 

Los fixed_features son variables que no queremos modificar en los contrafácticos. En este caso, continente, edad, y gender están fijas porque podrían ser atributos que no se pueden cambiar.


```{r}
# Ahora estudiamos qué factores  se deben cambiar para que la probabilidad aumente
# Se puede penalizar aquellos individuos que estén más lejos del intervalo deseado que un umbral epsilon.
# Si ponemos epsilon=0 entonces estamos penalizando a todos aquellos individuos cuya predicción está fuera del
# intervalo deseado
# Con fixed_features se fijan las variables que no se pueden mover

# Ponemos las opciones para el algoritmo
moc_classif = MOCClassif$new(
  predictor, epsilon = 0, fixed_features = c("continente", "edad","gender"))
# Sacamos los contrafácticos
cfactuals = moc_classif$find_counterfactuals(
   x_interest, desired_class = "1", desired_prob = c(0.92, 1))


```


Observamos que solo se logra un contrafáctico. 


```{r}
print(cfactuals)

head(cfactuals$predict(), 3)
```
Estos 149 contrafácticos representan combinaciones alternativas de valores en las características (variables explicativas) que, de ser alcanzadas, moverían al caso específico (x_interest) hacia la clase deseada con una probabilidad muy alta.

```{r}
# Filtramos por aquellos que son válidos, es decir, aquellos que tienen la predicción deseada
cfactuals$subset_to_valid()
nrow(cfactuals$data)

head(cfactuals$data,3)
```

```{r}
# Pintamos las variables más importantes para lograr el cambio deseado
# Setting subset_zero = TRUE excludes all unchanged features from the plot.
cfactuals$plot_freq_of_feature_changes(subset_zero = TRUE)

# En azul el punto de interés y en gris los contrafácticos
cfactuals$plot_parallel(feature_names = names(
  cfactuals$get_freq_of_feature_changes()), digits_min_max = 2L)


```
La variable swimtimeP tiene la mayor frecuencia relativa. Esto sugiere que modificar los tiempos de la prueba preliminar (swimtimeP) es clave para mover la predicción hacia la clase deseada (nadadores que bajan su tiempo en la final).

laneF (carril en la final) es la segunda variable más importante. Cambios en esta variable parecen influir significativamente en el resultado.

Recordemos que la variable lane representa el carril asignado al nadador durante la competición (en la preliminar o en la final, según sea laneP o laneF), y vemos que todos los contrafácticos encontrados estan en el carril 7, y la mayoria de ellos con un swimtimeP más alto. Habría que estimar algún valor medio de entre los swimtime para poder indicar al nadador algún posible cambio que suponga una mejora.


```{r}
rm(cfactuals, moc_classif,predictor,x_interest,df_random,df_test_random)
```



Probamos con otro punto de interés, con más opción de mejora o fijando otros valores con más conocimiento(por ejemplo la calle).

### Manera 2
(con knn a mano)

# Conclusiones sobre nuestro mejor modelo.

hacer los contrafácticos y tema 7 en general.

PREGUNTAR A CARMEN CÓMO ELEGIR LA PROBABILIDAD (0.5 O OTRA)

# Curva ROC (Pruebo por ahora como van los modelos, actualizar)

Genero las probabilidades para el conjunto de prueba .

```{r}
# Probabilidades del árbol de decisión
pred_probs_arbol <- predict(arbol, newdata = df_test_arbol, type = "prob")[, 2]  # Probabilidad de clase 1

# Probabilidades del modelo KNN
pred_probs_knn <- predict(knn_best, newdata = df_test_scaled, type = "prob")[, 2]


library(pROC)


# ROC para cada modelo

roc_arbol <- roc(df_test_arbol$target, pred_probs_arbol)
roc_knn <- roc(df_test$target, pred_probs_knn)
roc_randomforest <- roc(df_test$target, pred_rf_test)

#AUC de cada modelo
auc_arbol <- auc(roc_arbol)
auc_knn <- auc(roc_knn)

# Gráfico comparativo de curvas ROC
plot(roc_arbol, col = "blue", lwd = 2, main = "Comparación de Curvas ROC")
lines(roc_knn, col = "red", lwd = 2)
lines(roc_randomforest, col = "green", lwd = 2)
# Añadir una leyenda
legend("bottomright", legend = c("Árbol de Decisión", "KNN","RandomForest"),
       col = c("blue", "red", "green", "purple"), lwd = 2)


```

El AUC es 0.618, lo cual indica que el modelo tiene un rendimiento moderado, pero no particularmente bueno para distinguir entre las clases.

El AUC es 0.582, lo cual sugiere que el modelo KNN tiene un rendimiento ligeramente inferior al del Árbol de Decisión.

Las curvas muestran que ambos modelos tienen un desempeño similar, pero el Árbol de Decisión parece ser marginalmente mejor en ciertos puntos

Ambos valores de AUC son menores a 0.7, lo cual indica que los modelos necesitan mejoras.
Un AUC \> 0.7 se considera aceptable, y \> 0.8 es bueno.
