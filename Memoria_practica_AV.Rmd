---
title: "Mundial de natación de Kazán 2015"
author: "Inés Molinero, Javier Villanueva, Salma Ghailan, Alonso González"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    toc: yes
    toc_float:
      collapsed: true
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Cargamos las librerias que vamos necesitando a lo largo del codigo
library(pastecs)
library(factoextra)
library(dplyr)
library(MASS)
library(rstatix)
library(ggplot2)
library(tidyr)
library(ggimage)
library(countrycode)
library(ggExtra)
library(cluster)
library(purrr)
library(dendextend)

```

# Introducción.

En este proyecto, se analizarán los resultados del **mundial de natación de 2015** con el objetivo de identificar patrones en el desempeño de los nadadores por país y eventos.
Se realizará un análisis exploratorio de datos y se utilizarán técnicas de reducción de dimensionalidad, aprendizaje no supervisado, aprendizaje supervisado, medidas de rendimiento, comparación de modelos y técnicas de Aprendizaje Máquina Explicable

En primer lugar, vemos con qué datos vamos a tratar.
El conjunto de datos consiste en los resultados del Campeonato Mundial de Natación Kazán del año 2015, con los correspondientes datos de cada nadador y prueba.
Los datos han sido extraídos de [Omega](http://www.omegatiming.com/File/Download?id=00010F0200FFFFFFFFFFFFFFFFFFFF08), la plataforma oficial de tiempos de la World Aquatics.
El conjunto de datos contiene información sobre los nadadores (fecha de nacimiento, país, id), y sobre la prueba nadada (tiempo de reacción, parciales, tiempo total, estilo, serie).

Las variables o atributos que conforman el conjunto de datos son:

-   athleteid: id del nadador
-   lastname: Apellidos del nadador
-   firstname: El nombre del nadador
-   birthdate: Fecha de nacimiento del nadador
-   gender: Género del nadador/a
-   name: Nombre del país
-   code: abreviatura del país.
-   eventid: id de la prueba nadada (único)
-   heat: Serie en la que nadaron
-   lane: Calle en la que nadaron (0 a 9)
-   points: puntos FINA que realizaron. (es una "estimación" entre el mejor tiempo o récord del mundo, y el tiempo realizado. )
-   reactiontime: Tiempo de reacción en la salida.
-   swimtime: tiempo tardado
-   split: Parcial
-   cumswimtime: Tiempo acumulado en el parcial
-   splitdistance: Distancia del parcial
-   daytime: hora a la que se nadó
-   round: ronda (preliminar, semifinal, final)
-   distance: distancia de la prueba
-   relaycount: Número de relevista.
-   stroke: Estilo de nado en el que se realizó la prueba.
-   splitswimtime: Tiempo del parcial (50m)

# Entender los datos.

Primeramente, vamos a leer los datos:

```{r}
datos2015<-read.csv("datos/2015_FINA.csv", header=TRUE, sep = ',')
```

Una vez nuestro programa los ha leído, vamos a averiguar el tamaño de los datos con los que vamos a tratar:

```{r}
dim(datos2015)
```

Las dimensiones de la tabla son 11423 filas y 22 variables o columnas.

Veámos la primera ocurrencia de nuestra tabla:

```{r}
head(datos2015,1)
```

Observamos Noel Borshi, nadadora albanesa nacida un 13 de febrero de 1996, que tiene como id el número (100784).
Noel Borshi nadó la prueba 1 en la serie 1 y carril 4.
Nadó el 100m Mariposa en la ronda preliminar con un tiempo final de 63.65s y pasó por el primer parcial (50m) en 29.63 segundos.

# Análisis exploratorio de datos.

## Resumen de los datos.

A continuación, vamos a ver un resumen de los datos:

```{r}
summary(datos2015)

```

De aquí, podemos observar que tenemos algunos valores nulos (NA's), durante toda la competición, que como máximo hubo 12 series y como mínimo 1 y que la piscina disponía de 10 carriles numerados del 0 al 9.
También observamos que se nadaron pruebas de 50 y hasta 1500 metros.

Tenemos variables categóricas las cuales no se ven bien en el resumen anterior, por lo que, usando la librería "dyplr", vamos a convertirlas a variables categóricas en R para tener una mejor visualización de ellas.

```{r}
datos2015<- datos2015 %>% convert_as_factor(gender,name,code,round,heat,lane,stroke, relaycount)

```

Visualicemos ahora de nuevo el resumen:

```{r}
summary(datos2015)
```

Viendo este resumen de los datos podemos comenzar a entender algunas de las variables.

Observamos que las variables name y code toman absolutamente los mismos valores, luego seguramente podamos reducir en una variable el conjunto de datos.
Se trata del país de procedencia de cada nadador.

Vemos que hay 5 ***tipos de nado***: braza, mariposa, crol, espalda y estilos individual.

No hemos guardado la distancia como una variable categórica, pero más adelante veremos que hay 6 distancias (50, 100, 200, 400, 800, 1500)
Hay 5 tipos de ronda distintos.

El menor tiempo de reacción fue de 0.42 y el mayor de 0.97.

Viendo los datos, observamos que cada nadador tiene en una prueba concreta, tantas filas como parciales tenía en esa prueba, luego es obvio que para conocer mejor algunas variables, vamos a necesitar limpiar los datos para que los elementos repetidos no causen interferencia en nuestros datos.



A continuación, vamos a ir realizando estudios para tratar de comprender más a fondo algunas variables.

##  Variable Relaycount. ¿Nos sirve de algo?

Si observamos el resumen de la variable relaycount: 

```{r}
summary(datos2015$relaycount)
```

Observamos que sólo toma un único valor, 1.
Esto se debe principalmente a que nuestro conjutno de datos consta de las pruebas individuales del mundial de Kazán 2015, luego como no hay relevos, todos los nadadores son el primer "relevista" en su prueba.

Luego la eliminamos:

```{r}
datos2015$relaycount <- NULL
```

Luego ahora, tenemos 21 variables en vez de 22. 


## Valores NA. Datos faltantes. [Expone Alonso todo.]

Si volvemos a mirar nuestro resumen, observamos que hay valores faltantes.
Vamos a tratar de identificarlos, intentar entender el por qué de esos datos faltantes, y razonar cuándo será conveniente eliminarlos o no de nuestro estudio.

Para ello, vamos a obtener primeramente un resumen de cómo se distribuyen los datos faltantes: 

```{r}
print(sum(is.na(datos2015)))
```
Observamos que hay 309 valores faltantes. 

Vamos a crear una tabla donde se nos muestren dónde se encuentran los valores faltantes: 

```{r}
datosNA <- datos2015[rowSums(is.na(datos2015)) > 0, ]
dim(datosNA)

```
Observamos que, de 11429 observaciones de mi tabla original, en 73 de ellas, existe algún valor nulo. Es decir, un 0.63 %  por ciento. Un valor muy bajo. 

En principio y sin estudiar nada más, podríamos considerar eliminar las filas que contengan datos faltantes ya que toman un valor muy pequeño con respecto al total. Aún así, vamos a ver dónde se suelen tomar más valores nulos y intentar explicar el por qué. Hacemos una tabla con los valores nulos de cada variable en porcentaje: 

```{r}
percent_na <- colSums(is.na(datosNA)) / nrow(datosNA) * 100
percent_na

```

Observamos de manera bastante clara que los datos nulos tienen mucho que ver con el tiempo acumulado, los puntos finales, el tiempo de reacción, el tiempo final y el tiempo al paso por el parcial. 

A continuación vamos a intentar clasificar los nulos dependiendo qué falta: 

### Valores nulos en los que faltan todas las variables.

Visualicemos los datos donde faltan todas las variables dichas anteriormente: 

```{r}
todosNA<-datosNA[is.na(datosNA$points) & is.na(datosNA$reactiontime) & is.na(datosNA$swimtime) & is.na(datosNA$cumswimtime) & is.na(datosNA$splitswimtime), ]
```

Bien, en 59 de las 73 observaciones, faltan, tanto el tiempo de reacción, los puntos finales, el tiempo final, los parciales acumulados... Es decir, nadadores que posiblemente se dieron de baja en la prueba. La mayoría de nadadores causaron baja en la ronda preliminar, pero hay uno, el chino Sun Yang, que causó baja en la final del 1500m libres masculino. Haciendo una pequeña búsqueda en los resultados de la World Aquatics de los mundiales de 2015, observamos que Sun Yang produció DNS (Did not Start). También, buscando a Cesar Cielo en el 50 libres de las preliminares, observo que causó baja DNS. Luego todo parece indicar que estos nadadores fueron baja en esa prueba y por ello no sale ningún dato en esas variables. Los elimino: 

```{r}
#Primero de la tabla datosNA: 
datosNA <- datosNA %>%
  filter(!(is.na(datosNA$points) & is.na(datosNA$reactiontime) & is.na(datosNA$swimtime) & is.na(datosNA$cumswimtime) & is.na(datosNA$splitswimtime)))

#Ahora, los elimino de la tabla datos2015: 
datos2015<-datos2015 %>%
  filter(!(is.na(datos2015$points) & is.na(datos2015$reactiontime) & is.na(datos2015$swimtime) & is.na(datos2015$cumswimtime) & is.na(datos2015$splitswimtime)))

```


Bien, ahora, tenemos solamente datos en los que falta alguna de las variables, echemos un vistazo para volver a clasificarlos: 

```{r}
datosNA
```


Nos quedan solamente 14 filas en los que hay datos nulos. Sigamos nuestra limpieza: 

### Valores nulos donde faltan los puntos: 

Veamos qué sucede si sólo faltan los puntos: 

```{r}
naReactionTime<-datosNA[is.na(datosNA$points),]
naReactionTime
```

Vamos a buscar los resultados de World Aquatics de alguno de ellos, para estimar qué esta sucediendo. ¿Fueron descalificados?. 

Nuestro nadador de la primera fila, Ben Treffers, fue descalificado. Buscamos también a Vladimir Morozov, y también fue descalificado. 
Luego, son gente que nadó pero quedó descalificada. Luego sus datos nos servirán para hacer estudios sobre participación, pero no para cualquier estudio que involucre los resultados. Luego estos, no los eliminamos del dataframe inicial datos2015

```{r}
datosNA <- datosNA %>%
  filter(!(is.na(datosNA$points)))
```


Me quedan las dos ultimas observaciones por ver: 

```{r}
datosNA
```

Tenemos dos observaciones en las cuales no existe el tiempo de reacción. Seguramente se deba a algún fallo en el sistema electrónico o algún fallo al pasar los datos. Por lo tanto, al igual que con los anteriores, no lo eliminaremos de nuestro dataframe inicial, pero sí lo tendremos en cuenta cuando tengamos que analizar estudios que tengan que ver con el tiempo de reacción. 


```{r}
print(sum(is.na(datos2015)))
```

Luego, de 309 iniciales, vamos a tratar ahora con 14 datos nulos ya controlados. 

```{r, echo=FALSE}
#Elimino las tablas creadas para no sobrecargar la escritura. Ya que no las vamos a volver a usar.
rm(datosNA)
rm(naReactionTime)
rm(todosNA)
rm(percent_na)
```

## Variable birthdate. Creacion de nueva variable edad.

A continuación, vamos a crear una variable llamada *edad*, ya que será más representativo que trabajar con la variable birthdate.
La variable tendrá el valor numérico de la edad de cada participante en el momento del mundial.
Es decir, el 24 de Julio de 2015.

```{r}
datos2015$birthdate <- as.Date(datos2015$birthdate)
#Calculamos la edad
fechaKazan<- as.Date("2015-07-24")
datos2015$edad <- as.numeric(difftime(fechaKazan, datos2015$birthdate, units = "weeks")) %/% 52  # Convertir de semanas a años
```

Además, borramos la variable birthdate: 

```{r}
datos2015$birthdate=NULL
```


## Estudio sobre el número de nadadores, su género, país y edad. [Alonso]

Para estudiar el número de nadadores, ver cuantos hombres y mujeres había, la edad de los participantes... Vamos a necesitar eliminar filas como bien hemos anunciado antes.

Por ello, vamos a crear una nueva tabla, llamada *nadadoresParticipantes*, la cual constará de todos los participantes sin repetir.
Para ello usamos la variable athleteid, la cual es única para cada participante.

```{r}
nadadoresParticipantes <- datos2015 %>%
  distinct(athleteid, .keep_all = TRUE)

#guardamos una copia de seguridad por si se modifica la tabla más adelante. 

nadadoresParticipantesCopia<-nadadoresParticipantes
```

```{r}
summary(nadadoresParticipantes)
```

Ya está preparado una tabla con nadadores únicos en el conjunto nadadoresParticipantes, lo cual es ideal para estudiar características individuales sin duplicados.
Con este conjunto, vamos a explorar variables como género, país y edad de los participantes.

Ahora, comenzamos nuestro estudio:

### Edad [Alonso]

Veamos primeramente un resumen de la edad:

```{r}
summary(nadadoresParticipantes$edad)
```

Observamos que la edad máxima fue de 38 años, la media fue de 21.32 años, y el participante con menos edad fue de 10 años.
Además, el 50% de los participantes estaban entre 19 y 24 años de edad.

Una pregunta razonable sería: ¿El dato relativo al participante de 10 años es un error?

Procedemos a contrastar la información.
De esta forma, podemos ver si de verdad existe este atleta o es un dato mal tomado de nuestra base de datos.
Confirmamos la información, entre otras fuentes, con esta noticia, de la cual añadimos el enlace sobre la joven nadadora de 10 años.
[noticia](https://www.rtve.es/deportes/20150807/nina-10-anos-alzain-tareq-asombra-a-natacion-mundial/1195782.shtml#:~:text=Se%20llama%20Alzain%20Tareq%2C%20tiene,estrella%20medi%C3%A1tica%20de%20la%20jornada.)

Confirmamos mediante su nombre, apellidos y edad, que la noticia se refiere a los datos que tenemos.

```{r}
datos2015[datos2015$edad == 10, ]
```

Se trata de una nadadora de Bahrain que nadó el 50 mariposa y el 50 libres.
Luego podemos concluir que es un dato atípico pero no es erróneo.

De acuerdo con esta nueva variable, vemos cómo se distribuyen las edades.

```{r}
ggplot(nadadoresParticipantes, aes(x = edad)) +
geom_density() +
ggtitle("Distribución. Edades.")
```

La mayoría de los nadadores parecen tener entre 15 y 25 años, con un pico alrededor de los 20 años.

Esto sugiere que los participantes en la competición están en su mayoría en la etapa juvenil o temprana adultez.

Podríamos preguntarnos si la edad sigue una distribución normal en estos datos, para ello, hacemos uso del test shapiro:
```{r}
shapiro.test(nadadoresParticipantes$edad)
```

Rechazamos la hipótesis nula, es decir, la edad NO sigue una distribución normal en estos datos. 

### Análisis de géneros participantes.

Veamos el número exacto de mujeres y hombres en la competición:

```{r}
summary(nadadoresParticipantes$gender)
```

Luego, hay 608 hombres y 491 mujeres que participaron en los mundiales de Kazán 2015.

Veamos ahora cómo se distribuyen los hombres y las mujeres y sus respectivas edades:

```{r}
ggplot(nadadoresParticipantes, aes(x = edad, colour = gender)) +
# Añadir la capa de la densidad de probabilidad.
    geom_density()
```

Según observamos, la distribución está ligeramente desplazada a la derecha para los hombres, esto indica que los hombres tienden a ser mayores en promedio que las mujeres.
Esta diferencia en la distribución de edades entre los géneros nos conduce a realizar distintos test estadísticos para confirmar si la diferencia realmente es significativa.

#### Hipótesis:

Hipótesis nula: Las medias de los dos grupos son iguales.
Hipótesis alternativas: Las medias de los dos grupos son diferentes.

```{r}
t.test(edad~gender,data=nadadoresParticipantes)

```

Hemos comparado las medias de edad entre mujeres (grupo F) y hombres (grupo M), tomando como hipótesis nula que las medias de edad entre mujeres y hombres son iguales, y cómo hipótesis alternativa que las medias de edad entre mujeres y hombres son diferentes.
Aunque el resultado del t-test muestra que hay una diferencia estadísticamente significativa (el p-valor es muy pequeño) entre las edades medias de hombres y mujeres (aproximadamente 1.16 años), en términos prácticos, esta diferencia es relativamente pequeña.
En este caso, puede no ser relevante en términos de la experiencia o desempeño de los nadadores.

No obstante, proseguimos en nuestro análisis exploratorio.

```{r}
tabla1<-table(nadadoresParticipantes$edad>30,nadadoresParticipantes$gender)
chisq.test(tabla1)
```

Por el resultado del siguiente test aplicado, podemos concluir con que **no hay asociación significativa**: Dado que el p-valor es 0.47, entre ser mayor de 30 años y el género de los nadadores en nuestros datos.
En términos sencillos,la edad no parece estar relacionada con el género de los nadadores en cuanto a si son mayores de 30 años.

```{r}
tabla2<-table(nadadoresParticipantes$edad<20,nadadoresParticipantes$gender)
chisq.test(tabla2)
```

Hay una diferencia considerable entre las frecuencias observadas (cuántos hombres y mujeres son menores de 20 años) y las frecuencias esperadas bajo la hipótesis nula (que no hay asociación entre edad y género para menores de 20 años).
Esto sugiere ir un paso más allá, **¿Hay más mujeres menores de edad que hombres menores de edad?**

```{r}
tabla3<-table(nadadoresParticipantes$edad<18,nadadoresParticipantes$gender)
chisq.test(tabla3)
```

Los resultados sugieren que el género y la minoría de edad si que están significativamente relacionados en nuestro conjunto de datos de nadadores.
Esto podría tener implicaciones para el análisis del rendimiento y la participación en competiciones.

Veamos números,

```{r}
tabla3

#Calcular los totales
totales <- colSums(tabla3)

#Calcular el porcentaje de nadadores menores de 18 años por género
porcentajes <- (tabla3[2, ] / totales) * 100  
# fila 2 son los menores de 18

porcentajes
```

De esta forma, ya habiendo confirmado una diferencia significativa.
Podemos ver, de manera más representativa, como existe el doble de proporción de mujeres menores de edad en comparación con los hombres.
Dicho en otras palabras, *2 de cada 10 mujeres son menores de 18 años, mientras que esto sólo ocurre en 1 de cada 10 hombres*:

```{r}
 # Supongamos que tienes los siguientes porcentajes:
porcentajes <- c(10.88, 21.66)  # 10% para hombres y 20% para mujeres
generos <- c("Hombres", "Mujeres")

# Crear un dataframe con los porcentajes
datos_porcentajes <- data.frame(Genero = generos, Porcentaje = porcentajes)

# Crear el gráfico de barras
ggplot(datos_porcentajes, aes(x = Genero, y = Porcentaje, fill = Genero)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = paste0(Porcentaje, "%")), vjust = -0.5) +  # Agregar los porcentajes sobre las barras
  labs(title = "Porcentaje de Nadadores Menores de 18 Años por Género",
       x = "Género",
       y = "Porcentaje") +
  scale_fill_manual(values = c("violet", "red")) +  # Colores para los géneros
  theme_minimal() +
  ylim(0, max(porcentajes) + 10)  # Ajustar el límite del eje Y

```


```{r, echo=FALSE}

#elimino las cosas creadas para no interferir luego. 

rm(tabla1,tabla2, tabla3, generos, porcentajes, totales, datos_porcentajes)

```

### Análisis de nacionalidades.

Vamos a ver la cantidad de nadadores por país.

```{r, warning=FALSE}

# Utilizamos la tabla nadadoresParticipantes
# Agregar el código ISO de dos dígitos. No es posible con la variable CODE, hay que convertir.
nadadoresParticipantes$iso2 <- countrycode(nadadoresParticipantes$name, "country.name", "iso2c")
#Vemos que salta error EN FINA, KOSOVO,MICRONESIA Y VIRGIN ISLAND
#Por tanto, revisamos los datos 
nombres<- unique(nadadoresParticipantes$name) #Para no repetir
print(nombres)

#Nombres problemáticos
manual <- data.frame(
  nombre = c("Fina", "Kosovo", "Micronesia", "Virgin Islands"),
  iso2 = c("FI", "XK", "FM", "VI")  
)

# Agregamos la variable continente 
nadadoresParticipantes$continent <- countrycode(nadadoresParticipantes$iso2, "iso2c", "continent")
#vuelve a fallar

#solo es XK(KOSOVO, que está en Europa)
#manualmente el continente para Kosovo (XK)
nadadoresParticipantes <- nadadoresParticipantes %>%
  mutate(continent = ifelse(iso2 == "XK", "Europe", continent))  


#nadadores por país
resumen_paises <- nadadoresParticipantes %>%
  group_by(name, iso2, continent) %>%
  summarise(num_nadadores = n(), .groups = "drop") %>%
  arrange(desc(num_nadadores))  # Ordenar por número de nadadores

resumen_paises

#Creamos un gráfico con colores
paleta <- c("Americas" = "#0084ff", "Asia" = "#44bec7", 
            "Europe" = "#ffc300", "Oceania" = "#fa3c4c")

oda_bar <- resumen_paises %>% 
  ggplot(aes(x = reorder(name, num_nadadores), y = num_nadadores, fill = continent)) + 
  geom_flag(y = -10, aes(image = iso2), size = 0.05) +  
  geom_bar(stat = "identity") + 
  labs(title = "Participación de Nadadores por País",
       subtitle = "Datos de nadadores en competiciones",
       x = "País",
       y = "Número de Nadadores") +
  scale_fill_manual(values = paleta) +  # colores personalizados
  expand_limits(y = c(0, max(resumen_paises$num_nadadores) + 10)) +  # Aumentar el límite superior
  coord_flip() +  # Para hacer el gráfico horizontal
  theme_minimal()

# Imprimir el gráfico
print(oda_bar)
```

Vemos también este mismo gráfico, pero separando los países por continentes.

```{r, warning=FALSE}
paleta <- c("Americas" = "#0084ff", 
            "Asia" = "#44bec7", 
            "Europe" = "#ffc300", 
            "Oceania" = "#fa3c4c")

oda_bar1 <- resumen_paises %>% 
  ggplot(aes(x = reorder(name, num_nadadores), 
             y = num_nadadores, 
             fill = continent)) + 
  geom_flag(y = -10, aes(image = iso2), size = 0.05) +  
  geom_bar(stat = "identity") + 
  labs(title = "Participación de Nadadores por País",
       subtitle = "Datos de nadadores en competiciones",
       x = "País",
       y = "Número de Nadadores") +
  scale_fill_manual(values = paleta) +  # Colores personalizados
  expand_limits(y = c(0, max(resumen_paises$num_nadadores) + 10)) +  # Ajustar el límite superior
  coord_flip() +  # Gráfico horizontal
  theme_minimal() +
  facet_wrap(~ continent, scales = "free_y")  # Separar por continentes

# Imprimir el gráfico
print(oda_bar1)

```

Como vemos, estos gráficos son poco interpretables debido a la gran cantidad de países.
Por ello, realizaremos un gráfico reduciendo la dimensión, juntando en un grupo llamado 'Otros' a aquellos países con menos de 10 nadadores.
*añadirlo*

```{r}
#Este código se encuentra en el script codigoUsado11oct. Daba error por eso lo he cambiado
```

```{r}
paleta <- c("Americas" = "#0084ff", 
            "Asia" = "#44bec7", 
            "Europe" = "#ffc300", 
            "Oceania" = "#fa3c4c")

# Crear el histograma de cantidad de nadadores por continente
histograma_nadadores <- resumen_paises %>% 
  ggplot(aes(x = continent, y = num_nadadores, fill = continent)) + 
  geom_bar(stat = "identity") +  # Sumar cantidad de nadadores por continente
  labs(title = "Cantidad de Nadadores por Continente",
       x = "Continente",
       y = "Número de Nadadores") +
  scale_fill_manual(values = paleta) +  # Colores personalizados por continente
  theme_minimal()

# Imprimir el histograma
print(histograma_nadadores)

```

Como podemos observar en los gráficos, la mayor cantidad de nadadores son de procedencia europea, continuando con Asia y Américas, y teniendo baja proporción los nadadores de África y Oceanía.

Nos preguntamos en esta situación, si los Europeos tendrán los puestos más altos en el ranking.
Es decir, si existe mayor proporción de ganadores en los países con más densidad de participantes.

Para ello, analizaremos los puntos según las nacionalidades de los nadadores.

```{r}
puntos_por_pais <- nadadoresParticipantes %>%
  group_by(name) %>%  
  summarise(total_puntos = sum(points, na.rm = TRUE))  

# Ver el resultado
print(puntos_por_pais)

```

```{r}
#Graficar los puntos por país
ggplot(puntos_por_pais, aes(x = reorder(name, total_puntos), y = total_puntos)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Total de Puntos por País", x = "País", y = "Total de Puntos") +
  coord_flip() +  # Voltear el gráfico para una mejor visualización
  theme_minimal()

```

De la misma manera que nos ocurría antes, este gráfico es poco interpretativo.
Lo vemos por continentes:

```{r}
puntos_por_continente <- nadadoresParticipantes %>%
  group_by(continent) %>%  #agrupar por continente
  summarise(total_puntos = sum(points, na.rm = TRUE))  #Sumar puntos por continente

print(puntos_por_continente)
```

```{r}
#Graficar los puntos por continente
ggplot(puntos_por_continente, aes(x = reorder(continent, total_puntos), y = total_puntos, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Total de Puntos por Continente", x = "Continente", y = "Total de Puntos") +
  coord_flip() + 
  theme_minimal()
```

```{r}
ggplot(na.omit(nadadoresParticipantes), aes(x = points, colour = continent)) +
# Añadir la capa de la densidad de probabilidad.
    geom_density()

ggplot(na.omit(nadadoresParticipantes), aes(x=continent, y=points, color=continent)) +
  geom_boxplot()
```

Como podemos observar, parece ser que los Europeos son mejores en el desempeño de las pruebas de natación.
Además, presentan una distribución más centrada a la media y sus valores más altos están bastante alejados del resto de los del resto de participantes de otros continentes.
Podríamos interpretar que América tiene la segunda distribución más centrada en comparación con el resto de continentes.
La esperanza está cercana a Oceanía por debajo pero con menor dispersión.
Oceanía también presenta una media bastante alta y cercana a la de Europa.
sin embargo, se puede ver como su dispersión es bastante elevada por lo que presenta nadadores de diversa cualificación.
La peor esperanza la tiene África, muy por debajo este valor del resto de los continentes.
Además presenta una gran dispersión, ya que abarca el rango desde valores cercanos al 0 hasta 1000, sin ser estos visualizados como outliers.
Esta información nos podría ser de gran ayuda para dar un posible enfoque a la hora de establecer tendencias en los grupos y a qué se puede deber (clima, tipo de entrenamiento, condiciones sociales en diversos países) la cantidad de puntos en promedio y la variabilidad de estas observaciones.

Anteriormente hemos hallado para cada contiente todos los puntos conseguidos por los nadadores de dicho continente.
Lo que vamos a hacer a continuación es normalizar los puntos por continente, es decir, para cada continente tomamos todos los puntos de dicho continente y lo dividimos por todos participantes de ese continente y comparamos.

```{r}
# Agrupar por continente, sumar puntos y contar participantes
resumenContinente <- nadadoresParticipantes %>%
  group_by(continent) %>%
  summarise(
    puntos_totales_continente = sum(points, na.rm = TRUE),
    numero_Participantes_continente = n()  # Contar los participantes
  ) %>%
  mutate(
    relacion_puntos_por_participante = puntos_totales_continente / numero_Participantes_continente
  )

# Imprimir el resultado
print(resumenContinente)
```

Vemos que Europa tiene el mejor promedio con una cierta diferencia, le siguen América y Oceanía (puntuaciones similares), despúes Asia y por último Africa.

Para terminar con esta sección, vamos a ver los 20 primeros en el ranking, y a hacer un gráfico que nos indique de que pais es cada uno de los 20.

```{r}
# Filtrar solo las filas de la prueba de 100 metros y ordenar por puntos
datos_100m_top <- nadadoresParticipantes[nadadoresParticipantes$distance==100,] %>% # Filtra para la prueba de 100 metros
  arrange(desc(points)) %>%           # Ordena por puntos de mayor a menor
  dplyr::slice(1:20)                        # Selecciona las primeras 20 

datos_100m_top
```

Vemos los 20 primeros y de que continente son:

```{r}

# Contar la cantidad de nadadores por continente
conteo_por_continente <- datos_100m_top %>%
  group_by(continent) %>%                                       # Agrupa por continente
  summarise(cantidad_nadadores = n()) %>%                      # Cuenta los nadadores por continente
  mutate(percent = (cantidad_nadadores / sum(cantidad_nadadores)) * 100)  # Calcula el porcentaje

# Crear el gráfico de distribución porcentual
grafico_distribucion_continente <- ggplot(conteo_por_continente, aes(x = continent, y = percent, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Distribución Porcentual de Nadadores por Continente en los Top 20 - 100 Metros",
       x = "Continente",
       y = "Porcentaje de Nadadores") +
  scale_fill_manual(values = paleta) +                          # Usa la paleta de colores personalizada
  theme_minimal()

# Imprimir el gráfico
print(grafico_distribucion_continente)
grafico_circular <- ggplot(conteo_por_continente, aes(x = "", y = percent, fill = continent)) +
  geom_bar(stat = "identity", width = 1) +                      # Crea las barras
  coord_polar("y") +                                            # Convierte el gráfico en circular
  labs(title = "Distribución Porcentual de Nadadores por Continente en los Top 20 - 100 Metros",
       fill = "Continente") +                                   # Etiqueta para la leyenda
  scale_fill_manual(values = paleta) +                          # Usa la paleta de colores personalizada
  theme_void()                                                  # Elimina el fondo y ejes

# Imprimir el gráfico
print(grafico_circular)
```

La alta cantidad de nadadores europeos en el podio de 100 metros(más específico que lo anterior, ya que esto nos mete directamente en los primeros 20) sugiere que hay un fuerte nivel de competencia y entrenamiento en las naciones de este continente.
Esto podría estar relacionado con la inversión en programas de natación.
Le sigue oceanía,ya que Oceanía, aunque es una región más pequeña en términos de población comparada con Europa, ha producido nadadores destacados que compiten a niveles muy altos.
La presencia de nadadores de élite, especialmente de Australia, resalta la calidad del talento en la región.

Los datos indican que África tiene solo un 5% de ganadores en la natación en comparación con otros continentes como Europa y Oceanía, esto puede abrir un amplio espacio para el análisis, ya que muchos países africanos enfrentan desafíos significativos en cuanto a la inversión en infraestructura deportiva.
La falta de instalaciones de calidad para la natación, como piscinas adecuadas, puede limitar el desarrollo de talentos.

Realizando un chequeo rápido a la tabla de los 20 mejores, vemos que tenemos South Africa en el top 2 en 100 metros(hemos elegido 100 metros al haber una gran cantidad de nadadores, lo que refleja bien lo que buscamos).
Podríamos ver que a pesar de que en África no se llegue mucho al podio, cuando se llega es en los tres primeros puestos.
¿Hemos concluido bien?
Veámoslo.
Esto es el podio de los 3 primeros en 100 metros

```{r}
# Filtrar solo las filas de la prueba de 100 metros y ordenar por puntos
datos_100m_top_3 <- nadadoresParticipantes[nadadoresParticipantes$distance==100,] %>% # Filtra para la prueba de 100 metros
  arrange(desc(points)) %>%           # Ordena por puntos de mayor a menor
  dplyr::slice(1:3)                        # Selecciona las primeras 20 

datos_100m_top_3
```

La presencia de Sudáfrica en el segundo lugar es un indicador de que, a pesar de la baja representación general, el continente tiene al menos algunos atletas de élite que pueden competir con los mejores del mundo.Aunque la cantidad de nadadores africanos en el podio es baja, su éxito en alcanzar los primeros puestos es notable.
Esto podría implicar que los nadadores africanos son altamente competitivos cuando tienen la oportunidad de competir en el más alto nivel.
Además,al centrarse en la prueba de 100 metros, que tiene una gran cantidad de participantes, se obtiene una visión clara del rendimiento de los nadadores en este evento específico.
Esto ayuda a eliminar sesgos que podrían surgir al mirar pruebas con menos competidores.

```{r}

# Crear un gráfico para visualizar el podio de los 3 primeros
grafico_podio_100m <- ggplot(datos_100m_top_3, aes(x = reorder(lastname, points), y = points, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Podio de los 3 Primeros en 100 Metros",
       x = "Nadador",
       y = "Puntos",
       fill = "Continente") +
  scale_fill_manual(values = paleta) +  # Usa la paleta de colores que ya definiste
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Mejorar legibilidad

# Imprimir el gráfico
print(grafico_podio_100m)

grafico_podio_100mrepresentacion <- ggplot(datos_100m_top_3, aes(x = reorder(continent, points), y = points, fill = continent)) +
  geom_bar(stat = "identity") +
  labs(title = "Representación podium de África VS Europa  (en Puntos)",
       x = "Nadador",
       y = "Puntos",
       fill = "Continente") +
  scale_fill_manual(values = paleta) +  # Usa la paleta de colores que ya definiste
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Mejorar legibilidad

# Imprimir el gráfico
print(grafico_podio_100mrepresentacion)

```




## Estudio sobre los eventos, reactiontime, lane, heats, daytime: [Alonso]

Para poder elaborar un estudio de algunas variables como *events*, *reactiontime*, *lane*, *heats* y *daytime*, vamos a necesitar una tabla que refleje a cada nadador y sus pruebas nadadas por filas.

Para poder realizar la tabla, primero hay que saber si cada prueba, dentro de cada tipo de prueba (preliminar, final, semifinal), tiene un id distinto.
Lo evaluamos seleccionando algún nadador que haya nadado en varias rondas:

```{r}
ejemplo<-datos2015[datos2015$distance == 100 & datos2015$stroke=="BACK" & datos2015$code=="AUS", ]
head(ejemplo,6)
```

```{r, echo=FALSE}
rm(ejemplo)
```

Bien, vemos que el australiano nadó tanto las preliminares, como las semifinales como la final y el eventid era distinto, luego parece que podemos seguir con nuestro estudio.
Creamos la siguiente tabla:

```{r}
nadadoresPruebas <- datos2015 %>%
  distinct(eventid, athleteid, .keep_all = TRUE)
nadadoresPruebas

#Copia de seguridad: 
nadadoresPruebasCopia<-nadadoresPruebas
```

Los datos creados, reflejan nadadores y pruebas nadadas por cada uno.

### Reactiontime. Hombres vs Mujeres

Veamos cómo se distribuyen los datos de tiempo de reacción de todos los nadadores. Para ello, no tenemos en cuenta las dos filas con datos nulos. 

```{r}
ggplot(na.omit(nadadoresPruebas), aes(x = reactiontime)) +
geom_density() +
ggtitle("Distribución. reactiontime")

```

Parece que los datos siguen una distribución normal a priori. Igual que antes, vamos a hacer el test de shapiro: 

```{r}
shapiro.test(na.omit(nadadoresPruebas$reactiontime))
```

Al tener un p-valor tan bajo, no parece que siga una distribución normal. 

Vamos a ir más alla para intentar sacar conclusiones más profundas.

Vamos a comparar las funciones de densidad de chicos y chicas en general:

```{r message=FALSE, warning=FALSE}
nadadoresPruebas <- nadadoresPruebas %>% filter(!is.na(nadadoresPruebas$reactiontime))
ggplot(na.omit(nadadoresPruebas), aes(x=reactiontime, colour=gender))+
geom_density()+
  ggtitle("Distribución. Hombres vs Mujeres")
```

De esta gráfica nos surgen muchas preguntas, vamos a analizar esto más a fondo.
Hagamos un test de hipótesis donde:

-   H0: El tiempo de reacción es igual en mujeres y hombres.
-   H1: El tiempo de reacción es menor en hombres que en mujeres.

```{r}
t.test(reactiontime~gender,data=nadadoresParticipantes)
```

De manera similar a lo realizado previamente, el p- valor nos indica que hay una evidencia significativa en rechazar la hipótesis nula, y por ende concluir con que hay una diferencia estadística en el tiempo de reacción dependiendo del género.
Ahora que hemos determinado que la diferencia es estadísticamente significativa, es importante considerar si la diferencia es también significativa en la práctica o si tiene relevancia a la hora de los resultados finales.
Por ejemplo, de las mujeres/hombres que tienen un tiempo de reacción más bajo y aquellas/os que tienen un tiempo de reaccion más alto,¿ le corresponden puestos mas altos y bajos respectivamente?
No podemos precipitarnos a decir que la diferencia es muy pequeña ya que habría que hacer un análisis adicional para medir la magnitud la diferencia (como el de Cohen).
Esto nos diría cómo es de grande la diferencia en términos de desviaciones estándar.

### Reactiontime. Distancias largas vs distancias cortas.

Vamos a comparar ahora las funciones de densidad de las chicas en la prueba de 800m libres y 50m libres:

Primeramente calculamos el conjunto de datos:

```{r}
nadadorasComparacionReactionTime<-nadadoresPruebas[(nadadoresPruebas$distance==50 | nadadoresPruebas$distance==800) & nadadoresPruebas$gender=="F" & nadadoresPruebas$stroke=="FREE", ]
```

```{r}
ggplot(nadadorasComparacionReactionTime, aes(x = reactiontime,group=distance)) +
geom_density() +
ggtitle("Distribución. Reaction time: 800m free vs 50m free")

```

El gráfico muestra dos curvas de densidad superpuestas, una para la prueba de 50 metros y otra para 800 metros.

```{r}
# Crear el gráfico de densidad con colores por distancia
ggplot(nadadorasComparacionReactionTime, aes(x = reactiontime, fill = factor(distance), group = distance)) +
  geom_density(alpha = 0.6) +  # Usar alpha para hacer las curvas semi-transparentes
  scale_fill_manual(values = c("50" = "#0084ff", "800" = "#fa3c4c")) +  # Asignar colores específicos
  ggtitle("Distribución del Tiempo de Reacción: 800m libre vs 50m libre") +
  labs(fill = "Distancia (m)") +  # Etiqueta para la leyenda
  theme_minimal() +  # Tema minimalista
  xlab("Tiempo de Reacción (s)") +  # Etiqueta para el eje X
  ylab("Densidad")  # Etiqueta para el eje Y
```

Las curvas se encuentran en un rango de aproximadamente 0.6 a 0.9, que representa los tiempos de reacción.
La advertencia en la consola indica que algunos valores fueron eliminados debido a ser no finitos, lo que sugiere que puede haber valores faltantes u outliers en los datos de tiempo de reacción.
Para los 50 metros, la densidad es más alta en el rango de tiempos de reacción más cortos, lo que indica que las nadadoras tienden a tener tiempos de reacción más rápidos en esta distancia.
Esto es esperado, ya que la carrera de 50 metros es más corta y requiere reacciones más rápidas y explosivas.
En cuanto a la de 800 metros, la curva muestra una mayor dispersión en los tiempos de reacción, con una densidad más amplia.
Esto sugiere que los tiempos de reacción son más variados en esta distancia, probablemente debido a la naturaleza más larga y estratégica de la carrera, donde las nadadoras pueden no necesitar un tiempo de reacción tan rápido.

Aquí también podemos hacer un test de hipótesis.

```{r}
t.test(reactiontime~distance,data=nadadorasComparacionReactionTime)
```

Veamos nuestros resultados del test.
Por un lado tenemos el valor del estadístico t calculado, como es un valor negativo indica que la media del primer grupo (50 metros) es menor que la del segundo grupo (800 metros).El valor del p-valor (que es extremadamente bajo) indica que hay una diferencia estadísticamente significativa entre las medias de los dos grupos.
Las nadadoras que participan en distancias más cortas (50 metros) tienen un tiempo de reacción más rápido en comparación con aquellas que nadan distancias más largas (800 metros).Luego, habíamos identificado correctamente la tendencia del gráfico, en términos estadísticos.

A continuación, realizamos el mismo estudio pero con hombres y vemos si la situación es similar.

```{r}
nadadoresComparacionReactionTime<-nadadoresPruebas[(nadadoresPruebas$distance==50 | nadadoresPruebas$distance==800) & nadadoresPruebas$gender=="M" & nadadoresPruebas$stroke=="FREE", ]
```

```{r}
ggplot(nadadoresComparacionReactionTime, aes(x = reactiontime,group=distance)) +
geom_density() +
ggtitle("Distribución para Hombres. Reaction time: 800m free vs 50m free")

```

```{r}
t.test(reactiontime~distance,data=nadadoresComparacionReactionTime)
```

Al realizar el t-test para este grupo, vemos también como la diferencia es significativa entre el tiempo de reacción para la prueba de 50 metros y la de 800.

La diferencia entre estos dos extremos en las pruebas es muy significativa, pero queremos saber también como se distribuyen todas.
Es decir, cuál es la diferencia entre las pruebas de 50 metros, las de 100, 200, etc.
Para ello, realizaremos un gráfico de densidad conjunto.

```{r}
ggplot(nadadoresPruebas, aes(x = reactiontime, color = as.factor(distance), fill = as.factor(distance))) +
  geom_density(alpha = 0.5) +  # Ajustar la transparencia
  ggtitle("Distribución comparada de Reaction time") +
  labs(x = "Tiempo de Reacción", y = "Densidad", color = "Distancia", fill = "Distancia") +
  theme_minimal()
```

Como podemos observar, nuestras suposiciones parecen ser ciertas acerca de que las medias de los tiempos de reacción aumentan según la carrera es más larga.
Si bien es cierto, para distancias largas, como son 800 y 1500 metros, no se observan diferencias en torno a su valor central.
Del mismo modo, para carreras de 100 y 200 tampoco se observa una diferencia signifiticativa.
Contrastamos esto de forma más precisa realizando el test ANOVA de diferencia de medias.

```{r}
anova_tiempoReaccion_distancia <- aov(reactiontime ~ as.factor(distance), data = na.omit(nadadoresPruebas))
summary(anova_tiempoReaccion_distancia)
```

Interpretando estos resultado, tenemos que el valor p es un valor de orden e\^-16.
Por ello, podemos concluir que hay diferencias significativas en los tiempos de reacción entre al menos uno de los grupos de distancia.
Esto indica que, al menos una distancia tiene un tiempo de reacción diferente en comparación con las otras distancias.
El valor de F es alto (56.98), sugiere que la variación entre los grupos es mucho mayor que la variación dentro de los grupos.
Esto refuerza la idea de que las medias de los tiempos de reacción son significativamente diferentes entre las carreras de diferente distancia.


```{r, echo=FALSE}
rm(anova_tiempoReaccion_distancia, nadadorasComparacionReactionTime, nadadoresComparacionReactionTime)

#restauro nadadoresPruebas para el siguiente estudio: 
nadadoresPruebas<-nadadoresPruebasCopia

```


### Calles usadas.

Veamos cómo se distribuyen las calles usadas:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(nadadoresPruebas$lane)) + geom_bar(fill = "orange") +
theme_bw()

```

Se observa que las calles menos usadas son tanto la 0 como la 9.
Esto es un dato que puede resultar curioso al visualizar los datos.

Informándonos acerca de ello, las calles 0 y 9 sólo se usan en la ronda preliminar, en las semifinales y finales se usan de la 1 a la 8, luego tiene sentido que sean las menos frecuentadas por los nadadores. Podríamos intentar visualizar si hay alguna relación entre alguna variable de nuestro dataframe y la calle usada, aunque podemos adelantar que, en cada serie, los nadadores se van colocando de más rapido a más lento de la siguiente forma: 4-5-3-6-2-7-1-8. Luego hay que tener esto en cuenta para no sacar conclusiones equivodadas. 

¿Habrá alguna relación entre la calle usada y el tiempo de reacción?

```{r, warning=FALSE}
#Creo una paleta con 10 colores: 
colores <- c("#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00", 
             "#A65628", "#F781BF", "#999999", "#D95F02", 
             "#7570B3", "#66A61E")


ggplot(nadadoresPruebas, aes(x = reactiontime, fill = lane)) +
  geom_histogram(binwidth = 0.01, alpha = 0.7, position = "identity") +
  facet_wrap(~ lane) +  # Crear facetas por calle
  theme_bw() +
  labs(title = "Distribución de Tiempos de Reacción por Calle",
       x = "Tiempo de Reacción",
       y = "Frecuencia") +
  scale_fill_manual(values = colores)
```

Como podemos ver, no parece haber diferencias significativas según el tipo de calle en los tiempos de reacción.
De nuevo, podemos realizar un test anova sobre la diferencia de medias.

```{r}
anova_tiempoReaccion_Calles <- aov(reactiontime ~ as.factor(lane), data = na.omit(nadadoresPruebas))
summary(anova_tiempoReaccion_Calles)
```

El p-valor de nuestro análisis es menor de 0.005, por lo que podríamos sugerir que sí tiene cierta influencia según el número de calle empleada.
Sin embargo, existen muchas variables en nuestro conjunto de datos que podrían influir.


Realizamos un modelo lineal para ver si existe una relación entre los puntos de los participantes y el número de calle en el que compiten.

```{r}
lmPuntosCalle = lm(nadadoresPruebas$points~nadadoresPruebas$lane)
summary(lmPuntosCalle)
plot(lmPuntosCalle)

```

Podemos ver como tenemos unos valores de los parámetros de nuestra aproximación con p valores muy significativos.
Sin embargo, si observamos la gráfica qqplot, la tendencia no es lineal.
Para conseguir un mejor ajuste, realizaremos una transformación de la variable puntos mediante Box-Cox.

```{r}
boxcox(lmPuntosCalle)
```

El mejor ajuste que nos devuelve Box-Cox es con \lambda=2.
Por tanto,

```{r}
lmPuntosCalle2 = lm((nadadoresPruebas$points)^2~nadadoresPruebas$lane)
summary(lmPuntosCalle)
plot(lmPuntosCalle)
```

Sigue sin ser normal la distribución de los residuos, luego parece que este no es el camino indicado si queremos explicar los puntos a partir de las calles. 

De todas formas, si en algún momento existe relación entre los puntos y las calles usadas, será porque los nadadores con mejor tiempo se situan en las calles centrales. 

### Daytime

Nos genera curiosidad, por su formato, cómo se distribuye daytime, luego veamos:

```{r}
ggplot(nadadoresPruebas, aes(daytime)) + geom_bar(width=0.7, colour="red", fill="skyblue") + ggtitle("Daytime en los que se producen las pruebas")
```

Vemos que, aunque podríamos sacar alguna conclusión ya, el valor de la variable daytime debería tener el formato hora/minutos.
Por ello, lo realizamos:

```{r}
# Función para convertir
convertir_a_hhmm <- function(tiempo_numerico) {
  # Convertir el número a un string y separar horas y minutos
  horas <- tiempo_numerico %/% 100
  minutos <- tiempo_numerico %% 100
  
  # Crear un objeto de tiempo en formato hh:mm
  tiempo_formateado <- sprintf("%02d:%02d", horas, minutos)
  return(tiempo_formateado)
}

# Aplicar la función a todos los tiempos
tiempos_hhmm <- sapply(nadadoresPruebas$daytime, convertir_a_hhmm)
head(tiempos_hhmm)

```

Ahora representamos estos tiempos en una gráfica.
De esta manera, el lector puede visualizarlo sin tener que imaginar su conversión, como en el gráfico de antes.

```{r}
# Crear la columna 'tiempo_hhmm'
nadadoresPruebas$tiempo_hhmm <- sapply(nadadoresPruebas$daytime, convertir_a_hhmm)

# Convertir la nueva columna 'tiempo_hhmm' a formato POSIXct
nadadoresPruebas$tiempo_hhmm <- as.POSIXct(nadadoresPruebas$tiempo_hhmm, format = "%H:%M")

# Ahora puedes hacer el histograma
ggplot(nadadoresPruebas, aes(x = tiempo_hhmm)) +
  geom_histogram(binwidth = 3600, color = "black", fill = "blue") +  # binwidth en segundos (3600 segundos = 1 hora)
  scale_x_datetime(date_labels = "%H:%M", breaks = "1 hour") +  # Etiquetas de tiempo
  labs(title = "Frecuencia de Tiempos",
       x = "Tiempo (hh:mm)",
       y = "Frecuencia") +
  theme_minimal()

```

Luego, podemos observar de manera clara que, cada día de competición constaba de 2 sesiones, una matinal y otra vespertina, y que las franjas horarias van, por la mañana de 9:30 a 12:30, y por la tarde de 17:30 a 19:30.


#### Pruebas matinales y vespertinas. [Alonso]

Observamos que el número de nadadores que nadan por la mañana es mucho mayor al de por la tarde.

Vamos a ver un resumen de qué pruebas se nadan por la mañana y cuáles por la tarde:

```{r}
nadadoresPruebas$tiempo_hhmm<- as.POSIXct(nadadoresPruebas$tiempo_hhmm, format = "%H:%M")
#intervalo para las matinales
limite_inferior1 <- as.POSIXct("09:30", format = "%H:%M")
limite_superior1 <- as.POSIXct("13:00", format = "%H:%M")
#intervalo para las vespertinas
limite_inferior <- as.POSIXct("17:00", format = "%H:%M")
limite_superior <- as.POSIXct("20:00", format = "%H:%M")
#Creamos las tablas
pruebasMatinales<-subset(nadadoresPruebas, nadadoresPruebas$tiempo_hhmm >= limite_inferior1 & nadadoresPruebas$tiempo_hhmm <= limite_superior1)

pruebasVespertinas<-subset(nadadoresPruebas, nadadoresPruebas$tiempo_hhmm >= limite_inferior & nadadoresPruebas$tiempo_hhmm <= limite_superior)
```

Bien, dividida ya nuestras pruebas en la sesion matinal y la vespertina, veamos un resumen de los datos:

```{r}
dim(pruebasMatinales)
dim(pruebasVespertinas)
```

De aquí observamos que, mientras que por las mañanas se nada un 75% de las pruebas del mundial, por las tardes sólo se nada un 25%.
Veamos si hay alguna variable que nos pueda ayudar:

```{r}
print("Resumen de rondas nadadas en sesiones matinales.")
summary(pruebasMatinales$round)
print("Resumen de rondas nadadas en sesiones vespertinas.")
summary(pruebasVespertinas$round)
```

Luego podemos concluir que, el formato que sigue el mundial de Kazán 2015 es, nadar por las mañanas las series preliminares de cada prueba, mientras que por las tardes sólo nadan los nadadores clasificados a semifinales y finales.


## Estudio sobre la variable distancia y su asociación con los tipos de nado. (SALMA)




## Estudio sobre la relación entre la edad de los nadadores y las distancias que nadan.

```{r}
#Crear una nueva columna para clasificar por edad
nadadoresPruebas <- nadadoresPruebas %>%
  mutate(grupo_edad = ifelse(edad < 18, "Menores de 18", "18 y más"))

#Resumir el número de participantes en cada prueba por grupo de edad
resumen_pruebas <- nadadoresPruebas %>%
  group_by(grupo_edad , distance) %>%  # Agrupar por grupo de edad y prueba(LO MIRO POR DISTANCIAS)
  summarise(num_participantes = n(),.groups = "drop") %>%  #Contar el número de participantes
  ungroup() %>%  # Quitar agrupación
  arrange(grupo_edad, desc(num_participantes))  #Ordenar los resultados

# Mostrar el resumen
resumen_pruebas

```

Para poder analizar correctamente la tendencia de los nadadores según su grupo de edad, no podemos quedarnos en las frecuencias absolutas.

Debemos analizar los resultados según sus frecuencias relativas.

```{r}
# Crear una nueva columna para clasificar por edad
nadadoresPruebas <- nadadoresPruebas %>%
  mutate(grupo_edad = ifelse(edad < 18, "Menores de 18", "18 y más"))

# Contar el número total de nadadores
total_nadadores <- nrow(nadadoresPruebas)

# Resumir el número de participantes en cada prueba por grupo de edad
resumen_pruebas <- nadadoresPruebas %>%
  group_by(grupo_edad, distance) %>%  # Agrupar por grupo de edad y prueba
  summarise(num_participantes = n(), .groups = "drop") %>%  # Contar el número de participantes
  mutate(porcentaje = (num_participantes / total_nadadores) * 100) %>%  # Calcular el porcentaje
  ungroup() %>%  # Quitar agrupación
  arrange(grupo_edad, desc(num_participantes))  # Ordenar los resultados

# Mostrar el resumen
print(resumen_pruebas)


```

Lo veo gráficamente:

```{r}
library(ggplot2)

# Gráfico de barras para el número de participantes por grupo de edad y distancia
ggplot(resumen_pruebas, aes(x = factor(distance), y = num_participantes, fill = grupo_edad)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Número de Participantes por Distancia y Grupo de Edad",
       x = "Distancia (m)",
       y = "Número de Participantes",
       fill = "Grupo de Edad") +
  theme_minimal()

```

La distancia de 100 y 50 metros es la distancia más popular entre los nadadores mayores de 18 años.
Le sigue la distancia de 200 metros.
La participación disminuye considerablemente en distancias más largas, como 1500 metros.
Para los menores de 18 años tenemos carreras de 100 y 50 metros como las más frecuentadas, aunque menos que el grupo de 18 años o más(hay menos menores).
La participación en distancias más largas, como 400 metros, es aún más baja en menores.

Los nadadores mayores de 18 años tienen una participación significativamente mayor en todas las distancias en comparación con los menores de 18 años.
La participación en distancias más largas tiende a ser baja en ambos grupos, pero la caída es más pronunciada en los menores de 18.

Tratando de analizar los datos obtenidos podemos concluir con que la distancia de 50 metros es la más popular entre los nadadores.
Sin embargo, la diferencia en el número de participantes entre ambos grupos de edad es significativa.
Este es un dato que es evidente con nuestras observaciones anteriores, ya que vimos que la media de los participantes está en torno a 21 años.
Por tanto, hay más de la mitad de los participantes en el segundo grupo.
Lo que si podemos apreciar es que se observa una tendencia de disminución en la participación a medida que las distancias aumentan.

```{r}
# Gráfico de líneas para mostrar la tendencia
resumen_pruebas
ggplot(resumen_pruebas, aes(x = distance, y = num_participantes, color = grupo_edad, group = grupo_edad)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  labs(title = "Tendencia de Participación en Distancias de Natación por Grupo de Edad",
       x = "Distancia (m)",
       y = "Número de Participantes") +
  scale_x_continuous(breaks = unique(resumen_pruebas$distance)) +
  scale_color_manual(values = c("blue", "orange")) +
  theme_minimal()

```

La distancia de 50 metros es la más popular, tanto para mayores como para menores de 18 años.
La participación de los mayores de 18 años es considerablemente más alta en todas las distancias.
La caída en la participación es más pronunciada en el grupo de menores de 18 años, especialmente en distancias más largas.

Nos vamos a centrar, en una de las conclusiones que hemos mencionado varias veces.
En los menores de edad,¿realmanete hay una diferencia significativa entre el número de nadadores en las pruebas más explosivas, que en las pruebas más largas?
Para ello, creamos una nueva columna, que nos indique que prueba es explosiva, y cual de más resistencia.
A continuación, procedo a quedarme con lo que me interesa(menores de edad agrupados en explosivo y resistencia)

```{r}
resumen_pruebas
# Clasificar las distancias
resumen_pruebas <- resumen_pruebas %>%
  mutate(tipo_prueba = case_when(
    distance %in% c(50, 100) ~ "Explosiva",
    distance %in% c(200, 400, 800, 1500) ~ "Resistencia",
    TRUE ~ "Otra"
  ))

# Filtrar solo los menores de 18 años y contar las participaciones
participaciones_menores <- resumen_pruebas  %>%
  filter(grupo_edad == "Menores de 18") %>%
  group_by(tipo_prueba) %>%
  summarise(total_participantes = sum(num_participantes),porcentajes_acumulativos=sum(porcentaje))

print(participaciones_menores)

```

Evidentemente, como ya nos podíamos esperar, la participación de nadadores menores de edad en pruebas explosivas es notablemente mayor que en pruebas de resistencia.
Esto se puede atribuir a la naturaleza de las pruebas, donde las pruebas explosivas, como los 50 y 100 metros, requieren menos tiempo de entrenamiento prolongado en comparación con las pruebas de resistencia, que implican una mayor dedicación y condición física a largo plazo.



## Estudio sobre la variable round. [Alonso]

A continuación, vamos a intentar entender más sobre la variable ronda.
Para ello, primero vemos un resumen:

```{r}
summary(datos2015$round)
```

Observamos que toma 5 posibles valores, tenemos controlados tanto FIN (final), como PRE (preliminar) y SEM (semifinal).
Pero SOP y SOS no parece tan claro saber qué es.
Vamos a comenzar dejando de lado SOP y SOS, nos vamos a centrar en controlar los otros 3 valores.

### ¿Cuántos nadadores nadan cada ronda? [Alonso]

Una pregunta natural podría ser, ¿cuántos nadadores pasan de ronda?
¿Todos?
Está claro que al ver que por la mañana en preliminares nadan el 75% y por las tardes son semifinales y finales y son un 25%.
Veamoslo con distintas pruebas:

#### 50 libre femenino: [Alonso]

Seleccionamos las nadadoras que nadaron preliminares en el 50 libre femenino:

```{r}
free50PrelimWomens<- nadadoresPruebas[nadadoresPruebas$round=="PRE" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]

free50PrelimWomens
```

Ahora, vamos a hacer el ranking de resultados de esta prueba, para ello:

```{r}
free50PrelimWomens<-free50PrelimWomens[order(free50PrelimWomens$swimtime), ]

dim(free50PrelimWomens)
```

Observamos que hubo 119 nadadoras que nadaron las preliminares del 50 libres.
Veamos ahora cuántas nadaron las semifinales:

```{r}
free50SemisWomens<-nadadoresPruebas[nadadoresPruebas$round=="SEM" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]
```

Antes de ordenarlas, veamos cuántas filas tengo en mi nueva tabla:

```{r}
dim(free50SemisWomens)
```

Es decir, de 119, sólo se clasificaron 16.
Veamos si fueron las 16 primeras.
Para ello, voy a coger las 16 primeras de las prelims, voy ahora a ordenarlas por athleteid, y hacer lo mismo con las de las semifinales, a ver si coincide:

```{r}
free50PrelimWomens<-head(free50PrelimWomens, 16)

#Ordeno: 

free50PrelimWomens<-free50PrelimWomens[order(free50PrelimWomens$athleteid), ]
free50SemisWomens<-free50SemisWomens[order(free50SemisWomens$athleteid), ]

free50PrelimWomens
free50SemisWomens

```

Luego, podemos observar claramente que, las 16 primeras de las preliminares, consiguieron clasificarse a las semifinales.
Hagamos el mismo trabajo con la tabla *free50SemisWomens* para ver cuántas nadadoras se clasificaron en la final:

```{r}
free50SemisWomens<-free50SemisWomens[order(free50SemisWomens$swimtime), ]

```

Al igual que antes, confeccionamos la tabla de la final:

```{r}
free50FinalWomens<-nadadoresPruebas[nadadoresPruebas$round=="FIN" & nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=="FREE" & nadadoresPruebas$gender=="F", ]

dim(free50FinalWomens)
```

Observamos que hay 8, luego las 8 primeras se clasificaron a la final.

### ¿Se nadan las 3 rondas en cada prueba?

Esta cuestión nos surge ya que, algunas pruebas requieren más esfuerzo y el tiempo de descanso para la recuperación total es más largo, por ello alomejor hay pruebas en las que sólo hay 1 ronda, o 2, o esta suposición es falsa y en cada prueba se nadan 3 rondas.
Para ello, echemos un cálculo inicial.
Hay 2 géneros, pruebas de 50, 100, 200, 400, 800 y 1500 metros.
Veamos qué valores toman las rondas en cada una de estas pruebas.
Para ello:

```{r}
print("Rondas que se nadan en las pruebas de 50 metros: ")
summary(nadadoresPruebas[nadadoresPruebas$distance==50, ]$round)
print("Rondas que se nadan en las pruebas de 100 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==100, ]$round)
print("Rondas que se nadan en las pruebas de 200 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==200, ]$round)
print("Rondas que se nadan en las pruebas de 400 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==400, ]$round)
print("Rondas que se nadan en las pruebas de 800 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==800, ]$round)
print("Rondas que se nadan en las pruebas de 1500 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==1500, ]$round)
```

Luego, observamos que en las pruebas de 400, 800 y 1500 metros no hay semifinales, tan sólo una ronda preliminar y una ronda final.

También podemos sacar conclusiones gracias al estudio hecho en el apartado anterior.
En los 50 por ejemplo, hay 128 nadadores que nadan semifinales, hay dos géneros, luego 64 nadadores por género nadaron semifinales, además, hay 4 estilos, luego 16 nadadores nadaron las semifinales de cada prueba, lo cual concuerda con lo visto anteriormente.

Destaca a la vista que, en las pruebas de 200 metros, hay más nadadores.
¿Por qué sucede esto?.
Veamos:

```{r}
print("Estilos que se nadan en pruebas de 50 metros: ")
summary(nadadoresPruebas[nadadoresPruebas$distance==50, ]$stroke)
print("Estilos que se nadan en pruebas de 200 metros:")
summary(nadadoresPruebas[nadadoresPruebas$distance==200, ]$stroke)
```

Hay más nadadores que nadan semifinales puesto que hay 5 pruebas, no 4.
Si echamos los cálculos, 160/(2\*5)=16 nadadores, igual que en las demás.

Se puede ver de manera análoga que nadan 8 nadadores cada final.

Ahora, ya que hemos analizado a fondo qué sucede con las finales, semifinales y preliminares, vamos a ver qué significan los otros dos valores que toma la variable *round*.

### Rondas SOP [Alonso]

Bien, primeramente, vamos a observar las filas tales que toman ese valor.
Lo hacemos de la siguiente manera:

```{r}
datosSOP<-datos2015[datos2015$round=="SOP",]

datosSOP
```

Observamos 4 filas, que se trata, viendo que es el mismo *eventid*, de una prueba que nadan sólo 2 nadadoras, Osman y Kelly.
En este caso, un 100 mariposa.
Es curioso que estas dos nadadoras naden una sóla prueba.
Además, nadaron a las 11:56, por la mañana, donde sólo se nadan preliminares.
Vamos a ver si descubrimos algo viendo la clasificación de ese 100 mariposa en la ronda preliminar:

```{r}
fly100PREWomen<-nadadoresPruebas[nadadoresPruebas$distance==100 & nadadoresPruebas$stroke=="FLY" & nadadoresPruebas$round=="PRE" & nadadoresPruebas$gender=="F", ]

#Ahora ordenamos por tiempo
fly100PREWomen<-fly100PREWomen[order(fly100PREWomen$swimtime), ]
#Las ordeno
rownames(fly100PREWomen) <- 1:nrow(fly100PREWomen)
fly100PREWomen

```

Si busco a Osman y Kelly en la anterior tabla, observo que se encuentran en el puesto 16 y 17 respectivamente y que, hicieron el mismo tiempo.
Luego tiene sentido razonar que, las rondas SOP son rondas de desempate para ver quién pasa a la siguiente ronda.

### Rondas SOS [Alonso]

Viendo el razonamiento de las rondas SOP, intuimos que las rondas SOS deben ser rondas de desempate entre nadadores de las semifinales.
De todas maneras, vamos a verlo.
Para ello, si nos fijamos en una de las tablas anteriores, en la prueba de 200 metros había 4 nadadores que nadan la ronda SOS.
Vamos a visualizarlo:

```{r}
datosSOS<-nadadoresPruebas[nadadoresPruebas$round=="SOS" & nadadoresPruebas$distance==200, ]
datosSOS
```

Vemos que se nadaron dos rondas SOS, una para la prueba de 200m braza femenino, y otra para la prueba de 200 estilos masculino.
Elijamos el 200 estilos masculino, visualicemos el ranking de las semifinales y veamos si están Roberto Pavoni y Conor Dwyer empatados en el 8vo y 9no puesto:

```{r}
medley200SEM<-nadadoresPruebas[nadadoresPruebas$round=="SEM" & nadadoresPruebas$distance==200 & nadadoresPruebas$gender=="M" & nadadoresPruebas$stroke=="MEDLEY", ]

#Ahora, ordeno igual que antes: 

medley200SEM<-medley200SEM[order(medley200SEM$swimtime), ]
#Las ordeno
rownames(medley200SEM) <- 1:nrow(medley200SEM)
medley200SEM
```

Y efectivamente, empataron con un tiempo de 118.54 segundos, luego SOS equivale a las rondas de desempate producidas en las rondas semifinales.
Además, observamos que se realizan por las tardes.

## Estudios relacionados con los puntos.

Veamos las posibles relaciones de puntos con las demás variables:

### Mejor nadador por prueba nadada. MVP de los mundiales.

Veamos ahora cómo se distribuyen los puntos:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = points)) +
geom_density() +
ggtitle("Distribución. points")
```

Observamos que la mayoría de puntos se encuentran a partir de los 750/800 puntos, y esto, tiene sentido si razonamos que para entrar a los mundiales de natación, se necesitan unas marcas mínimas (una cantidad de puntos preestablecida).
Luego es normal encontrar una gran cantidad de datos que tengan más de 750 puntos ya que había un "corte" para la inscripción en la competición.
Esto hace que la gráfica no esté más distribuida por todos los posibles valores de puntos.

Ahora nos surge la siguiente pregunta: *¿Quién rindió mejor en los campeonatos?*.

Podemos buscar el nadador que hizo más puntos:

```{r}
datos2015[which.max(datos2015$points), ]
```

Observamos que la nadadora que cosechó más puntos en una prueba fue Katie Ledecky en los 1500 metros.
Buscando, casualmente observamos que batió el récord[<https://www.rtve.es/deportes/20150803/ledecky-bate-record-del-mundo-1500-libres/1193160.shtml>] del mundo en dicha prueba.

Ahora, vamos a buscar al nadador que, en promedio, consiguió más puntos, podríamos denominarlo el *MVP* del Mundial Kazán 2015.
Para ello:

```{r}
#Usamos nadadoresPruebas, donde tenemos cada nadador y la prueba que realizó. 

media_puntos <- aggregate(nadadoresPruebas$points ~ nadadoresPruebas$athleteid, data = nadadoresPruebas, FUN = mean)
media_puntos <- media_puntos[order(media_puntos$`nadadoresPruebas$points`, decreasing = TRUE), ]
media_puntos<- rename(media_puntos, "athleteid"="nadadoresPruebas$athleteid")
media_puntos<-rename(media_puntos, "meanPoints"="nadadoresPruebas$points")

head(media_puntos,5)
```

El atleta con id 108588 es el que hizo más puntos, veamos quien es:

```{r}
nadadoresPruebas[nadadoresPruebas$athleteid==108588	, ]
```

Luego, el MVP fue el británico Adam Peaty, que nadó 50, 100 y 200 braza.
Veamos quiénes fueron los integrantes del podio:

```{r}
nadadoresParticipantes[nadadoresParticipantes$athleteid==102630 | nadadoresParticipantes$athleteid==105594, ]
```

Completaron el podio Cameron Van der Burgh, de Sudáfrica, y Katie Ledecky.

### Puntos. Hombres vs Mujeres

A continuación, vamos a comparar los puntos realizados por hombres y mujeres, para ver si podemos sacar alguna conclusión.

Primeramente, vamos a ver la función de densidad:

```{r, warning=FALSE}
ggplot(nadadoresPruebas, aes(x = points, colour=gender)) +
geom_density() +
ggtitle("Distribución. Puntos por sexo")

```

A priori, parece haber dos distribuciones muy igualadas.

```{r}
modelo= lm(points ~ gender, data = nadadoresParticipantes)

summary(modelo)

# Realizar ANOVA
anova_puntos_genero <- aov(points ~ gender, data = nadadoresParticipantes)

# Ver el resumen del resultado
summary(anova_puntos_genero)

```

### Puntos. ¿La edad influye?

(parte de Javi) En esta sección vamos a comparar los puntos con la edad.
Para ello, vamos a dividir en 3 grupos por edades (menores de 18, entre 18 y 30 y mayores de 30) y a comparar el promedio de puntos cosechados por cada franja de edad.

```{r}
nadadores_menores <- nadadoresParticipantes[nadadoresParticipantes$edad < 18, ]

```

(Parte de Salma) Una buena manera de medir el rendimiento con respecto a la edad del nadador, es verlo a través de los puntos obtenidos.

```{r, warning=FALSE}
#QUERIA PONERLO CON COLORES Q SE VEA MEJOR EL GRAFICO DE CALOR(POR SER CREATIVOS Y TAL)
resumen_puntos <- nadadoresPruebas %>%
  group_by(edad, points) %>%
  summarise(frecuencia = n(), .groups = 'drop')

# Crear el gráfico de calor
ggplot(resumen_puntos, aes(x = edad, y = points)) +
  geom_tile(aes(fill = frecuencia), color = "white") +
  scale_fill_gradient(low = "pink", high = "darkred",limits = c(min(resumen_puntos$frecuencia), max(resumen_puntos$frecuencia)))+
  theme_bw() +
  labs(title = "Gráfico de Calor: Edades y Puntos Obtenidos",
       x = "Edad",
       y = "Puntos Obtenidos") +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank())
```

### Modelo de regresión lineal: reactiontime vs swimtime

```{r}
# Esto no funciona porque las dos variables continuas tienen distinto tamaño
# Hay que gestionar los NAs previamente
# Además, como solo se está trabajando con dos variables continuas, no tiene sentido hacer pairs
# Realmente es un único plot
# pairs(nadadoresPruebas$points,splitswimtime)
```

*poner aqui todo juntos en un pairs* Empezamos viendo la relación lineal (que ya sabemos que será alta) entre puntos y tiempo.
Es evidente que a mayor tiempo, hay menos puntos.
Veámoslo

```{r}
nadadoresPruebas50crol<- nadadoresPruebas[nadadoresPruebas$distance==50 & nadadoresPruebas$stroke=='FREE', ]
t= nadadoresPruebas50crol$swimtime
p= nadadoresPruebas50crol$points
cor(t,p)
#verlo pero 
```

Esto no es de mucho estudio, ya que es lo lógico.

Veamos los puntos respecto al tiempo de reacción:

```{r}
nadadoresPruebas<- na.omit(nadadoresPruebas)
x= nadadoresPruebas$points
y=nadadoresPruebas$reactiontime
```

```{r}
cor(x,y)
```

Parecen no estar correlacionadas el tiempo de reaccion y los puntos de manera lineal.
Pero a lo mejor, en pruebas específicas , como las pruebas de distancias cortas la correlación es mayor.

```{r}
nadadoresPruebas50<- nadadoresPruebas[nadadoresPruebas$distance==50, ]
X=nadadoresPruebas50$reactiontime
Y=nadadoresPruebas50$points
cor(X,Y)
```

Ya tenemos nuestro objetivo de estudio ya que para comenzar con la modelización estadística, debemos contextualizar el problema, definiendo objetivos y variables.

Queremos investigar si existe relación entre el tiempo de reacción y puntos.
Una pregunta que puede surgirnos es, ¿A mayores valores del tiempo de reacción, hay mayores valores de puntos?
Luego, nuestro objetivo será saber si hay algún tipo de relación lineal, y las variables, por ende, serán tiempo de reacción y puntos.
La variable tiempo de reacción, será nuestra variable independiente, y puntos será la variable dependiente.

A continuación, procedemos a realizar una inspección gráfica simple, para identificar tendencias.

```{r}
plot(X,Y,xlab="Tiempo de reacción",ylab="Puntos")
```

```{r}
cov(X,Y)
```

Esta covarianza, positiva y grande en valor absoluto, nos indica que hay relación negativa entre las variables(ya lo habíamos intuido pero gracias al signo lo hemos confirmado).

A pesar de la confirmación, en este momento nos surge un problema, pues, la covarianza toma valores en todos los números reales, dependiendo de las magnitudes del tiempo de reacción y puntos, y de sus unidades .
Por eso, calcularemos el coeficiente de correlación lineal, que se obtiene tipificando la covarianza, es decir, dividiendo la covarianza entre las desviaciones típicas muestrales (obteniendo un coeficiente entre -1 y 1)

```{r}
cor(X,Y)
```

De manera adicional, podemos incluir histogramas marginales en cada eje del gráfico, para ello usamos las librerías `ggplot2` y `ggExtra`.

```{r}

#da error
#datos<-data.frame(x=X,y=Y)

#p<-ggplot(datos, aes(x = X, y = Y)) +
  #geom_point()
#vemos la nube de puntos 
#print(p)
#Especificamos que se añadan histogramas en los márgenes
#ggMarginal(p, type = "histogram")

```

Como hemos visto, si la relacion lineal es fuerte tiene sentido querer ajustar una recta a la nube de puntos.
Es decir, considerar un modelo de regresion lineal simple.

La función que ajusta el modelo de regresión lineal simple en R es `lm`(con parametros B_0,B_1 y sigma\^2), directamente hacemos un `summary` para que nos devuelva la información más importante, aunque realmente `lm` calcula muchas cosas: estimaciones, residuos, predicciones, etc.

```{r}
 #lm=lm(Y~X)
#summary(lm)
```

Podemos añadir la recta de regresión al gráfico usando el comando `abline`, y el objeto donde hemos guardado el ajuste de la recta, en este caso `lm4`:

```{r}
#representamos
#plot(X,Y)
#añadimos la recta de regresion
#abline(lm)
```

Los coeficientes de la regresión estimados también están en el objeto donde hemos guardado el ajuste, en `lm`

```{r}
#generamos un vector con los coeficientes de la regresion
#coeficientes=lm$coefficients
#comprobamos que es lo mismo que nos salía en el summary
#coeficientes
```

Sabemos que el valor de los puntos cuando X=0, es decir, que el tiempo de reacción sea cero, es de 1809 aproximadamente.
Este parámetro no tendría sentido, pues el tiempo de reacción nunca va a ser cero.
Por otro lado la pendiente es -1562.315, lo que nos muestra que por cada valor que aumenta X, Y aumenta lo indicado.

## Prueba 800m Libre femenino. [Alonso]

Veamos qué nadadores nadaron el 800 libre femenino:

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
nadadoras800free<-nadadoresPruebas[nadadoresPruebas$distance==800 & nadadoresPruebas$gender=="F", ]

dim(nadadoras800free)
```

Tenemos que 52 chicas nadaron el 800 libres, algunas de ellas dos veces ya que pasaron a la final.

Nos vamos a fijar en la final, para ello, filtramos otra vez los datos:

```{r}
nadadoras800free<-datos2015[datos2015$gender=="F" & datos2015$distance==800 & datos2015$round=="FIN", ]

```

#### Estudio sobre los parciales de la carrera.

Vamos a evaluar cómo fueron los parciales de las nadadoras, para ello hacemos el siguiente gráfico:

```{r}
ggplot(nadadoras800free, aes(y=nadadoras800free$lastname, x=nadadoras800free$splitswimtime, fill=nadadoras800free$lastname))+
  geom_boxplot()+
  labs(x="Parciales", y="Nadadoras")
```

De aquí podemos observar la media y los cuantiles de los parciales de las nadadoras.
Observamos que casi todas tienen 1 o incluso 2 puntos atípicos, seguramente se deban al primer y último parcial de la prueba.
Además, podemos observar que algunas nadadoras como Kapas y Friis, tuvieron una desviación muy pequeñita en sus parciales, es decir, fueron a un ritmo constante durante toda la prueba clavando sus parciales.

Vamos a observar, para cada nadador, los parciales realizados para ver si podemos conseguir algún patrón de tipo de carrera:

```{r}
ggplot(nadadoras800free, aes(x=nadadoras800free$splitdistance, y=nadadoras800free$splitswimtime, group = lastname, colour =lastname )) + 
  geom_line()  + 
  geom_point( size=2, shape=21, fill="white") + 
  theme_minimal()
```

Observamos que todas nadan muy rápido tanto el primer parcial como el último.
Además, vemos de manera clara como Ledecky parece que alterna un largo un poco más rapido y luego otro más lento durante toda su prueba.
¿Puede ser una estrategia de carrera?
Lo veremos más adelante.
También vemos alguna otra nadadora más que hace algo similar como Van Rouwendaal.
Otras en cambio, intentan conservar el ritmo marcado desde el inicio y ser constantes.
Carlin mete un cambio de ritmo muy drástico al paso de los 650m de 31s altos a 31s bajos y sigue luego bajando.

#### Visualización de la carrera.

Ahora, vamos a definir una tabla en la que nos va a importar el nombre, la suma total de tiempo al paso de cada parcial:

```{r}
nadadoras800free <- nadadoras800free %>%
  dplyr::select(lastname,firstname,gender,reactiontime,splitdistance,cumswimtime, swimtime)

```

Visualizamos la carrera:

```{r}
# Ordenar los datos por tiempo
nadadoras800free <- nadadoras800free %>%
  arrange(splitdistance, cumswimtime)

# Crear un índice de posición
nadadoras800free <- nadadoras800free %>%
  group_by(splitdistance) %>%
  mutate(Posicion = rank(cumswimtime, ties.method = "first"))



ggplot(nadadoras800free, aes(x = splitdistance, y = Posicion, group = lastname)) +
  geom_line(aes(color = lastname, alpha = 1), size = 2) +
  geom_point(aes(color = lastname, alpha = 1), size = 4) +
  scale_y_reverse(breaks = 1:nrow(nadadoras800free))
```

Observamos como Ledecky lidera toda la carrera, Boyle alcanza al paso de los 100 metros la segunda posición y la mantiene.
La pelea por la última medalla en juego dura hasta los 700 metros, donde un adelantamiento de Carlin a Ashwood hace que la nadadora Jaz Carlin alcance el bronce olímpico.

# PCA's

Realizaremos ahora el análisis de componentes principales del 800m libres femenino:

## PCA. 200 mariposa masculino preliminares (Salma)

La idea de realizar el siguiente PCA es porque disponemos de gran cantidad de variables, algunas de las cuales están correlacionadas entre sí, lo que complica su análisis.
En estas situaciones es conveniente aplicar el método de componentes principales, que permita reducir el número de variables sin pérdida sustancial de información, y consiguiendo que estas nuevas variables sean incorreladas evitando así que haya información redundante.

Comenzamos,cargando los datos:

```{r}
prueba200MariposaMasc<- datos2015[datos2015$distance==200 & datos2015$gender=="M" & datos2015$stroke=="FLY"& datos2015$round=="PRE", ]

prueba200MariposaMasc <- prueba200MariposaMasc %>%
    dplyr::select(lastname, reactiontime, splitdistance, splitswimtime, edad)
```

Creamos una tabla en la que nos quedamos con el nombre, apellidos y parciales

```{r}
pruebita <- prueba200MariposaMasc %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
pruebita
#omito los valores nulos: 
pruebita<- na.omit(pruebita)
row.names(pruebita) <- pruebita$lastname # esto es para llamar a las filas con el nombre de los nadadores
pruebita
```

Calculas estadísticas descriptivas utilizando 'pastecs::stat.desc' para entender mejor tus datos:

```{r}
pastecs::stat.desc(pruebita, basic = F)
```

Se puede observar que hay grandes diferencias entre las varianzas de las variables, lo que puede afectar a los resultados de un análisis de componentes principales (ACP), debido a que las variables con mayor varianza tendrán más influencia en la generación de un componente.

El ACP tiene sentido cuando hay correlación entre las variables pues permite eliminar información redundante.
Si se analiza la matriz de correlaciones se puede ver, a modo de ejemplo, que hay correlaciones fuertes.Luego, procedemos con el PCA

```{r}
prueba200MariposaMasc2<- datos2015[datos2015$distance==200 & datos2015$gender=="M" & datos2015$stroke=="FLY"& datos2015$round=="PRE", ]

prueba200MariposaMasc2 <- prueba200MariposaMasc2 %>%
    dplyr::select( reactiontime, splitdistance, splitswimtime, edad)

R <- cor(prueba200MariposaMasc2)
corrplot::corrplot(R, method = "number", 
                   number.cex = 0.75) # Matriz de correlaciones con números en letra pequeña
```

Para la obtención de los componentes principales utilizamos la función princomp.
Para evitar la influencia de la diferencia en magnitud de las varianzas se puede emplear los datos originales y el argumento cor = TRUE o los datos originales estandarizados y el argumento cor = FALSE.Utilizaremos el primer caso,ya que conseguimos que la suma de las varianzas de las variables originales y la de los componentes coincida con el número de variables de la matriz de datos original.

```{r}
componentess=prcomp(pruebita[,-1], cor = TRUE)
summary(componentess)
```

Los componentes están ordenados en función de la varianza que explican y el porcentaje acumulado permite decidir con cuántos componentes trabajar.
En este caso con solo dos se explica el 96%, con tres el 98%, con uno el 68%...

Generalmente, hay un número pequeño de componentes, los primeros, que contienen casi toda la información y el resto suele contribuir relativamente poco.
Ya lo hemos visto en nuestro estudio.
Podemos directamente coger 2, trabajar sobre el plano y tener una alta varianza explicada, pero vamos a demostrarlo de una manera un poco más empírica.
Utilizamos el criterio del autovalor superior a la unidad (regla de Kaiser) y el gráfico de sedimentación (scree test).

Para el primero, tenemos que saber que este criterio retiene aquellos componentes cuyos valores propios son superiores a la unidad y funciona bastante bien salvo con un gran número de variables, que no es nuestro caso.Luego, será muy preciso.
Las raices de los autovalores asociados a la matriz de correlaciones son las desviaciones típicas de los componentes y se encuentran en '\$sdev' del objeto componentes creado con la función princomp.

```{r}
auto<-componentess$sdev^2
auto
```

El número de componentes a retener según este criterio sería 2, ya que únicamente hay 2 autovalores mayores que uno.
Como ya se ha visto, esta decisión implicaría quedarnos con un 96% de la varianza total de los datos, que es bastante.

Otra manera de ver el número de componentes que escojamos, más gráfica, es un gráfico de sedimentación (scree test).
Este gráfico muestra en el eje de ordenadas los autovalores y en el eje de abscisas los componentes.
Los cambios en la pendiente nos permiten observar cuánta capacidad explicativa va aportando cada componente.

Se escoge el número de componentes a partir del cual los autovalores restantes son relativamente más pequeños en comparación con él.

```{r}
plot(componentess, type="lines", main = "Gráfico de sedimentación")
abline(h=1, lty=3, col="red")
```

El gráfico de codo nos aconseja también quedarnos con 2 componentes.
Ambos criterios ofrecen la misma conclusión, que el número de componentes a retener es 2.

Una vez pasamos a la interpretación de las componentes debemos estudiar sus relaciones con cada una de las variables originales.
Para ello se obtienen e interpretan las correlaciones entre los componentes (componentes\$scores) y las variables.
Una forma de calcularla es con la función cor:

```{r}

Cor_CompVar <- round(cor(pruebita[,-1], componentess$scores), 4) # con round se redondea, en este caso concreto, a 4 decimales 
Cor_CompVar
```

Estos coeficientes que se acaban de calcular son los que se utilizan para interpretar los componentes.
Como se ha decidido retener solo dos componentes, es conveniente crear un objeto que contenga solo las correlaciones con esos tres componentes, que será el objeto a analizar:

```{r}
Cor_CompVar_retenidos <- Cor_CompVar[, 1:2]
Cor_CompVar_retenidos
```

Antes de seguir con la interpretación de los componentes, es conveniente analizar si con el número de componentes elegido (dos) están todas las variables bien representadas.
Para ello se utiliza el coeficiente de correlación al cuadrado.El valor de la correlación al cuadrado se utiliza para estimar la calidad de la representación.
Cuanto más cercano esté a la unidad, mejor será esta.

```{r}
round(Cor_CompVar[,1:2]^2, 4) # con round se redondea, en este caso concreto, a 4 decimales
```

Estos resultados se pueden visualizar con corrplot:

```{r}
corrplot::corrplot(factoextra::get_pca_var(componentess)$cos2[, 1:2], is.corr = F)
```

La variable correspondiente a 200m se explica principalmente por la componente 1, lo que sugiere que el rendimiento en esta distancia está fuertemente asociado a la variabilidad que captura este componente.
La visualización indica que esta relación tiene un porcentaje de varianza explicada de aproximadamente 37% lo cual es significativo.La variable 150m también tiene una correlación notable con el componente 1, aunque en menor medida que la variable de 200m.
Esto indica que el rendimiento en 150m también está influenciado por las mismas características que se reflejan en el componente 1.

La variable edad tiene un fuerte impacto en el componente 1, con un porcentaje de varianza explicada alrededor del 74%.
Esto sugiere que este componente refleja características que son particularmente relevantes para la edad de los nadadores, implicando que, a medida que los nadadores envejecen, sus tiempos y capacidades en el agua podrían verse influidos por la edad.
Este hallazgo es importante porque indica que la edad no solo es un factor en el rendimiento, sino que también está profundamente integrada en los componentes que explican la variabilidad del rendimiento en natación.

```{r}


factoextra::fviz_cos2(componentess, choice = "var", 
                      axes = 1:2, # axes recoge los componentes a utilizar
                         title = "Cos2 de las variables para los componentes 1 a 2") 
```

En este caso, se representa la suma de cos2 para los 2 componentes.La proporción de variabilidad explicada por los dos componentes retenidos es bastante baja.

Procedemos, con la función fviz_pca_var del paquete factoextra, donde sobre un círculo de radio unidad, se sitúan las variables, utilizando como coordenadas sus correlaciones con cada uno de los componentes en el plano.
Además, las variables se pueden colorear en función de distintas características, entre las que destacan su contribución y el valor del cos2 (por ejemplo, verde, naranja o rojo dependiendo de que sean valores bajos, medios o altos, respectivamente).

En edad,la recta formada por la primera componente solo explica el 0,28% de la varianza de edad, lo que significa que está pobremente representado por esta dimensión.

```{r}

factoextra::fviz_pca_var(componentess, col.var = "cos2", 
                         gradient.cols = c("green", "orange", "red"),
                         repel = TRUE,
                         title = "Cos2 de las variables en el plano 1")
```

Cuanto más cercana esté una variable al borde, mejor será la calidad de la representación en el conjunto de las dos componentes.

La variable reactiontime también se observa en una posición cercana al centro del círculo, lo que sugiere que su variabilidad no está suficientemente capturada por los dos componentes principales.
Esto refuerza la idea de que el tiempo de reacción podría requerir un análisis más profundo o considerar otros componentes adicionales para una representación más adecuada.
Por el contrario, otras variables relacionadas con las distancias (como las variables de 50m, 100m, 150m, y 200m) están más alejadas del centro, lo que indica que están bien representadas por los dos primeros componentes.
Esto sugiere que estos componentes capturan la mayor parte de la variabilidad del rendimiento en natación en estas distancias.

Ya estamos preparados para interpretar las componentes:

Para llevar a cabo esta interpretación puede resultar útil visualizar exclusivamente las correlaciones más altas en valor absoluto de forma que nuestra atención se centre en ellas.
En nuestro caso, al ser pocas variables vamos a saltarnos este paso.
Pero si fuese muy lioso, lo haríamos asi, obteniendo el valor de -0.4533 que será objeto de estudio más adelante.

```{r}
Cor_CompVar_retenidos_mayores <- Cor_CompVar_retenidos
Cor_CompVar_retenidos_mayores[abs(Cor_CompVar_retenidos_mayores) < 0.4]<- NA
print(Cor_CompVar_retenidos_mayores, na.print="")
```

Vemos todas nuestras correlaciones

```{r}
Cor_CompVar_retenidos
```

Tiempo de reacción: Las variables 150, siguiendolas, fondos e ingresos presentan correlaciones con el componente 1 superiores, indicando que están mas correlacionados con el tiempo de reacción, que por ejemplo 50 metros.
Esto es, cuanto mayor sea el valor de estas cuatro variables en una prueba, mayor será su puntuación en esta componente.

Concluimos con que los tiempos de reacción están positivamente correlacionados con todas las distancias, siendo más pronunciada la correlación con las distancias más largas (150 y 200 metros), que tienen valores de 0.3712 y 0.3496, respectivamente.
Esto sugiere que a medida que aumenta la distancia, también tienden a aumentar los tiempos de reacción, lo que podría ser esperado debido al mayor esfuerzo físico requerido en distancias más largas.

Edad:las correlaciones entre la edad y las distancias son todas negativas, con el valor más alto siendo -0.4533 para la distancia de 200 metros.
Esto indica que a medida que aumenta la edad, los tiempos tienden a ser más altos en las distancias más largas.
Es posible que los nadadores más jóvenes tiendan a tener mejores rendimientos en distancias más largas en comparación con los mayores, aunque esto debe interpretarse con cautela y podría estar influenciado por otros factores no considerados en este análisis.

Los resultados sugieren que el tiempo de reacción es un factor que podría ser optimizado independientemente de la edad.
Esto puede ser útil para diseñar programas de entrenamiento que se centren en mejorar los tiempos de reacción de los nadadores, sin considerar necesariamente su edad.
La relación negativa entre la edad y los tiempos en distancias más largas podría indicar que es importante tener en cuenta la progresión en el rendimiento de los nadadores a medida que envejecen.

Represento

```{r}
fviz_pca_biplot(componentess, repel = TRUE)

```

Este gráfico combina la información de las variables y de las observaciones, utilizando las dos primeras componentes principales (Dim1 y Dim2), que explican la mayor parte de la varianza en los datos.

Cada flecha o vector en el gráfico representa una variable original y muestra cómo esa variable contribuye a las componentes principales (Dim1 y Dim2).

Una flecha más larga significa que la variable está más correlacionada con una de las componentes principales.
En el gráfico: edad parece tener una de las flechas más largas y apunta en la dirección contraria a las otras variables, indicando una fuerte relación con Dim1 pero en sentido negativo.

Tiempos de natación (50, 100, 150, 200) tienen flechas bastante largas, apuntando hacia la derecha y hacia arriba, lo que indica una alta correlación positiva con tiempo de reaccion y también una correlación significativa con edad.

En este caso, 50, 100, 150, y 200 metros están bastante agrupadas y apuntan hacia una dirección similar, lo que indica que estas variables están positivamente correlacionadas entre sí.

La edad apunta en dirección opuesta a las variables de los tiempos de natación, lo que sugiere que a mayor edad, menor rendimiento en esas pruebas.

El caso de reactiontime, que está casi perpendicular a las otras variables, indicando una baja correlación con las demás.

La posición de los puntos en relación con las flechas de las variables te da una idea de qué variables influyen más en esas observaciones.

```{r}
# Filtro de pruebas de 200m masculino
resumen200 <- datos2015[datos2015$distance==200 & datos2015$gender=="M" & datos2015$stroke=="FLY"& datos2015$round=="PRE", ]

# Selección de columnas relevantes
resumen200 <- resumen200 %>% dplyr::select(lastname,reactiontime,edad) %>%
    distinct() %>%         
    arrange(desc(reactiontime))


resumen200
#habria q ver quienes son el 5 y el 15 aqui
```

Para entender mejor esto, elijo el punto 5 y el 15, y veo como concluyo: El punto 5 representa una observación, probablemente correspondiente a un participante más joven, pero con un tiempo de reacción muy alto.
La edad parece tener poca o ninguna influencia negativa en su desempeño, pero esta muy alejado de la flecha edad.
Luego debe ser bastante joven, pero no mas joven que el número 26, ni con un tiempo de reacción más alto que el 26, pues este esta mucho más alejado a la derecha.

El punto 15 representa una observación que no tiene una fuerte correlación con ninguna variable en particular.
Es probable que el participante correspondiente tenga un rendimiento promedio o moderado en las pruebas de natación y que su edad no juegue un papel importante.
Al estar más arriba en Dim2, podría haber alguna influencia positiva de los tiempos de natación, pero no de forma muy clara como en el caso del punto 5.

Para ver que hemos concluido bien, represento pero con nombres, y dejo de estar a ciegas

```{r}
# Crear un biplot con los nombres en lugar de los números
fviz_pca_biplot(componentess, 
                 repel = TRUE,
                 label = "none") +  # No mostrar etiquetas por defecto
  geom_text(data = pruebita, aes(x = componentess$x[, 1], 
                               y = componentess$x[, 2], 
                               label = lastname), 
            vjust = -1)  # Ajustar el desplazamiento vertical
resumen200
```

El punto 5 se corresponde con Castillo, que efectivamente aparece con tiempo de reacción alto, el punto 26 es Alkula, que aparece el segundo con tiempo de reacción más alto.
En las edades también vemos que AL-Khulaifi es muy joven, como ya nos esperábamos.

## PCA. 800M libres femenino. [Alonso]

Lo primero que debemos hacer es cargar los datos:

```{r}
prueba800libresPreliminar<- datos2015[datos2015$distance==800 & datos2015$gender=="F" & datos2015$stroke=="FREE" & datos2015$round=="PRE", ]

prueba800libresPreliminar <- prueba800libresPreliminar %>%
    dplyr::select(lastname, reactiontime, splitdistance, splitswimtime, edad)
```

Bien, ahora, debemos encontrar la manera de crear una tabla en la que nos quedemos con el nombre, apellido y parciales.

```{r}
pruebawide <- prueba800libresPreliminar %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas
pruebawide
#omito los valores nulos: 
pruebawide<- na.omit(pruebawide)
row.names(pruebawide) <- pruebawide$lastname # esto es para llamar a las filas con el nombre de los nadadores


```

Ahora que ya tenemos nuestra tabla hecha, vamos a hacer el PCA:

```{r}
prcomp(pruebawide[,-1], scale=T)
summary(prcomp(pruebawide[,-1],scale=T))
```

Viendo el pca, observamos que con la primera componente, tenemos un 85% de la varianza.
Con pc2 un 5%, luego con esas dos podemos explicar un 90% de los datos.

Ahora, veamos cómo se ven los datos:

```{r}
plot(prcomp(pruebawide[,-1],scale=T)$x[,1:2], type="n")
text(prcomp(pruebawide[,-1],scale=T)$x[,1:2],rownames(pruebawide))

```

Si nos fijamos en la variable PC1, tenemos más a la izquierda a las nadadoras más rápidas en media en la prueba y a la derecha las más lentas.

Si nos fijamos en la variable PC2, más arriba tenemos a las nadadoras con MENOR tiempo de reacción y abajo las que tienen mayor tiempo de reacción, variando un poco también con la edad pero no siendo tan significativa.

Veamos cómo queda el biplot:

```{r}
biplot(prcomp(pruebawide[,-1],scale=T))

```

## PCA 100m mariposa femenino

En primer lugar, vamos a crear una nueva tabla llamada prueba100MariposaFem en la cuál nos quedamos con todas las pruebas de atletas femeninos, de distancia igual a 100 metros y de estilo de nado mariposa.
A continuación, nos quedamos con las columnas de lastname, reactiontime, splitdistance, splitswimtime y swimtime de la tabla prueba100MariposaFem.

```{r}
# Filtro de pruebas de 100m mariposa femenino
prueba100MariposaFem <- datos2015[datos2015$distance==100 & datos2015$gender=="F" & datos2015$stroke=="FLY" & datos2015$round =="PRE",]

# Selección de columnas relevantes
prueba100MariposaFem <- prueba100MariposaFem %>% dplyr::select(lastname, reactiontime, splitdistance, splitswimtime)
```

```{r}
prueba <- prueba100MariposaFem %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas

#Eliminamos duplicados y NA de la columna 'lastname'
prueba <- prueba[!duplicated(prueba$lastname) & !is.na(prueba$lastname), ]

prueba <- as.data.frame(prueba)

# Asignar los nombres de fila como el apellido del nadador
row.names(prueba) <- prueba$lastname

#Eliminamos filas con NA restantes
prueba <- na.omit(prueba)
```

Con todo esto, estamos preparados para realizar el PCA:

```{r}
#Realizamos el PCA
pca_100mariposafemenino <- prcomp(prueba[,-1], scale=T)

# Resultados del PCA
summary(pca_100mariposafemenino)

#Visualización del PCA
biplot(pca_100mariposafemenino)
```

Obtenemos que la componente 1 (PC1) explica un 74,23% de las prueba y la 2 un 23,28%.
También tenemos una gráfica del PCA realizado.


# Análisis de componentes principales en la carrera preliminar de 1500 metros (INES)

Vamos a ver en qué estilo predominan los nadadores de 1500 metros En la prueba de 1500, todos los nadadores nadan en estilo libre.
Por tanto, no seleccionaremos según esa imposición, ya que nos viene de los propios datos.
Gracias a ello, tenemos un enfoque más global de la carrera de 1500 metros.
Esto lo comprobamos viendo que

```{r}
summary(nadadoresPruebas$stroke[nadadoresPruebas$distance == 1500])

summary(nadadoresPruebas$round[nadadoresPruebas$distance == 1500])


```

Como podemos observar, todos los nadadores nadan en estilo libre.
Por tanto, no debemos hacer distinción en este tipo de carrera.
Además, tenemos 70 participantes en rondas preliminares y 15 finales.
Por tanto, tomaremos la ronda preliminar para hacer nuestro análisis de componentes principales.

```{r}
# Filtro de pruebas de 1500m masculino
datos1500Masc <- datos2015[datos2015$distance==1500 & datos2015$gender=="M" & datos2015$round =="PRE",]

# Selección de columnas relevantes
datos1500Masc <- datos1500Masc %>% dplyr::select(lastname, reactiontime, splitdistance, splitswimtime)
datos1500Masc
```

```{r}
prueba1500 <- datos1500Masc %>%
  pivot_wider(names_from = splitdistance,       # Los valores de 'Split' serán los nombres de las columnas
              values_from =splitswimtime)     # Los valores de 'Tiempo' llenarán las celdas

#Eliminamos duplicados y NA de la columna 'lastname'
prueba1500 <- prueba1500[!duplicated(prueba1500$lastname) & !is.na(prueba1500$lastname), ]

prueba1500 <- as.data.frame(prueba1500)

# Asignar los nombres de fila como el apellido del nadador
row.names(prueba1500) <- prueba1500$lastname

#Eliminamos filas con NA restantes
prueba1500 <- na.omit(prueba1500)
prueba1500
```

Con todo esto, estamos preparados para realizar el PCA:

```{r}
#Realizamos el PCA
pca_1500masculino <- prcomp(prueba1500[,-1], scale=T)

# Resultados del PCA
summary(pca_1500masculino)

```

Por tanto, vemos el Análisis de Componentes Principales (PCA) en los datos de nadadores masculinos en la carrera de 1500 metros, excluyendo la primera variable, que es el nombre.

Observamos que el primer componente principal (PC1) tiene una desviación estándar de 5.0272 y explica el 81.52% de la varianza total.
Este componente captura la mayor parte de la variabilidad en los datos, lo que sugiere que una sola dirección en el espacio de los datos contiene gran parte de la información relevante.
Los siguientes componentes, como PC2 y PC3, explican 7.75% y 3.47% de la varianza respectivamente.
Estos valores disminuyen progresivamente, lo que indica que los componentes adicionales explican cada vez menos de la variabilidad total.
Así pues, los primeros dos componentes principales explican el 89,27% de la varianza.
Si añadimos el tercer componente, logran explicar el 92.73% de la varianza, lo que puede ser suficiente para una interpretación efectiva de los datos.

Visualizamos ahora cómo se distribuyen los datos en las dos primeras componentes principales y observamos la influencia de las variables en estas componentes.

```{r}
fviz_pca_biplot(pca_1500masculino, repel = TRUE)

```

Viendo el gráfico, podemos interpretar la primera componente como la rapidez en cada split de los participantes.
Cuantos mayores tiempos tienen en cada split, mas desplazados estarán hacia la izquierda.
Por tanto, los nadadores mas a la derecha serán aquellos con mejores resultados.
Vemos como el 81,5% de la varianza de los resultados está explicado por estos tiempos, como podría imaginarse en un principio.
Si nos enfocamos en lo que explica la componente 2, vemos que mayores tiempos de los primeros splits condicionan su desplazamiento hacia abajo, y los tiempos mayores en los ultimos splits desplazan los puntos hacia arriba.
Esto parece indicar que la componente 2 captura las diferencias entre el rendimiento en las etapas iniciales y finales de la prueba, posiblemente destacando la resistencia o la fatiga en los nadadores.
Además, es claramente visible como el tiempo del último split (cuando se completan los 1500m) es muy influyente en la posición de estos nadadores.
Es decir, los tiempos en esta última parte parecen ser muy decisivos en cuanto a su resultado final.

Si observamos la influencia del tiempo de reacción, los tiempos de reacción altos ejercen influencia a favor del eje x e y, en sus sentidos positivos.
Con lo cual, el tiempo de reacción alto parece estar asociado con un rendimiento positivo en los splits y posiblemente en la resistencia hacia el final de la prueba.

Para ver si estas cuestiones se cumplen, vamos a observar si los primeros puestos del ranking de puntos de esta categoría coincide con lo visto en el gráfico.

```{r}
# Filtro de pruebas de 1500m masculino
resumen1500 <- datos2015[datos2015$distance==1500 & datos2015$gender=="M" & datos2015$round =="PRE",]

# Selección de columnas relevantes
resumen1500 <- resumen1500 %>% dplyr::select(lastname,points) %>%
    distinct() %>%         
    arrange(desc(points))


resumen1500
```

Como podemos comprobar, Paltrinieri, Jaeger, Sun y Milne aparecen en los puntos más extremos del eje x.
Además, se localizan en la posición central, lo que parece indicar que sus tiempos son bastante estables durante todo el recorrido.
Si visualizamos los últimos nadadores, que son Arias Dourdet, Butler y Sim Wee Sheng, observamos que efectivamente están en los extremos izquierdos del eje x.
Además, Arias Dourdet y Butler están desplazados hacia el eje y, lo que parece indicar que obtuvieron tiempos más largos en sus splits finales, posiblemente debido a una falta de resistencia y mayor fatiga en estos tiempos, que es un factor crucial para el desarrollo de este tipo de pruebas.

## Clusters

#Cluster 200 masculina

```{r}
clusterprueba200 <- scale(pruebita[,-1])

summary(clusterprueba200)
```

```{r}
distancias <- get_dist(clusterprueba200)
fviz_dist(distancias, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k200 <- kmeans(clusterprueba200, centers = 2, nstart = 25)
str(k2)
```

```{r}
fviz_cluster(k200, data = clusterprueba200)
```

Como vemos, con 2 clusters nos divide a los participantes según el tiempo de reacción (vemos como el 5, que ya habiamos mencionado, aparece en los más rápidos).
Los medios, son más, y están en el rojo.

Realmente parece que dos grupos no son suficientes.
Vamos a verlo empíricamente.

```{r}
# Reproducible
set.seed(123)

fviz_nbclust(clusterprueba200, kmeans, method = "wss")
```

Parece que deberiamos aumentar el número de grupos, incluso 5 grupos.
A partir de 5 grupos, parece muy baja mejora.

Utilizamos otros métodos.
Para ello, como el de la silueta.

```{r}
fviz_nbclust(clusterprueba200, kmeans, method = "silhouette")
```

Parece que con dos grupos, podemos excluir a valores muy discriminados en nuestro estudio.
Luego, depende de si nuestro objetivo es encontrar valores peculiares.

Probamos con k=5

```{r}
k5_200 <- kmeans(clusterprueba200, centers = 5, nstart = 25)

fviz_cluster(k5_200, data = clusterprueba200)
```

El cluster 5 representa un grupo de nadadores que tienen un comportamiento peculiar en cuanto a los tiempos de reacción, y la edad no parece ser un factor determinante para ellos.

El grupo azul (cluster 4) tiene varias observaciones distribuidas más arriba a la derecha del gráfico, a lo largo de Dim1.
Estos nadadores parecen tener una mayor edad y mayor tiempo de reacción.
Esto tiene sentido, ya que el eje de Dim1 parece estar relacionado con el rendimiento en la prueba (donde mayor puntuación indicaría menor rendimiento).

Este cluster verde está ubicado hacia el centro del gráfico, alrededor del origen de los ejes de Dim1 y Dim2.
Esto sugiere que los nadadores en este grupo tienen un rendimiento promedio o neutral en las variables consideradas (edad y tiempo de reacción).

Los puntos 5 y 26 están en un cluster aislado, probablemente por tener características atípicas en cuanto a su tiempo de reacción, pero con una edad no influyente.
El cluster azul representa a nadadores mayores con tiempos de reacción más lentos, lo que afecta negativamente su rendimiento.
Los otros clusters agrupan a los nadadores con características más cercanas entre sí en cuanto a edad y tiempos de reacción.

#Cluster divisivo 200

```{r}
# Clustering jerárquico divisivo
hc200 <- diana(clusterprueba200)

# Coeficiente de división; cantidad de estructura de agrupación encontrada
hc200$dc
```

Podemos proceder a realizar el dendograma(cercano a 1).

```{r}
# Drendrograma
pltree(hc200, cex = 0.6, hang = -1, main = "Dendrogram de DIANA")
```

Utilizamos k=5

```{r}
# Método de Ward
# Matriz de disimilaridades
d200 <- dist(clusterprueba200, method = "euclidean")
hc5_200 <- hclust(d200, method = "ward.D2" )

# Cortamos en 4 clusters
sub_grp <- cutree(hc5_200, k = 5)

# Visualizamos el corte en el dendrograma
plot(hc5_200, cex = 0.6)
rect.hclust(hc5_200, k = 5, border = 2:5)
```

Veamos si coincide con los clusters anteriores

```{r}
# Visualización
#Cluster realizado con el método de división
fviz_cluster(list(data=clusterprueba200,cluster=sub_grp))

#Cluster realizado con kmeans
fviz_cluster(k5_200, data = clusterprueba200)
```

Vemos que coinciden.

#Cluster para la prueba de 1500 masculina

```{r}


# escalado de todas las variables
clusterprueba1500 <- scale(prueba1500[,-1])

summary(clusterprueba1500)
```

```{r}
distance <- get_dist(clusterprueba1500)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r}
k2 <- kmeans(clusterprueba1500, centers = 2, nstart = 25)
str(k2)
```

```{r}
fviz_cluster(k2, data = clusterprueba1500)
```

Como vemos, con 2 clusters nos divide a los participantes según la velocidad.
Es decir, los que pertenecen al cluster rojo serían los de tiempos más altos, y los azules los que están en mejores posiciones de resultados.

Nos preguntamos, si el número óptimo de clústeres para dividir a nuestro grupo total es realmente 2, o podemos dividirlos en más grupos.
Para ello, utilizamos el método del codo.

```{r}
# Reproducible
set.seed(123)

fviz_nbclust(clusterprueba1500, kmeans, method = "wss")
```

Parece que sí que tenemos una mejoría si continuamos diviendo nuestro grupo en 3 o incluso 4.
Por encima de estos números, no obtenemos grandes mejoras en nuestro análisis.

Por tanto, probamos con k=3 y k=4 y observamos los resultados

```{r}
k3 <- kmeans(clusterprueba1500, centers = 3, nstart = 25)

fviz_cluster(k3, data = clusterprueba1500)
```

```{r}
k4 <- kmeans(clusterprueba1500, centers = 4, nstart = 25)

fviz_cluster(k4, data = clusterprueba1500)
```

Como podemos observar en ambos gráficos, la segregación de nadadores sigue estando bastante influida por su posición relativa al eje x.
Es decir, nos clasifica los grupos según sus velocidades.
Con 3 clústeres, tendríamos los nadadores lentos, los intermedios, y los muy rápidos.
En el segundo gráfico con 4 clusteres, podemos observar los grupos muy lentos (prácticamente valores outiers), los centrales divididos en mas y menos lentos y un último grupo, de competidores de alta calificación.
Observando ambos, los dos grupos de la derecha contienen prácticamente los mismos puntos.
Sin embargo,si que existe una división entre los puntos de la izquierda.
La elección de k=3 o k=4 vendrá por el interés del estudio que queramos realizar.
Si no nos interesan los nadadores de peor cualificación, no será necesario segregar a los nadadores en 4 grupos.
Sin embargo, si queremos analizar estos nadadores con peores marcas parece interesante ajustarnos a un nivel de k=4.

Utilizamos otros métodos para decidir si nuestro razonamiento es correcto.
Para ello, utilizamos el método de "silueta" y el método "GAP".

```{r}
fviz_nbclust(clusterprueba1500, kmeans, method = "silhouette")
```

```{r}
set.seed(123)
gap_stat <- clusGap(clusterprueba1500, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)

print(gap_stat, method = "firstmax")
fviz_gap_stat(gap_stat)
```

Utilizando estos dos últimos métodos, nos dan el resultado de que el número óptimo de clústers son dos en "silueta" y uno en "Gap".
Puesto que cada método nos determina un número distinto de k, utilizaremos la división en grupos según el objetivo a tratar, como hemos comentado recientemente.

#Cluster jerarquico prueba de 1500 metros masculina

## Cluster aglomerativo. AGNES.

Queremos hacer un cluster jerárquico de nuestra prueba.
Para ello, calculamos el valor del coeficiente aglomerativo

```{r}
# Clustering jerárquico usando enlace completo
hc2 <- agnes(clusterprueba1500, method = "complete" )

hc2$ac
```

El coeficiente aglomerativo tiene un valor cercano al 1, con lo que sugiere una fuerte estructura de agrupamiento.
Vamos ahora a evaluar qué metodo nos da un coeficiente mayor y emplearemos esa estructura de agrupacion con el objetivo de conseguir una estructura de agrupación más fuerte.

```{r}
# Métodos evaluados
m <- c( "average", "single", "complete", "ward")
names(m) <- c( "average", "single", "complete", "ward")

# Función para calcular el coeficiente de agrupamiento
ac <- function(x) {
  agnes(clusterprueba1500, method = x)$ac
}

map_dbl(m, ac)
```

Como vemos, lo conseguimos con el método ward.
Por tanto, utilizamos ese método para realizar el dendrograma

```{r}
# Matriz de disimilaridades
d <- dist(clusterprueba1500, method = "euclidean")

# Clustering jerárquico usando enlace completo
hc1 <- hclust(d, method = "ward" )

# Dendrograma
plot(hc1, cex = 0.6, hang = -1)
```

Interpretando el dendrograma, vemos como los primeros pasos de agrupamiento son entre distintas muy pequeñas.
Por tanto, no tiene sentido cortar en esas etapas iniciales.
El gráfico parece sugerir la aglomeración en 3 grupos.

##Cluster divisivo.
DIANA.

Calculamos ahora el coeficiente de división.

```{r}
# Clustering jerárquico divisivo
hc4 <- diana(clusterprueba1500)

# Coeficiente de división; cantidad de estructura de agrupación encontrada
hc4$dc
```

Como podemos ver, tenemos un coeficiente de división cercano al 1.
Con lo cual, podemos proceder a realizar el dendograma.

```{r}

# Drendrograma
pltree(hc4, cex = 0.6, hang = -1, main = "Dendrogram de DIANA")
```

Utilizamos ahora la función "cutree" para dividir nuestro dendrograma en los clústers que consideremos.
En este caso, utilizamos k=4

```{r}
# Método de Ward
hc5 <- hclust(d, method = "ward.D2" )

# Cortamos en 4 clusters
sub_grp <- cutree(hc5, k = 4)

# Visualizamos el corte en el dendrograma
plot(hc5, cex = 0.6)
rect.hclust(hc5, k = 4, border = 2:5)
```

Veamos si coincide con los clusters que hemos considerado en el apartado previo

```{r}
# Visualización
#Cluster realizado con el método de división
fviz_cluster(list(data=clusterprueba1500,cluster=sub_grp))

#Cluster realizado con kmeans
fviz_cluster(k4, data = clusterprueba1500)
```

Como vemos, las divisiones son similares, pero no son iguales.
Esto se debe al método de agregación que difiere en ambos casos.

A su vez, comparamos si los dendrogramas utilizados para agregar o dividir son isomorfos.

```{r}

# Matriz de distancias
res.dist <- dist(clusterprueba1500, method = "euclidean")

# Calcuamos los dos clustering jerárquicos
hc1 <- hclust(res.dist, method = "ward")
hc2 <- hclust(res.dist, method = "ward.D2")

# Dendrogramas
dend1 <- as.dendrogram (hc1)
dend2 <- as.dendrogram (hc2)

# los enfrentamos
tanglegram(dend1, dend2)
```

Como podemos observar, no nos dan dendrogramas isomorfos puesto que los dos métodos manejan de manera diferente las distancias entre grupos durante el proceso de fusión.
